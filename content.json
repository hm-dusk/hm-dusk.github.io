{"meta":{"title":"貍铭的博客","subtitle":"越自律，越自由","description":"长风破浪会有时，直挂云帆济沧海","author":"貍铭","url":"http://blog.hming.org","root":"/"},"pages":[{"title":"404","date":"2020-03-11T06:05:27.000Z","updated":"2020-03-11T06:07:36.917Z","comments":true,"path":"404.html","permalink":"http://blog.hming.org/404.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"about","date":"2017-07-17T11:49:44.000Z","updated":"2020-03-11T03:22:50.214Z","comments":false,"path":"about/index.html","permalink":"http://blog.hming.org/about/index.html","excerpt":"","text":"立志成为大佬的一个研究java后台的菜鸟如果你喜欢台球，我们可以切磋切磋如果你喜欢跑步，请加qq群869586140联系我：邮箱：cqupt_hm@163.comQQ：1322260665 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"categories","date":"2017-07-17T16:08:38.000Z","updated":"2020-03-11T03:22:11.758Z","comments":false,"path":"categories/index.html","permalink":"http://blog.hming.org/categories/index.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"contact","date":"2020-03-11T02:13:06.000Z","updated":"2020-03-11T02:13:40.225Z","comments":true,"path":"contact/index.html","permalink":"http://blog.hming.org/contact/index.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"tags","date":"2017-07-17T16:05:10.000Z","updated":"2020-03-11T03:22:37.590Z","comments":false,"path":"tags/index.html","permalink":"http://blog.hming.org/tags/index.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"},{"title":"friends","date":"2019-08-19T03:08:38.000Z","updated":"2019-08-19T03:08:55.435Z","comments":true,"path":"friends/index.html","permalink":"http://blog.hming.org/friends/index.html","excerpt":"","text":"document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"}],"posts":[{"title":"理财过程中遇到的名词整理","slug":"理财过程中遇到的名词整理","date":"2020-02-22T04:55:21.000Z","updated":"2020-02-22T04:55:21.000Z","comments":true,"path":"2020/02/22/li-cai-guo-cheng-zhong-yu-dao-de-ming-ci-zheng-li/","link":"","permalink":"http://blog.hming.org/2020/02/22/li-cai-guo-cheng-zhong-yu-dao-de-ming-ci-zheng-li/","excerpt":"","text":"GDP（Gross Domestic Product）百度百科国内生产总值（GDP）是指按国家市场价格计算的一个国家（或地区）所有常住单位在一定时期内生产活动的最终成果，常被公认为是衡量国家经济状况的最佳指标。国内生产总值GDP是核算体系中一个重要的综合性统计指标，也是我国新国民经济核算体系中的核心指标，它反映了一国（或地区）的经济实力和市场规模。 理解国民生产总值，指一个国家过去一年内新生产的全部财富总和。 CPI（consumer price index）百度百科消费者物价指数（consumer price index），又名居民消费价格指数，简称CPI。是一个反映居民家庭一般所购买的消费品和服务项目价格水平变动情况的宏观经济指标。它是在特定时段内度量一组代表性消费商品及服务项目的价格水平随时间而变动的相对数，是用来反映居民家庭购买消费商品及服务的价格水平的变动情况，是一个月内商品和服务零售价变动系数。 理解消费者价格指数，俗称物价指数，反映全社会物价变动水平的宏观经济指标。 M2百度百科广义货币供应量（M2）是指流通于银行体系之外的现金加上企业存款、居民储蓄存款以及其他存款，它包括了一切可能成为现实购买力的货币形式，通常反映的是社会总需求变化和未来通胀的压力状态。近年来，很多国家都把M2作为货币供应量的调控目标。 货币（M0）=流通中的现金，即流通于银行体系之外的现金。狭义货币（M1）=（M0）+单位活期存款。广义货币（M2）=M1+准货币（单位定期存款+居民储蓄存款+其他存款+证券公司客户保证金+住房公积金中心存款+非存款类金融机构在存款类金融机构的存款）。另外还有M3=M2+其他短期流动资产（如国库券、银行承兑汇票、商业票据等）。 理解广义货币供应量，是衡量社会真实货币存量和通货膨胀水平的最关键指标。 M指Money 复利百度百科复利（Compound Interest）,是指在计算利息时，某一计息周期的利息是由本金加上先前周期所积累利息总额来计算的计息方式，也即通常所说的”利说利”，”利滚利”。 理解世界第八大奇迹，也是为什么理财能跑赢通货膨胀的重要因素。 ETF基金百度百科交易型开放式指数基金，通常又被称为交易所交易基金（Exchange Traded Fund，简称ETF），是一种在交易所上市交易的、基金份额可变的一种开放式基金。交易型开放式指数基金属于开放式基金的一种特殊类型，它结合了封闭式基金和开放式基金的运作特点，投资者既可以向基金管理公司申购或赎回基金份额，同时，又可以像封闭式基金一样在二级市场上按市场价格买卖ETF份额，不过，申购赎回必须以一篮子股票换取基金份额或者以基金份额换回一篮子股票。由于同时存在二级市场交易和申购赎回机制，投资者可以在ETF市场价格与基金单位净值之间存在差价时进行套利交易。套利机制的存在，使得ETF避免了封闭式基金普遍存在的折价问题。 理解ETF基金是所有公募基金中成本最低，交易最方便的一种。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"理财","slug":"理财","permalink":"http://blog.hming.org/categories/%E7%90%86%E8%B4%A2/"}],"tags":[{"name":"专业名词","slug":"专业名词","permalink":"http://blog.hming.org/tags/%E4%B8%93%E4%B8%9A%E5%90%8D%E8%AF%8D/"},{"name":"解释","slug":"解释","permalink":"http://blog.hming.org/tags/%E8%A7%A3%E9%87%8A/"}]},{"title":"基金学习笔记","slug":"基金学习笔记","date":"2020-02-22T04:22:44.000Z","updated":"2020-02-22T04:22:44.000Z","comments":true,"path":"2020/02/22/ji-jin-xue-xi-bi-ji/","link":"","permalink":"http://blog.hming.org/2020/02/22/ji-jin-xue-xi-bi-ji/","excerpt":"","text":"基金的概念百度百科：基金，英文是fund，广义是指为了某种目的而设立的具有一定数量的资金。主要包括信托投资基金、公积金、保险基金、退休基金，各种基金会的基金。 用常人的话讲，基金是一种投资工具（产品），是投资机构筹集投资者手中的钱去投资股票、债券、外汇、货币等标的。 日常生活中所说的狭义上的基金一般特指：公募证券投资基金，简称公募基金。 股票和基金是人类历史上集合大量资金用以做特定用途的最重要的两项伟大发明。 基金分类按照是否在交易所上市划分 场内市场和场外市场场外市场 = 一级市场 场内市场 = 二级市场 分类按能否在一级市场或场外市场申购来划分为场内基金和场外基金 基金分类 特点 是否需要开股票账户 举例 场外基金 ● 从一级市场或场外市场买入● 基金规模会随着买入增加而增加● 费率高，一般万15 不需要 天天基金、蚂蚁聚宝、基金官网 场内基金 ● 从二级市场或场内市场买入● 基金规模固定● 无法进行申购和赎回，只能在二级市场通过买卖交易基金份额● 需要下载专门的证券交易软件，而且必须在股市开盘的时间内才能购买● 费率低，一般万1.5 需要 华宝智投 绝大部分场内交易的基金场外都有对应的产品 股市开盘（场内基金交易）时间： 周一至周五 9:30-11:30 13:00-15:00 按照投资标的划分 资本市场和货币市场 分类名 特点 资本市场 股票市场和一年期以上的长期债券市场 货币市场 交易一年期以下短期债券和各类票据的市场 分类 分类名 特点 投资市场 股票型基金（股基） ≥80%的资金投资股票 资本市场 混合型基金（混基） 一部分买股票，一部分买债券，但是比例都不超过80% 资本市场 债券型基金（债基） ≥80%的资金投资债券 资本市场 货币市场基金（货基） 投资货币市场 货币市场 股票型基金分类股票基金分成主动型基金和被动型基金。 分类名 特点 举例 主动型基金 基金经理根据自己的经验、模型进行买卖股票，企图获得超越市场的收益 国泰估值优势混合 被动型基金（指数基金） 完全复制某种指数，选取该指数的成分股基金投资 沪深300指数标普500指数纳斯达克100指数 混合型基金分类 分类名 特点 偏股型基金 投资股票份额≥50% 偏债型基金 投资债券份额≥50% 平衡型基金 投资股票、债券份额都≤50% 灵活型基金 投资份额未做上限规定 投资风险股票型基金 &gt; 混合型基金 &gt; 债券型基金 &gt; 货币基金 其他分类方式还有种分类是分成封闭基金和开放基金，不过现在封闭基金基本成为过去时，我们购买的一般都是开放基金。 完整基金名称的组成部分[基金公司名称] + [基金特点] + [基金投资范围] 货币基金余额宝余额宝为典型的货币基金，带动了货币基金的发展 余额宝成功的秘诀 余额宝随取随用，解决货币基金流动性的最后一公里难题。 货基一般需要T+2才能到账，T是交易（trade）的意思，意思是交易指令打上去之后需要2天钱才能到账。一般申购也是同样的道理。 余额宝7x24小时全天候为投资者提供赎回服务（但计算收益的方式还是没变）。 基金存在一个问题，如果在工作日下午3点钱申请赎回，则定为当天申请，需要第二天或者第三天才能赎回到账；如果是工作日下午3点后的申请，算作是第二天上班后的申请，需要等到第三天或者第四天才能到账。 同样的，如果在工作日下午3点钱申购，则定为当天申请，第二天才开始计算收益，第三天才能看到收益；如果是工作日下午3点后的申请，算作是第二天上班后的申请，需要等到第三天才计算收益，第四天才能看到收益。 因为周末交易所休市，所以周四下午3点是一个关键时间点，周四下午3点前申购，周五就开始计算收益，收益周六就能看到；如果是周四下午3点后申购，则算作周五的申请，下周一才开始计算收益，相当于白白浪费了3天的利息。 余额宝将基金的按月结算方式替换成了按日结算。 日结算不仅可以让投资者能每天看到收益，得到正反馈，而且通过复利的特点还能额外获得收益。 余额宝直接打通了投资和消费的任督二脉 直接用余额宝就可以很方便的进行支付。 现在已经不推荐购买余额宝了 随着基金规模的增大，余额宝的收益已经很低了。 赎回到账速度也不是最快的，最晚需要2小时左右。 现在余额宝转出超过一定额度需要手续费。 如何选购货币基金货币基金扮演的角色 货币基金扮演的应该是守门员的角色，它的主要责任是高安全性和高流动性。 货币基金的利率一般在一年期的银行定期存款基准利率的一倍到两倍之间。 普通家庭需要准备至少3-6个月的家庭支出金额来作为家庭紧急备用金。 货币基金的指标 七日年化收益（过去7天的平均年化收益，并不能代表货基的真实收益率） 每万份收益（只能反映一天的数据） 应该看过去半年、一年甚至更长时间的累计回报（可以在天天基金里面看）。 货币基金的分类货币基金一般后面跟A、B的后缀，不同的字母区分投资门槛。 货币基金类型 特点 适合投资者 A类货基 1000元起卖，有些低至100元甚至1元起卖 普通散户 B类货基 100万起卖，有些甚至1000万起卖 机构、土豪 普通投资者一般购买A类，A类的收益率也比B类地上0.2%~0.3%，所以优先挑选不分AB类的基金，避免受到利率歧视。 对于股票型、债券型、混合型基金来说，常见A、B、C后缀，区分收费方式。 分类 说明 特点 适合投资者 A类 通常指前端收费（在购买基金时收取费用，但赎回没有费用） 申购金额越高费率越低 一次性购入较多金额的土豪投资者 B类 通常指后端收费（在基金赎回时才收费） 持有基金时间越长费率越低 有耐心的长情投资者 C类 通常指销售服务费（不收申购费，也不收赎回费） 按日收费 短期持有，对流动性要求较高的投资者 货币基金的收费货币基金买卖不收取申购赎回费。传统货基费用收取情况表： 类别 费用 收取方 基金管理费 0.33% 基金公司 基金托管费 0.1% 资金托管银行 销售服务费 0.25% 销售渠道（银行、券商、天天基金网等第三方销售平台） 余额宝费用收取情况表： 类别 费用 收取方 基金管理费 0.3% 基金公司 基金托管费 0.08% 资金托管银行 销售服务费 0 销售渠道 （支付宝做销售渠道，免收销售服务费） 货币基金的购买时间 如果遇到春节、国庆等假期，需要提前购买，享受假期间的利息。 基金计算收益受交易所开放时间影响，平时最好在周四下午3点前购买（参考上文中的交易所开放时间）。 场内货币基金（货币ETF）ETF基金（Exchange Traded Funds）：交易型开放式指数基金。ETF基金是所有公募基金中成本最低，交易最方便的一种。需要挑选规模比较大的货币ETF。门槛较高，华宝添益10万起买，存在复杂的套利机制，不推荐新手购买。 Shibor指标Shibor是什么上海银行间同业拆借利率（Shanghai Interbank Offered Rate）：指中国大陆内各家银行之间借钱的利率。 银行是金融的核心，金融是经济的命脉，所以银行资金的流动性是绝对不能出半点差池的。为了预防危机，各国金融监管机构都会对银行做各种各样的关于资金安全的刚性约定。 最重要的一个指标：资本充足率必须高于8%资本充足率：简称CAR 公式=资本/加权风险资产政府通过规定CAR下限，保证银行能化解一定金融风险，保证银行的正常运营和发展。 一般每个季度都会对银行考察一次，每到季末的时候之前放贷过于激进，导致现钱不够的银行不等不想办法借钱来应对考察，但是银行对资金需求规模太大了，向老百姓借钱远远不够，所以必须在银行之间建立一个资金融通的市场，方便银行之间互相借钱。这个市场中的资金利率不是央行规定的，完全市场化定价，需求大的时候利率就高，这个资金利率就叫做银行间同业拆借利率。各个地方的命名有所不同：伦敦（Libor）、纽约（Nibor）、新加坡（Sibor）、香港（Hibor）、上海（Shibor） Shibor分类根据借款时间长短不同，利率可以分为隔夜、1周、2周、1个月、3个月、6个月、9个月和1年这几个品种。其中，隔夜拆借利率最能体现市场短期资金面是否紧张的关键指标。 Shibor指标会影响到中国境内所有资产的价格。 查看Shibor的方式可以通过官网：www.shibor.org查看最新数据 其中O/N（Over Night）就是指的隔夜拆借利率 历史Shibor指标2013年6月20日隔夜拆借利率达到了史无前例的：13.444%，在这段时间里余额宝的收益率也达到了7% 国债逆回购国债逆回购利率也深受Shibor指标影响 什么是国债逆回购国债正回购：持有未到期国债的机构投资者以国债为抵押物借钱，到期后再把国债拿回来。国债逆回购：个人投资者把钱借给交易对手，并暂时持有对方的国债，到期收钱归还国债。 国债逆回购分类根据借款期限可分为1天、2天、3天、4天、7天、14天、28天、91天和182天这么多品种。其中交易最活跃的是7天以内的，尤其是1天期限的品种 超过7天的品种普通投资者就不需要去考虑了 国债逆回购版本由于中国有沪深两个证券交易所，所以国债逆回购存在上交所和深交所两个版本另外，两个版本的交易门槛和回报率都不一样，深市利率往往比沪市低（利率歧视无处不在）： 类别 沪市（上海交易所） 深市（深圳交易所） 单份国债逆回购价格 1000元 100元 国债逆回购起卖份数 100份 10份 国债逆回购交易门槛 10万元 1000元 国债逆回购的费用和货基不同，投资国债逆回购有手续费，期限越长，相对费用越低，例如： 类别 费用 GC001 1元 GC002 2元 GC007 5元 GC014 10元 国债逆回购的买卖国债逆回购的价格 × 100% = 年化利率 注意：国债逆回购的买卖和其他买卖正好相反：买国债逆回购时要点击卖出卖国债逆回购时要点击买入 收益计算方式： 一天的收益 = 买入金额 × 年化利率 ÷ 一年的天数（沪市360天、深市365天） 国债逆回购历史利率 国债逆回购计息规则2017年5月22日起国债逆回购计息规则已改变计息天数由名义投资天数修改为资金实际占款天数 国债逆回购的缺点国债逆回购没有办法做日内回转交易，也就是说一旦买入国债逆回购，当天是没有办法撤销的，必须持有到期才能使用资金。这就有可能会错过股市最佳买入时机。 因为人人都想在股市下午快要收盘时去购买国债逆回购，所以国债逆回购在每天下午往往走势一路向下，一般下手越晚收益越低。 国债逆回购信息查看方式去集思录官网的现金管理板块查看:https://www.jisilu.cn/data/repo/ 场外货基/场内货基/国债逆回购的对比 债券基金永恒不变的投资三大支柱股票、债券、房产 金融市场中的两种融通方式 债券形式 我把钱借你，我是你的债主，你的生意做得好不好和我无关，就算生意失败，这钱也得还。 股票形式 直接买下公司股权成为股东，生意失败，钱打水漂，生意成功，分到更丰厚的分红。 在理财道路上债券和股票都要有才行。 债券基金分类按照投资期限分类短债基金、中短债基金、长期债券型基金 按能否投资股票分类二级债基：最多可以拿不超过20%资金投资二级市场股票的债基。一级债基：不能在二级市场买股票，但是可以在一级市场打新股的债基，风险比二级债基低得多。纯债基金：绝对不可以碰任何股票的债基（推荐）。转债基金：专门投资可转债市场的转债基金，风险远高于纯债基金和一级债基，和二级债基风险不好比较。 注意：名字里面没有纯债的也可能是纯债基金，名字里面有纯债的也可能还投资了高风险的可转债。 纯债基金的选购发行时间较久，长期回报比较稳健的优秀的纯债基金。 天天基金网首页选择基金排行，选债券型-长期纯债-近3天倒序排序 取排名前30名做候选基金池 每一个点进去查看债券持仓，去除掉投资可转债的基金（存在问题：如何查看债券是否是可转债？），去除掉其中公司名气小的基金 剔除掉基金规模超过20亿的基金 点击基金公司，往下滑，查看该基金公司的基金排名，剔除掉第二名及其以下的所有，只留下该公司王牌纯债基金 最后可以筛选到10只左右基金，点击费率详情，挑出综合费率最低的5只 再在最后5只中选择基金成立时间相对较长的，基金经理任职相对较长时间的3只纯债基金，作为长期投资的基金 ABC类型区分对于债券型基金来说，常见A、B、C后缀，区分收费方式。 分类 说明 特点 适合投资者 A类 通常指前端收费（在购买基金时收取费用，但赎回没有费用） 申购金额越高费率越低 一次性购入较多金额的土豪投资者 B类 通常指后端收费（在基金赎回时才收费） 持有基金时间越长费率越低 有耐心的长情投资者 C类 通常指销售服务费（不收申购费，也不收赎回费） 按日收费 短期持有，对流动性要求较高的投资者 定期开放债基选购注意3点： 选择定开债的纯债基金 别选杠杆率太高的债基（超过160%不推荐） 建议选择封闭期为1年的定开债 债券不建议直接投资债券。直接投资债券劣势： 品种较少，投资门槛较高 流动性较差 投资性价比低 投资过于复杂 分类 交易所债券市场 缺点：和二级市场一样，债券品种少，流动性差 银行间债券市场 缺点：投资起点非常高，具备银行间债券交易资格才可以进行投资 国债尤其是凭证式国债，是定期储蓄的最佳替代品适合中老年人和保守型投资者 纯债基金是国债的最好替代品 基金指标基金分红基金分红和不分红本质上没什么区别，总资产不变。 分红方式： 现金分红（相当于把收益提现） 红利再投资（收益再投资） 累计净值基金最关键指标。 单位净值：分红后的净值。累计净值：算上所有分红收益的累计净值。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"理财","slug":"理财","permalink":"http://blog.hming.org/categories/%E7%90%86%E8%B4%A2/"}],"tags":[{"name":"基金","slug":"基金","permalink":"http://blog.hming.org/tags/%E5%9F%BA%E9%87%91/"},{"name":"笔记","slug":"笔记","permalink":"http://blog.hming.org/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"使用Zookeeper实现HiveServer2的HA","slug":"使用Zookeeper实现HiveServer2的HA","date":"2020-01-16T09:10:18.000Z","updated":"2020-01-16T09:10:18.000Z","comments":true,"path":"2020/01/16/shi-yong-zookeeper-shi-xian-hiveserver2-de-ha/","link":"","permalink":"http://blog.hming.org/2020/01/16/shi-yong-zookeeper-shi-xian-hiveserver2-de-ha/","excerpt":"","text":"本文主要讲述如何使用Zookeeper实现HiveServer2的HA 配置过程修改hive配置登录Cloduera Manager，进入Hive服务，在配置中搜索hive-site.xml，找到hive-site.xml 的 HiveServer2 高级配置代码段（安全阀），增加如下配置（Zookeeper地址修改为当前的地址） &lt;property> &lt;name>hive.server2.support.dynamic.service.discovery&lt;/name> &lt;value>true&lt;/value> &lt;/property> &lt;property> &lt;name>hive.server2.zookeeper.namespace&lt;/name> &lt;value>hiveserver2_zk&lt;/value> &lt;/property> &lt;property> &lt;name>hive.zookeeper.quorum&lt;/name> &lt;value>master1:2181,master2:2181,master3:2181&lt;/value> &lt;/property> &lt;property> &lt;name>hive.zookeeper.client.port&lt;/name> &lt;value>2181&lt;/value> &lt;/property> 修改后点击保存 重启hive服务根据提示重启hive服务 测试是否配置成功查看Zookeeper注册情况用zookeeper-client命令进入zookeeper查看hiveserver2_zk节点下所有HiveServer2节点是否注册成功 [zk: localhost:2181(CONNECTED) 1] ls /hiveserver2_zk [serverUri=master3.segma.tech:10000;version=2.1.1-cdh6.3.0;sequence=0000000001, serverUri=master2.segma.tech:10000;version=2.1.1-cdh6.3.0;sequence=0000000000] 使用连接地址测试连接连接地址格式为： jdbc:hive2://&lt;zookeeper quorum>/&lt;dbName>;ServiceDiscoveryMode=zookeeper;zooKeeperNameSpace=hiveserver2_zk 数据库名可以为空 用beeline测试连接情况： [root@master1 ~]# beeline WARNING: Use \"yarn jar\" to launch YARN applications. SLF4J: Class path contains multiple SLF4J bindings. SLF4J: Found binding in [jar:file:/mnt/disk/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/jars/log4j-slf4j-impl-2.8.2.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: Found binding in [jar:file:/mnt/disk/opt/cloudera/parcels/CDH-6.3.0-1.cdh6.3.0.p0.1279813/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation. SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory] Beeline version 2.1.1-cdh6.3.0 by Apache Hive beeline> !connect jdbc:hive2://master1:2181,master2:2181,master3:2181/default;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2_zk Connecting to jdbc:hive2://master1:2181,master2:2181,master3:2181/default;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2_zk Enter username for jdbc:hive2://master1:2181,master2:2181,master3:2181/default: hvie Enter password for jdbc:hive2://master1:2181,master2:2181,master3:2181/default: 20/01/16 16:02:33 [main]: INFO jdbc.HiveConnection: Connected to master2.segma.tech:10000 Connected to: Apache Hive (version 2.1.1-cdh6.3.0) Driver: Hive JDBC (version 2.1.1-cdh6.3.0) Transaction isolation: TRANSACTION_REPEATABLE_READ 0: jdbc:hive2://master1:2181,master2:2181> show databases; INFO : Compiling command(queryId=hive_20200116160255_735faaf6-18dd-4de0-8a11-6e12aae92dff): show databases INFO : Semantic Analysis Completed INFO : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:database_name, type:string, comment:from deserializer)], properties:null) INFO : Completed compiling command(queryId=hive_20200116160255_735faaf6-18dd-4de0-8a11-6e12aae92dff); Time taken: 1.007 seconds INFO : Executing command(queryId=hive_20200116160255_735faaf6-18dd-4de0-8a11-6e12aae92dff): show databases INFO : Starting task [Stage-0:DDL] in serial mode INFO : Completed executing command(queryId=hive_20200116160255_735faaf6-18dd-4de0-8a11-6e12aae92dff); Time taken: 0.025 seconds INFO : OK +----------------+ | database_name | +----------------+ | default | +----------------+ 1 row selected (1.403 seconds) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"CDH","slug":"CDH","permalink":"http://blog.hming.org/tags/CDH/"},{"name":"Hive","slug":"Hive","permalink":"http://blog.hming.org/tags/Hive/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://blog.hming.org/tags/Zookeeper/"}]},{"title":"hive注释中文乱码问题","slug":"hive注释中文乱码问题","date":"2019-09-26T09:24:40.000Z","updated":"2019-09-26T09:24:40.000Z","comments":true,"path":"2019/09/26/hive-zhu-shi-zhong-wen-luan-ma-wen-ti/","link":"","permalink":"http://blog.hming.org/2019/09/26/hive-zhu-shi-zhong-wen-luan-ma-wen-ti/","excerpt":"","text":"在安装CDH中Hive时，虽然设置了Hive元数据库编码为UTF-8，但是创建Hive表注释依然会有乱码问题，本文介绍乱码原因以及解决方法。 乱码原因查看Hive元数据库（本文为MySQL中metastore），发现虽然数据库编码为UTF-8，但是库下面的表编码却还是latin1，这是因为虽然创建metastore库时指定了编码UTF-8，但是CDH在安装Hive时却还是以latin1编码去创建表的，所以导致Hive表存在中文乱码问题。 解决方法步骤登录MySQL，进入Hive元数据库use metastore; 修改字段注释字符集alter table COLUMNS_V2 modify column COMMENT varchar(256) character set utf8; 修改表注释字符集alter table TABLE_PARAMS modify column PARAM_VALUE varchar(4000) character set utf8; 修改分区参数，支持分区建用中文表示alter table PARTITION_PARAMS modify column PARAM_VALUE varchar(4000) character set utf8; alter table PARTITION_KEYS modify column PKEY_COMMENT varchar(4000) character set utf8; 修改表名注释，支持中文表示alter table INDEX_PARAMS modify column PARAM_VALUE varchar(4000) character set utf8; 修改视图，支持视图中文ALTER TABLE TBLS modify COLUMN VIEW_EXPANDED_TEXT mediumtext CHARACTER SET utf8; ALTER TABLE TBLS modify COLUMN VIEW_ORIGINAL_TEXT mediumtext CHARACTER SET utf8; 修改数据库注释，支持中文表示ALTER TABLE DBS MODIFY COLUMN `DESC` VARCHAR (4000) CHARACTER SET utf8; document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"CDH","slug":"CDH","permalink":"http://blog.hming.org/tags/CDH/"},{"name":"Hive","slug":"Hive","permalink":"http://blog.hming.org/tags/Hive/"},{"name":"乱码","slug":"乱码","permalink":"http://blog.hming.org/tags/%E4%B9%B1%E7%A0%81/"}]},{"title":"Impala配置优化","slug":"Impala配置优化","date":"2019-09-18T02:43:34.000Z","updated":"2020-01-16T11:36:16.000Z","comments":true,"path":"2019/09/18/impala-pei-zhi-you-hua/","link":"","permalink":"http://blog.hming.org/2019/09/18/impala-pei-zhi-you-hua/","excerpt":"","text":"参考官网文档：Impala安装后的推荐配置https://www.cloudera.com/documentation/enterprise/6/6.3/topics/impala_config_performance.html HDFS快速读取启用快速读取允许Impala直接从文件系统读取本地数据。不再需要通过DataNode进行通信，从而提高了性能。cloudera manager进入impala配置页面，搜索dfs.client.read.shortcircuit，勾选后重启。 设置内存限制进入impala配置页面，搜索mem_limit 设置连接超时时间进入impala配置页面，搜索idle_session_timeout 注意：超时时间设置过短可能导致服务端连接关闭而客户端未关闭，可能造成客户端无法使用impala的问题 设置连接数进入impala配置页面，搜索fe_service_threads 使用HDFS缓存参考官网文档：使用Impala时设置HDFS缓存https://www.cloudera.com/documentation/enterprise/6/6.3/topics/impala_perf_hdfs_caching.html#hdfs_caching 配置Impala负载均衡参考官网文档：Using Impala through a Proxy for High Availability参考微信公众hadoop实操文章：如何使用HAProxy实现Impala的负载均衡 Impala timestamp类型时区问题参考微信公众hadoop实操文章：Hive中的Timestamp类型日期与Impala中显示不一致分析（补充） document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"CDH","slug":"CDH","permalink":"http://blog.hming.org/tags/CDH/"},{"name":"Impala","slug":"Impala","permalink":"http://blog.hming.org/tags/Impala/"},{"name":"优化","slug":"优化","permalink":"http://blog.hming.org/tags/%E4%BC%98%E5%8C%96/"}]},{"title":"CDH官网链接整理","slug":"CDH官网链接整理","date":"2019-09-17T11:09:34.000Z","updated":"2019-09-17T11:09:34.000Z","comments":true,"path":"2019/09/17/cdh-guan-wang-lian-jie-zheng-li/","link":"","permalink":"http://blog.hming.org/2019/09/17/cdh-guan-wang-lian-jie-zheng-li/","excerpt":"","text":"安装部署类CDH安装教程https://www.cloudera.com/documentation/enterprise/6/6.3/topics/installation.html CDH、CM安装包下载地址https://docs.cloudera.com/documentation/enterprise/6/release-notes/topics/rg_version_packaging_download.html 集群所使用端口https://www.cloudera.com/documentation/enterprise/6/6.3/topics/cm_ig_ports.html 集群组件服务主机分配建议https://www.cloudera.com/documentation/enterprise/6/6.3/topics/cm_ig_host_allocations.html 定制化安装（离线安装）https://www.cloudera.com/documentation/enterprise/6/6.3/topics/cm_ig_custom_installation.html 基于裸金属部署参考文档https://www.cloudera.com/documentation/other/reference-architecture/topics/ra_bare_metal_deployment.html CHD各组件服务依赖项https://www.cloudera.com/documentation/enterprise/6/6.3/topics/cm_ig_service_dependencies.html Cloudera Manager相关Cloudera Manager APIhttps://www.cloudera.com/documentation/enterprise/6/6.3/topics/cm_intro_api.html Cloudera Manager常见问题（FAQ）https://www.cloudera.com/documentation/enterprise/6/6.3/topics/cm_faqs.html Impala相关Impala内存和查询数据量的关系https://www.cloudera.com/documentation/enterprise/6/6.3/topics/impala_faq.html#faq_internals__faq_memory_exceeded？ Impala常见问题及解答https://www.cloudera.com/documentation/enterprise/6/6.3/topics/impala_faq.html 使用Impala时设置HDFS缓存https://www.cloudera.com/documentation/enterprise/6/6.3/topics/impala_perf_hdfs_caching.html#hdfs_caching Impala安装后的推荐配置https://www.cloudera.com/documentation/enterprise/6/6.3/topics/impala_config_performance.html Impala安装要求https://www.cloudera.com/documentation/enterprise/6/6.3/topics/impala_prereqs.html Impala元数据管理(自动同步Hive元数据)https://www.cloudera.com/documentation/enterprise/6/6.3/topics/impala_metadata.html Impala中SQL和HQL的区别https://docs.cloudera.com/documentation/enterprise/latest/topics/impala_langref_unsupported.html Impala聚合函数https://docs.cloudera.com/documentation/enterprise/latest/topics/impala_aggregate_functions.html#aggregate_functions Impala分析函数https://docs.cloudera.com/documentation/enterprise/latest/topics/impala_analytic_functions.html#analytic_functions 从其他数据库迁移Sql到Impala注意事项https://docs.cloudera.com/documentation/enterprise/latest/topics/impala_porting.html#porting document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"CDH","slug":"CDH","permalink":"http://blog.hming.org/tags/CDH/"},{"name":"官网链接","slug":"官网链接","permalink":"http://blog.hming.org/tags/%E5%AE%98%E7%BD%91%E9%93%BE%E6%8E%A5/"}]},{"title":"Impala配置自动同步Hive元数据","slug":"Impala配置自动同步Hive元数据","date":"2019-09-10T07:12:15.000Z","updated":"2020-01-16T11:36:08.000Z","comments":true,"path":"2019/09/10/impala-pei-zhi-zi-dong-tong-bu-hive-yuan-shu-ju/","link":"","permalink":"http://blog.hming.org/2019/09/10/impala-pei-zhi-zi-dong-tong-bu-hive-yuan-shu-ju/","excerpt":"","text":"参考官方文档：Automatic Invalidation/Refresh of Metadata 原理解释Impala使用Catalog服务进行元数据的管理，Catalog使用StateStore进行元数据同步分发到各个Impalad服务。Impala使用两个元数据： 来自Hive Metastore的目录信息 来自NameNode的文件元数据。 在通过非Impala操作修改数据时（如：Hive操作、Spark操作Hive、HDFS直接操作表文件等），Impala是无感知的，此时需要在Impala端进行手动刷新元数据，手动刷新有两种方式: REFRESH INVALIDATE METADATA 问题描述由于全局刷新invalidate metadata语句会丢弃所有的元数据，导致没有更新的表再次查询也会去拉取元数据（造成延迟），所以不能采用这种方式（官网不推荐）。所以只能使用invalidate metadata [表名]或者refresh [表名]的方式。但是这样会有一个问题，需要知道表名， 配置步骤impala配置修改 查看impala catalog server web UI/metricsevents发现只有一个events-processor.status为DISABLED 在impala配置中找 Catalog Server 命令行参数高级配置代码段（安全阀）加入一下代码 （短横线中间不能有空格）： --hms_event_polling_interval_s=1 此时直接重启impala会报错，先修改hive配置 hive配置修改进入hive配置页面 勾选 启用数据库中的存储通知 在搜索框输入hive-site.xml在 hive-site.xml 的 Hive Metastore Server 高级配置代码段（安全阀） 中添加两个值 &lt;property> &lt;name>hive.metastore.notifications.add.thrift.objects&lt;/name> &lt;value>true&lt;/value> &lt;description>set auto invalidate metadata on hive events&lt;/description> &lt;/property> &lt;property> &lt;name>hive.metastore.alter.notifications.basic&lt;/name> &lt;value>false&lt;/value> &lt;description>set auto invalidate metadata on hive events&lt;/description> &lt;/property> 在 hive-site.xml 的 Hive 服务高级配置代码段（安全阀） 中添加 &lt;property> &lt;name>hive.metastore.dml.events&lt;/name> &lt;value>true&lt;/value> &lt;description>set auto invalidate metadata on hive events&lt;/description> &lt;/property> 在 hive-site.xml 的 Hive 客户端高级配置代码段（安全阀） 中添加 &lt;property> &lt;name>hive.metastore.dml.events&lt;/name> &lt;value>true&lt;/value> &lt;description>set auto invalidate metadata on hive events&lt;/description> &lt;/property> 剩余的坑官方文档里面说insert操作触发的是refresh，但是据实际测试情况来看，触发的是invalidate metadata [table]，两者的区别在于refresh几乎没有延迟，而invalidate metadata [table]下次进行查询时impala会去拉取元数据信息，会有延迟。 经过官方人员确认，表示insert确实是invalidate的效果，回复原话如下： 这个功能现在还比较粗暴，这块确实还是invalidate的效果……因为insert非partition表的时候hive发出来的是一个alter事件后接一个insert事件，接到alter事件后就执行invalidate了；insert partition的时候hive发出来的是一个insert事件后接一个alter事件，于是最终又会执行一次invalidate…… document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"CDH","slug":"CDH","permalink":"http://blog.hming.org/tags/CDH/"},{"name":"Impala","slug":"Impala","permalink":"http://blog.hming.org/tags/Impala/"},{"name":"元数据","slug":"元数据","permalink":"http://blog.hming.org/tags/%E5%85%83%E6%95%B0%E6%8D%AE/"}]},{"title":"CDH集群Yarn内存调优","slug":"CDH集群Yarn内存调优","date":"2019-08-30T01:13:32.000Z","updated":"2019-08-30T01:13:32.000Z","comments":true,"path":"2019/08/30/cdh-ji-qun-yarn-nei-cun-diao-you/","link":"","permalink":"http://blog.hming.org/2019/08/30/cdh-ji-qun-yarn-nei-cun-diao-you/","excerpt":"","text":"HDP的内存调优建议：http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.1.1/bk_installing_manually_book/content/rpm-chap1-11.html DRFDRF: Dominant Resource Fairness，根据CPU和内存公平调度资源。CDH动态资源池默认采用的DRF计划策略。简单的理解就是内存不够的时候，多余的CPU就不会分配任务了，就让他空着；CPU不够的时候，多出来的内存也不会再启动任务了。 相关参数RM的内存资源配置, 配置的是资源调度相关 RM1：yarn.app.mapreduce.am.resource.mb， ApplicationMaster自身的物理内存要求 RM2：yarn.scheduler.minimum-allocation-mb，分配给AM单个容器可申请的最小内存，如果申请的容器内存小于该值，则系统将调整至该值 RM3：yarn.scheduler.maximum-allocation-mb，分配给AM单个容器可申请的最大内存 上面三个值均不能超过NM1值由于AM也是容器，所以RM1的值需要在RM2、RM3范围内。 NM的内存资源配置，配置的是硬件资源相关 NM1：yarn.nodemanager.resource.memory-mb ，NodeManager节点分配给容器的内存，cdh默认8G NM2：yarn.nodemanager.resource.cpu-vcores ，NodeManager节点分配给容器虚拟CPU核数，cdh默认8，但CM会自动检测内核数并修改 NM1可以计算节点最大最大Container数量，max(Container)=NM1/RM2 AM内存配置相关参数，配置的是任务相关 AM1：mapreduce.map.memory.mb ，map任务内存，cdh默认1G（不能超过容器最大内存限制） AM2：mapreduce.map.cpu.vcores ，map任务虚拟CPU核数，cdh默认1 AM3：mapreduce.reduce.memory.mb ，reduce任务内存，cdh默认1G（不能超过容器最大内存限制） AM4：mapreduce.reduce.cpu.vcores ，reduce任务虚拟CPU核数，cdh默认1 AM1、AM3这两个值应该在RM2和RM3这两个值之间AM3的值最好为AM1的两倍 测试情况Yarn资源分配情况，虚拟CPU共分配了24核，内存则是他的两倍48G 执行任务，队列调度策略为DRF，查看内存和CPU使用情况可以发现，内存使用受限于cpu，与DRF策略吻合 总结Yarn队列如果采用的是DRF调度策略，则vcpu和内存最好按照1:1比例进行分配，因为多余的资源根本不会用到。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"CDH","slug":"CDH","permalink":"http://blog.hming.org/tags/CDH/"},{"name":"Yarn","slug":"Yarn","permalink":"http://blog.hming.org/tags/Yarn/"},{"name":"参数调优","slug":"参数调优","permalink":"http://blog.hming.org/tags/%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98/"}]},{"title":"如何给CDH集群分配角色","slug":"如何给CDH集群分配角色","date":"2019-08-27T05:57:27.000Z","updated":"2019-08-27T05:57:27.000Z","comments":true,"path":"2019/08/27/ru-he-gei-cdh-ji-qun-fen-pei-jiao-se/","link":"","permalink":"http://blog.hming.org/2019/08/27/ru-he-gei-cdh-ji-qun-fen-pei-jiao-se/","excerpt":"","text":"本文转载自微信公众号Hadoop实操：《如何给Hadoop集群划分角色》 参考官网：Recommended Cluster Hosts and Role Distribution 1.文档编写目的Fayson在之前的文章中介绍过《CDH网络要求(Lenovo参考架构)》，《如何为Hadoop集群选择正确的硬件》和《CDH安装前置准备》，而我们在搭建Hadoop集群时，还一件很重要的事就是如何给集群分配角色。 本文主要介绍由Cloudera Manager管理的CDH集群的角色划分。实际部署你可能还需要考虑工作负载的类型和数量，真实要部署的哪些服务，硬件资源，配置，以及其他因素。当你使用Cloudera Manager的安装向导来安装CDH时，CM会根据主机的可用资源，自动的分配角色到各台主机，边缘节点除外。你可以在向导中使用”自定义角色分配 - Customize Role Assignments”来更改这些默认划分，当然你也可以以后再使用Cloudera Manager来增加或修改角色分配。 在介绍角色划分时，我们首先来看看有哪几种主要的角色： 1.管理节点（Master Hosts）：主要用于运行Hadoop的管理进程，比如HDFS的NameNode，YARN的ResourceManager。 2.工具节点（Utility Hosts）:主要用于运行非管理进程的其他进程，比如Cloudera Manager和Hive Metastore。 3.边缘节点（Edge Hosts）：用于集群中启动作业的客户端机器，边缘节点的数量取决于工作负载的类型和数量。 4.工作节点（Worker Hosts）：主要用于运行DataNode以及其他分布式进程，比如ImpalaD。 本文会从测试/开发集群（小于10台），小规模集群（10-20台），中小规模集群（20-50台），中等规模集群（50-100台），大型集群（100-200台），超大规模集群（200-500台），巨型规模集群（500台以上）来分别讲述角色划分。以下角色划分场景都不包括Kafka，Kafka角色我们一般都会采用单独的机器部署。 2.集群角色划分2.1.小于10台一般用于测试/开发集群，我们建议至少5台机器，没有高可用。一个管理节点主要用于安装NameNode和ResourceManager，工具节点和边缘节点复用一个，主要用于安装Cloudera Manager等，剩余3-7台工作节点。 2.2.10-20台这是最小规模的生产系统，必须启用高可用。我们会用2个管理节点用于安装2个NameNode，一个工具节点用于安装Cloudera Manager等，如果机器充足或者Hue/HiveServer2/Flume的负载特别高，可以考虑独立出边缘节点用于部署这些角色，否则也可以跟Cloudera Manager复用。最后还剩下7-17个工作节点。 注：根据实际情况选择是否需要单独的边缘节点。 MySQL主备参考《如何实现CDH元数据库MySQL的主备》，《如何实现CDH元数据库MySQL的主主互备》和《如何实现CDH元数据库MySQL的高可用》 OpenLDAP主备参考《3.如何实现OpenLDAP的主主同步》 Kerberos主备参考《如何配置Kerberos服务的高可用》 2.3.20-50台这是中小规模的生产集群，必须启用高可用，与小规模集群角色划分差别不大。我们会用3个管理节点用于安装NameNode和Zookeeper等，一个工具节点用于安装ClouderaManager等，如果机器充足或者Hue/HiveServer2/Flume的负载特别高，可以考虑独立出边缘节点用于部署这些角色，否则也可以跟Cloudera Manager复用。最后还剩下16-46个工作节点。 注：根据实际情况选择是否需要单独的边缘节点。 Zookeeper和JournalNode需配置专有的数据盘 MySQL主备参考《如何实现CDH元数据库MySQL的主备》，《如何实现CDH元数据库MySQL的主主互备》和《如何实现CDH元数据库MySQL的高可用》 OpenLDAP主备参考《3.如何实现OpenLDAP的主主同步》 Kerberos主备参考《如何配置Kerberos服务的高可用》 HiveServer2和Impala Daemon的负载均衡参考《如何使用HAProxy实现Impala的负载均衡》，《如何使用HAProxy实现HiveServer2负载均衡》，《如何使用HAProxy实现Kerberos环境下的Impala负载均衡》，《如何使用Nginx实现Impala负载均衡》和《如何使用Zookeeper实现HiveServer2的HA》 2.4.50-100台这是中等规模的生产集群，必须启用高可用。我们会用3个管理节点用于安装NameNode和Zookeeper等，一个工具节点用于安装Cloudera Manager，一个工具节点用于安装ClouderaManagement Service和Navigator等。使用三个节点安装Hue/HiveServer2/Flume，作为边缘节点，使用两个节点安装负载均衡软件比如F5或者HAProxy并配置为KeepAlive的主主模式，该负载均衡可同时用于HiveServer2和Impala Daemon。最后还剩下42-92个工作节点。 注：Zookeeper和JournalNode需配置专有的数据盘 MySQL主备参考《如何实现CDH元数据库MySQL的主备》，《如何实现CDH元数据库MySQL的主主互备》和《如何实现CDH元数据库MySQL的高可用》 OpenLDAP主备参考《3.如何实现OpenLDAP的主主同步》 Kerberos主备参考《如何配置Kerberos服务的高可用》 HiveServer2和Impala Daemon的负载均衡参考《如何使用HAProxy实现Impala的负载均衡》，《如何使用HAProxy实现HiveServer2负载均衡》，《如何使用HAProxy实现Kerberos环境下的Impala负载均衡》，《如何使用Nginx实现Impala负载均衡》和《如何使用Zookeeper实现HiveServer2的HA》 2.5.100-200台属于大规模的生产集群，必须启用高可用。我们会用5个管理节点用于安装NameNode和Zookeeper等，1个工具节点用于安装Cloudera Manager，再使用4个工具节点分别安装HMS，Activity Monitor，Navigator等。使用3个以上节点安装Hue/HiveServer2/Flume，作为边缘节点，使用2个节点安装负载均衡软件比如F5或者HAProxy并配置为KeepAlive的主主模式，该负载均衡可同时用于HiveServer2和Impala Daemon。最后还剩下85-185个工作节点。 注：Zookeeper和JournalNode需配置专有的数据盘 Kudu Master不超过3个 Kudu Tablet Server不超过100个 MySQL主备参考《如何实现CDH元数据库MySQL的主备》，《如何实现CDH元数据库MySQL的主主互备》和《如何实现CDH元数据库MySQL的高可用》 OpenLDAP主备参考《3.如何实现OpenLDAP的主主同步》 Kerberos主备参考《如何配置Kerberos服务的高可用》 HiveServer2和Impala Daemon的负载均衡参考《如何使用HAProxy实现Impala的负载均衡》，《如何使用HAProxy实现HiveServer2负载均衡》，《如何使用HAProxy实现Kerberos环境下的Impala负载均衡》，《如何使用Nginx实现Impala负载均衡》和《如何使用Zookeeper实现HiveServer2的HA》 2.6.200-500台属于超大规模的生产集群，必须启用高可用。我们会用7个管理节点用于安装NameNode和Zookeeper等，1个工具节点用于安装Cloudera Manager，再使用7个工具节点分别安装HMS，Activity Monitor，Navigator等。使用3个以上节点安装Hue/HiveServer2/Flume，作为边缘节点，使用2个节点安装负载均衡软件比如F5或者HAProxy并配置为KeepAlive的主主模式，该负载均衡可同时用于HiveServer2和Impala Daemon。最后还剩下180-480个工作节点。 注：Zookeeper和JournalNode需配置专有的数据盘 Kudu Master不超过3个 Kudu Tablet Server不超过100个 MySQL主备参考《如何实现CDH元数据库MySQL的主备》，《如何实现CDH元数据库MySQL的主主互备》和《如何实现CDH元数据库MySQL的高可用》 OpenLDAP主备参考《3.如何实现OpenLDAP的主主同步》 Kerberos主备参考《如何配置Kerberos服务的高可用》 HiveServer2和Impala Daemon的负载均衡参考《如何使用HAProxy实现Impala的负载均衡》，《如何使用HAProxy实现HiveServer2负载均衡》，《如何使用HAProxy实现Kerberos环境下的Impala负载均衡》，《如何使用Nginx实现Impala负载均衡》和《如何使用Zookeeper实现HiveServer2的HA》 2.7.500台以上属于巨型规模的生产集群，必须启用高可用。我们会用20个管理节点用于安装NameNode和Zookeeper等，1个工具节点用于安装Cloudera Manager，再使用7个工具节点分别安装HMS，Activity Monitor，Navigator等。使用3个以上节点安装Hue/HiveServer2/Flume，作为边缘节点，使用2个节点安装负载均衡软件比如F5或者HAProxy并配置为KeepAlive的主主模式，该负载均衡可同时用于HiveServer2和Impala Daemon。最后还剩下至少467个工作节点。 注：这个规模的规划仅供参考，这种巨型规模的生产集群的角色划分依赖因素非常多，比如是否考虑NN和RM的联邦等 Zookeeper和JournalNode需配置专有的数据盘 Kudu Master不超过3个 Kudu Tablet Server不超过100个 MySQL主备参考《如何实现CDH元数据库MySQL的主备》，《如何实现CDH元数据库MySQL的主主互备》和《如何实现CDH元数据库MySQL的高可用》 OpenLDAP主备参考《3.如何实现OpenLDAP的主主同步》 Kerberos主备参考《如何配置Kerberos服务的高可用》 HiveServer2和Impala Daemon的负载均衡参考《如何使用HAProxy实现Impala的负载均衡》，《如何使用HAProxy实现HiveServer2负载均衡》，《如何使用HAProxy实现Kerberos环境下的Impala负载均衡》，《如何使用Nginx实现Impala负载均衡》和《如何使用Zookeeper实现HiveServer2的HA》 如果你玩的Hadoop集群节点数不在本文范围内，那你肯定不是在玩大数据，或者超过了Fayson的能力范围。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"CDH","slug":"CDH","permalink":"http://blog.hming.org/tags/CDH/"},{"name":"角色分配","slug":"角色分配","permalink":"http://blog.hming.org/tags/%E8%A7%92%E8%89%B2%E5%88%86%E9%85%8D/"}]},{"title":"CentOS7离线安装CDH","slug":"CentOS7离线安装CDH","date":"2019-08-16T07:03:41.000Z","updated":"2020-03-11T03:04:27.000Z","comments":true,"path":"2019/08/16/centos7-chi-xian-an-zhuang-cdh/","link":"","permalink":"http://blog.hming.org/2019/08/16/centos7-chi-xian-an-zhuang-cdh/","excerpt":"","text":"环境准备部分参考文章：Hadoop实操：CDH安装前置准备 本文环境 节点 IP地址 master1.hming.org 172.16.0.2 master2.hming.org 172.16.0.5 master3.hming.org 172.16.0.6 node1.hming.org 172.16.0.12 node2.hming.org 172.16.0.13 node3.hming.org 172.16.0.15 服务器配置：CPU：16核内存：64G磁盘：管理节点外挂一块2T HDD到/mnt/data01目录，工作节点挂载三块2T HDD到/mnt/data01-03目录 组件角色分配规划表：附：官方服务角色分配方案 环境准备节点数量 最小规模，建议最小4台服务器，1个管理节点安装Cloudera Manager和NameNode等服务，其他3个作为工作节点，因为没有任何的高可用，所以该规模只能用于开发测试。 建议规模，生产环境中建议最小6台服务器，3台管理节点+3台工作节点，1个管理节点安装Cloudera Manager，另外2个安装NameNode高可用，常见的较小规模生产系统一般为10-20台服务器。 硬件要求以下Cloudera Manager，NameNode和DataNode相同： CPU：最少4 cores，推荐2路8核，2路10核，2路12核内存：最小16GB，推荐128GB-256GB网络：最小千兆，推荐两张万兆绑定磁盘：系统盘参考下面系统盘/目录分配要求章节，数据盘，工作节点推荐12块1TB-4TB的SATA/SAS盘，管理节点推荐1-2块1TB-4TB的SATA/SAS盘（具体配置可根据实际情况而定） 附：官方硬件要求说明 系统盘/目录分配要求目录分配方案一：如果只有一个根目录/建议工作节点最少100G，管理节点因为会存放MySQL数据以及一些监控数据，可以选择200G以上 目录分配方案二： 目录 分配空间 / 可以默认比如10GB /opt 大于50GB /usr 大于50GB /var 大于20GB /var/log 大于50GB /var/lib 大于50GB /tmp 大于20GB 目录分配方案三： 目录 分配空间 / 可以默认比如10GB /opt 大于50GB /usr 大于50GB /var 大于50GB /tmp 大于20GB 磁盘要求 磁盘阵列要求：工作节点（DataNode/NodeManager），系统盘可以使用RAID1或者RAID10，数据盘不要使用RAID，应该为JBOD。管理节点（NameNode，Zookeeper，JournalNode），可以使用RAID或者JBOD，因为管理节点对I/O延迟比较敏感，建议将NN，ZK，JN存放数据的目录配置为不同的目录，并且对应到不同的磁盘。 DataNode数据盘格式建议选择ext4或xfs，并配置noatime，比如： [root@cdh ~]# cat /etc/fstab /dev/sda1 /data/1 xfs defaults,noatime 1 2 /dev/sdb1 /data/2 xfs defaults,noatime 1 2 /dev/sdc1 /data/3 xfs defaults,noatime 1 2 /dev/sdd1 /data/4 xfs defaults,noatime 1 2 /dev/sde1 /data/5 xfs defaults,noatime 1 2 /dev/sdf1 /data/6 xfs defaults,noatime 1 2 ... /dev/sdx1 /data/x xfs defaults,noatime 1 2 [root@cdh ~]# fdisk -l 注意: noatime已经包含了nodiratime。不需要同时指定。 参考：fstab atime 参数what is noatime默认的方式下linux会把文件访问的时间atime做记录，文件系统在文件被访问、创建、修改等的时候记录下了文件的一些时间戳，比如：文件创建时间、最近一次修改时间和最近一次访问时间；这在绝大部分的场合都是没有必要的。因为系统运行的时候要访问大量文件，如果能减少一些动作（比如减少时间戳的记录次数等）将会显著提高磁盘 IO 的效率、提升文件系统的性能。 DataNode数据盘确保没有配置分区卷LogicalVolume Manager (LVM) [root@cdh ~]# df –h [root@cdh ~]# lsblk [root@cdh ~]# lvdisplay Additionally, look for/dev/mapper or /dev/XX (where XX isnot sd). 确保BIOS配置正确，比如你如果使用的是SATA，请确保没有开启IDE emulation。 确保controller firmware是最新的，校验磁盘是否有一些潜在的问题。 [root@cdh ~]# dmesg | egrep -i 'sense error' [root@cdh ~]# dmesg | egrep -i 'ata bus error' 目前常见的SATA读写速度大概在150MB/S-180MB/S，SAS或者SSD会更快，如果磁盘读写速度小于70MB/S，肯定是有问题的，需要检查硬件。以下为测试读写的命令，这里我们将/mnt/data01挂载到/dev/sdb1： hdparm仅用于Linux系统。现在主要用来测试SSD固态硬盘读取速度。 [root@cdh ~]# hdparm -t --direct /dev/sdb1 /dev/sdb1: Timing O_DIRECT disk reads: 456 MB in 3.01 seconds = 151.67 MB/sec dd命令不是专业测试磁盘工具，它没考虑到缓存和物理读的区分，测试的结果仅作参考，不算权威。但是它通用于所有的Linux系统中。 两个特殊设备：（不产生IO，就能单独测试写速度和读速度） /dev/null 伪设备,回收站.写该文件不会产生IO /dev/zero 伪设备,会产生空字符流,对它不会产生IO 测试写入速度 [root@cdh ~]# dd bs=1M count=1024 if=/dev/zero of=/mnt/data01/test.dbf oflag=direct conv=fdatasync 1024+0 records in 1024+0 records out 1073741824 bytes (1.1 GB) copied, 7.05097 s, 152 MB/s 测试读取速度 [root@cdh ~]# dd bs=1M count=1024 of=/dev/null if=/mnt/data01/test.dbf iflag=direct conv=fdatasync dd: fsync failed for ‘/dev/null’: Invalid argument 1024+0 records in 1024+0 records out 1073741824 bytes (1.1 GB) copied, 6.77791 s, 158 MB/s 测试读写速度 [root@node10 ~]# dd if=/mnt/data01/test.dbf of=/mnt/data01/test_w.dbf bs=8k count=300000 131072+0 records in 131072+0 records out 1073741824 bytes (1.1 GB) copied, 7.39375 s, 145 MB/s 确保磁盘没有坏的扇区： [root@cdh ~]# badblocks -v /dev/sda1 [root@cdh ~]# badblocks -v /dev/sdb1 ... [root@cdh ~]# badblocks -v /dev/sdx1 安装用户可以使用root用户安装，或者具有sudo权限的其他用户 网络要求IPV4设置CDH支持IPV4，不支持IPV6，确保没有开启IPV6 [root@cdh ~]# lsmod | grep ipv6 [root@cdh ~]# 修改/etc/sysctl.conf文件添加一下内容禁用IPV6 #disable ipv6 net.ipv6.conf.all.disable_ipv6= 1 net.ipv6.conf.default.disable_ipv6= 1 net.ipv6.conf.lo.disable_ipv6= 1 如果是RHEL/CentOS，可以把以下内容补充到/etc/sysconfig/network NETWORKING_IPV6=no IPV6INIT=no 网络带宽测试使用iperf3进行网络带宽测试，两台服务器进行网络测试，一台当做服务端（master2）另一台做客户端（master1）。 服务端和客户端均安装iperf3 yum -y install iperf3 服务端master2启动iperf3服务 [root@master2 ~]# iperf3 -s ----------------------------------------------------------- Server listening on 5201 ----------------------------------------------------------- 客户端master1进行请求，连接服务端 [root@master1 ~]# iperf3 -c master2 Connecting to host master2, port 5201 [ 4] local 172.16.0.2 port 50472 connected to 172.16.0.5 port 5201 [ ID] Interval Transfer Bandwidth Retr Cwnd [ 4] 0.00-1.00 sec 123 MBytes 1.03 Gbits/sec 0 1.40 MBytes [ 4] 1.00-2.00 sec 120 MBytes 1.01 Gbits/sec 0 2.63 MBytes [ 4] 2.00-3.00 sec 119 MBytes 996 Mbits/sec 0 2.96 MBytes [ 4] 3.00-4.00 sec 120 MBytes 1.01 Gbits/sec 0 3.00 MBytes [ 4] 4.00-5.00 sec 119 MBytes 996 Mbits/sec 0 3.00 MBytes [ 4] 5.00-6.00 sec 120 MBytes 1.01 Gbits/sec 0 3.00 MBytes [ 4] 6.00-7.00 sec 120 MBytes 1.01 Gbits/sec 0 3.00 MBytes [ 4] 7.00-8.00 sec 119 MBytes 996 Mbits/sec 0 3.00 MBytes [ 4] 8.00-9.00 sec 120 MBytes 1.01 Gbits/sec 0 3.00 MBytes [ 4] 9.00-10.00 sec 119 MBytes 996 Mbits/sec 1 3.00 MBytes - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bandwidth Retr [ 4] 0.00-10.00 sec 1.17 GBytes 1.00 Gbits/sec 1 sender [ 4] 0.00-10.00 sec 1.17 GBytes 1.00 Gbits/sec receiver iperf Done. 可以看出千兆网卡网络带宽在1.00 Gbits/sec左右 主机名配置 将主机名设置为全限定域名格式FQDN（Fully Qualified Domain Name）sudo hostnamectl set-hostname master1.hming.org 配置/etc/hosts文件，添加集群中所有全限定域名，也可以在后面继续添加非限定名 172.16.0.2 master1.hming.org master1 172.16.0.5 master2.hming.org master2 172.16.0.6 master3.hming.org master3 172.16.0.12 node1.hming.org node1 172.16.0.13 node2.hming.org node2 172.16.0.15 node3.hming.org node3 配置免密登录（可选）如果所有主机节点root用户密码相同，则可以不用配置配置免密码登录教程请点击这里 关闭防火墙查看防火墙状态firewall-cmd --state或systemctl status firewalld临时关闭防火墙systemctl stop firewalld禁止开机启动systemctl disable firewalld 设置SELinux模式不关闭可能导致Apache http服务无法访问。 查看SELinux状态：getenforce如果是Permissive或者Disabled则可以继续安装，如果显示enforcing，则需要进行以下步骤修改模式 编辑/etc/selinux/config文件 修改SELINUX=enforcing行内容为SELINUX=permissive或者SELINUX=disabled 重启系统或者运行setenforce 0命令禁用SELinux 设置SWAP参考官网：https://www.cloudera.com/documentation/enterprise/latest/topics/cdh_admin_performance.html#cdh_performance__section_xpq_sdf_jq运行命令sysctl -w vm.swappiness=1临时生效或者修改/etc/sysctl.conf配置文件，增加如下配置，永久生效 # 配置为1时表示当内存使用超过99时，才使用交换空间，这里可以配置为1-10 vm.swappiness = 1 检查是否生效 [root@cdh ~]# cat /proc/sys/vm/swappiness 1 关闭透明大页面参考官网：https://www.cloudera.com/documentation/enterprise/latest/topics/cdh_admin_performance.html#cdh_performance__section_hw3_sdf_jq查看透明大页面配置，发现目前为开启状态always [root@cdh ~]# cat /sys/kernel/mm/transparent_hugepage/defrag [always] madvise never [root@cdh ~]# cat /sys/kernel/mm/transparent_hugepage/enabled [always] madvise never 执行命令关闭透明大页面，使其立即生效 [root@cdh ~]# echo never > /sys/kernel/mm/transparent_hugepage/enabled [root@cdh ~]# echo never > /sys/kernel/mm/transparent_hugepage/defrag 再次查看，确认已经修改为never [root@cdh ~]# cat /sys/kernel/mm/transparent_hugepage/enabled always madvise [never] [root@cdh ~]# cat /sys/kernel/mm/transparent_hugepage/defrag always madvise [never] 在/etc/rc.d/rc.local脚本文件中添加以下代码，使其永久生效 if test -f /sys/kernel/mm/transparent_hugepage/enabled; then echo never > /sys/kernel/mm/transparent_hugepage/enabled fi if test -f /sys/kernel/mm/transparent_hugepage/defrag; then echo never > /sys/kernel/mm/transparent_hugepage/defrag fi 赋予rc.local脚本可执行权限 [root@cdh ~]# chmod +x /etc/rc.d/rc.local 配置NTP服务（时钟同步）参考官网：https://www.cloudera.com/documentation/enterprise/6/6.3/topics/install_cdh_enable_ntp.html参考其他文章：https://blog.csdn.net/u010003835/article/details/84962098集群中所有主机必须保持时间同步，如果时间相差较大会引起各种问题，如果企业有自己的NTP Server则可以集群中所有节点可配置企业NTP Server，如果没有自己的NTP服务器则在集群中选用一台服务器作为NTP Server，其它服务器与其保持同步 本文在master1上安装NTP服务，其他节点和master1节点同步 1.所有节点安装ntp服务yum -y install ntp 2.修改配置文件vim /etc/ntp.conf 所有主机在restrict附近增加下面两行 restrict 172.16.0.3 nomodify notrap nopeer noquery # ip地址为本机主机ip restrict 172.16.0.1 mask 255.255.255.0 nomodify notrap # 网关地址和子网掩码 restrict 127.0.0.1 # 原本文件中的两行不要删 restrict ::1 作为NTP服务的节点（master1节点）注释所有server行，增加下面两行 #server 0.centos.pool.ntp.org iburst #server 1.centos.pool.ntp.org iburst #server 2.centos.pool.ntp.org iburst #server 3.centos.pool.ntp.org iburst server 127.127.1.0 # 这里如果有已经存在的NTP服务，则可以填写相应地址 Fudge 127.127.1.0 stratum 10 其他节点注释所有server行，增加下面两行 #server 0.centos.pool.ntp.org iburst #server 1.centos.pool.ntp.org iburst #server 2.centos.pool.ntp.org iburst #server 3.centos.pool.ntp.org iburst server 172.16.0.2 # 将时钟同步服务器地址指向master1的地址 Fudge 172.16.0.2 stratum 10 3.所有节点启动ntp服务systemctl start ntpd systemctl enable ntpd 4.查看服务状态[root@master1 ~]# systemctl status ntpd ● ntpd.service - Network Time Service Loaded: loaded (/usr/lib/systemd/system/ntpd.service; enabled; vendor preset: disabled) Active: active (running) since Tue 2019-09-03 06:58:01 EDT; 29s ago Process: 33823 ExecStart=/usr/sbin/ntpd -u ntp:ntp $OPTIONS (code=exited, status=0/SUCCESS) Main PID: 33824 (ntpd) CGroup: /system.slice/ntpd.service └─33824 /usr/sbin/ntpd -u ntp:ntp -g Sep 03 06:58:01 master1.hming.org ntpd[33824]: Listen and drop on... Sep 03 06:58:01 master1.hming.org ntpd[33824]: Listen normally on... Sep 03 06:58:01 master1.hming.org ntpd[33824]: Listen normally on... Sep 03 06:58:01 master1.hming.org ntpd[33824]: Listen normally on... Sep 03 06:58:01 master1.hming.org ntpd[33824]: Listen normally on... Sep 03 06:58:01 master1.hming.org ntpd[33824]: Listening on routi... Sep 03 06:58:01 master1.hming.org ntpd[33824]: 0.0.0.0 c016 06 re... Sep 03 06:58:01 master1.hming.org ntpd[33824]: 0.0.0.0 c012 02 fr... Sep 03 06:58:01 master1.hming.org ntpd[33824]: 0.0.0.0 c011 01 fr... Sep 03 06:58:02 master1.hming.org ntpd[33824]: 0.0.0.0 c514 04 fr... Hint: Some lines were ellipsized, use -l to show in full. 5.查看服务状态master1节点 [root@master1 ~]# ntpstat synchronised to local net at stratum 6 time correct to within 11 ms polling server every 64 s 其他节点 [root@master2 ~]# ntpstat synchronised to NTP server (172.16.0.2) at stratum 7 time correct to within 17 ms polling server every 64 s 查看状态时有可能遇到以下情况： [root@node8 ~]# ntpstat unsynchronised time server re-starting polling server every 8 s 这种情况属于正常情况，ntp服务器配置完毕后，需要等待5-10分钟才能与/etc/ntp.conf中配置的标准时间进行同步。等一段时间之后，再次使用ntpstat命令查看状态，就会变成正常结果 master1节点 [root@master1 ~]# ntpq -p remote refid st t when poll reach delay offset jitter ============================================================================== *LOCAL(0) .LOCL. 5 l 9 64 377 0.000 0.000 0.000 其他节点 [root@master2 ~]# ntpq -p remote refid st t when poll reach delay offset jitter ============================================================================== *master1.hming.org LOCAL(0) 6 u 31 64 377 0.160 -3.417 1.363 6.注意事项安装集群完成后可能会报错： 不良 : 无法找到主机的 NTP 服务，或该服务未响应时钟偏差请求。 因为Centos7.2之后默认使用chrony来进行时钟同步，所以如果系统中安装有chrony或者正在运行，要么把ntp换成chrony，要么彻底删除chrony [root@master1 ~]# yum -y remove chrony 下载离线包官网下载地址合集（当其他地址失效时尝试通过该链接找到最新下载地址）：https://docs.cloudera.com/documentation/enterprise/6/release-notes/topics/rg_version_packaging_download.html Cloudera Manager安装包到官网下载rpm包：https://archive.cloudera.com/cm6/6.3.0/redhat7/yum/RPMS/x86_64/下载allkeys文件：https://archive.cloudera.com/cm6/6.3.0/ CDH安装包官方有两种离线包可供选择： Parcel模式（推荐）（本文使用模式） Package模式到官网下载parcel包：https://archive.cloudera.com/cdh6/6.3.0/parcels/下载图中框选的三个文件 此条消息2020-3-11更新6.3.0parcel包已经被官网下架了，可以去官网下载地址合集找其他版本parcel下载 其他parcel包（可选）YCSB：http://archive.cloudera.com/cloudera-labs/ycsb/parcels/latest/Phoenix：http://archive.cloudera.com/cloudera-labs/phoenix/parcels/latest/kafka: http://archive.cloudera.com/cloudera-labs/kafka/parcels/latest/csds: http://archive.cloudera.com/cloudera-labs/csds/ktrace: http://archive.cloudera.com/cloudera-labs/htrace/parcels/latest/ 安装httpd服务（Apache服务，任意一个管理节点安装即可） 注意：selinux未关闭可能导致Apache服务地址403。 [root@cdh ~]# yum -y install httpd 修改/etc/httpd/conf/httpd.conf配置文件，找到如下行，增加.parcel使其支持parcel格式文件 ... AddType application/x-compress .Z AddType application/x-gzip .gz .tgz .parcel ... 启动服务 [root@cdh ~]# service httpd restart Redirecting to /bin/systemctl restart httpd.service 浏览器访问服务器80端口，查看httpd服务是否开启。 注意：配置信息如端口、映射路径可以通过编辑/etc/httpd/conf/httpd.conf文件进行修改 配置本地yum源httpd默认路径为：/var/www/html/ 如果httpd映射路径修改过，则以修改后的为准。 Cloudera Manager将下载的所有cm rpm包和allkeys文件一起制作离线yum源将离线yum源放到httpd服务路径中，方便其他节点访问 [root@node10 cm6.3.0]# pwd /var/www/html/cloudera-repos/cm6.3.0 [root@node10 cm6.3.0]# ls -l total 1378004 -rw-r--r-- 1 root root 14041 Aug 1 00:08 allkeys.asc -rw-r--r-- 1 root root 10479136 Aug 16 16:26 cloudera-manager-agent-6.3.0-1281944.el7.x86_64.rpm -rw-r--r-- 1 root root 1201341068 Aug 16 16:26 cloudera-manager-daemons-6.3.0-1281944.el7.x86_64.rpm -rw-r--r-- 1 root root 11464 Aug 16 16:26 cloudera-manager-server-6.3.0-1281944.el7.x86_64.rpm -rw-r--r-- 1 root root 10996 Aug 16 16:26 cloudera-manager-server-db-2-6.3.0-1281944.el7.x86_64.rpm -rw-r--r-- 1 root root 14209884 Aug 16 16:26 enterprise-debuginfo-6.3.0-1281944.el7.x86_64.rpm -rw-r--r-- 1 root root 184988341 Aug 16 16:26 oracle-j2sdk1.8-1.8.0+update181-1.x86_64.rpm drwxr-xr-x 2 root root 4096 Aug 20 14:48 repodata [root@node10 cm6.3.0]# CDH其他parcel包将parcel包移到httpd服务路径 创建/var/www/html//cloudera-repos/cdh6.3.0/目录，将parcel包放到该目录中 [root@cdh cdh6.3.0]# pwd /var/www/html/cloudera-repos/cdh6.3.0 [root@cdh cdh6.3.0]# ls -l total 2036848 -rw-r--r-- 1 root root 2085690155 Aug 16 16:25 CDH-6.3.0-1.cdh6.3.0.p0.1279813-el7.parcel -rw-r--r-- 1 root root 40 Aug 16 16:25 CDH-6.3.0-1.cdh6.3.0.p0.1279813-el7.parcel.sha1 -rw-r--r-- 1 root root 33887 Aug 16 16:25 manifest.json [root@cdh cdh6.3.0]# 安装并配置元数据库可以选择MySQL或者Mariadb 安装Mariadb参考官网 安装server yum -y install mariadb-server 修改配置文件/etc/my.cnf为以下内容 [mysqld] datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock transaction-isolation = READ-COMMITTED # Disabling symbolic-links is recommended to prevent assorted security risks; # to do so, uncomment this line: symbolic-links = 0 # Settings user and group are ignored when systemd is used. # If you need to run mysqld under a different user or group, # customize your systemd unit file for mariadb according to the # instructions in http://fedoraproject.org/wiki/Systemd key_buffer = 16M key_buffer_size = 32M max_allowed_packet = 32M thread_stack = 256K thread_cache_size = 64 query_cache_limit = 8M query_cache_size = 64M query_cache_type = 1 max_connections = 550 #expire_logs_days = 10 #max_binlog_size = 100M #log_bin should be on a disk with enough free space. #Replace '/var/lib/mysql/mysql_binary_log' with an appropriate path for your #system and chown the specified folder to the mysql user. #建议单独磁盘装binlog，并且修改目录拥有者为mysql log_bin=/var/lib/mysql/mysql_binary_log #In later versions of MariaDB, if you enable the binary log and do not set #a server_id, MariaDB will not start. The server_id must be unique within #the replicating group. server_id=1 binlog_format = mixed read_buffer_size = 2M read_rnd_buffer_size = 16M sort_buffer_size = 8M join_buffer_size = 8M # InnoDB settings innodb_file_per_table = 1 innodb_flush_log_at_trx_commit = 2 innodb_log_buffer_size = 64M innodb_buffer_pool_size = 4G innodb_thread_concurrency = 8 innodb_flush_method = O_DIRECT innodb_log_file_size = 512M [mysqld_safe] log-error=/var/log/mariadb/mariadb.log pid-file=/var/run/mariadb/mariadb.pid # # include all files from the config directory # !includedir /etc/my.cnf.d 启动Mariadb，并加入开机自启动 systemctl start mariadb systemctl enable mariadb 初始化Mariadb [root@cdh cdh6.3.0]# mysql_secure_installation ... Enter current password for root (enter for none): #第一次直接回车 OK, successfully used password, moving on... ... Set root password? [Y/n] Y New password: # 设置root密码 Re-enter new password: ... Remove anonymous users? [Y/n] Y ... Disallow root login remotely? [Y/n] N ... Remove test database and access to it [Y/n] Y ... Reload privilege tables now? [Y/n] Y ... All done! If you've completed all of the above steps, your MariaDB installation should now be secure. Thanks for using MariaDB! 安装MySQL离线安装MySQL教程点击这里 注意安装mysql时需要安装mysql-community-libs-compat-5.7.24-1.el7.x86_64.rpm包，不然安装cm server时会报错：Requires: libmysqlclient.so.18()(64bit) 参考官网，修改/etc/my.cnf配置文件，重启mysql服务 [mysqld] datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock transaction-isolation = READ-COMMITTED # Disabling symbolic-links is recommended to prevent assorted security risks; # to do so, uncomment this line: symbolic-links = 0 key_buffer_size = 32M max_allowed_packet = 32M thread_stack = 256K thread_cache_size = 64 query_cache_limit = 8M query_cache_size = 64M query_cache_type = 1 max_connections = 550 #expire_logs_days = 10 #max_binlog_size = 100M #log_bin should be on a disk with enough free space. #Replace '/var/lib/mysql/mysql_binary_log' with an appropriate path for your #system and chown the specified folder to the mysql user. #建议单独磁盘装binlog，并且修改目录拥有者为mysql log_bin=/var/lib/mysql/mysql_binary_log #In later versions of MySQL, if you enable the binary log and do not set #a server_id, MySQL will not start. The server_id must be unique within #the replicating group. server_id=1 binlog_format = mixed read_buffer_size = 2M read_rnd_buffer_size = 16M sort_buffer_size = 8M join_buffer_size = 8M # InnoDB settings innodb_file_per_table = 1 innodb_flush_log_at_trx_commit = 2 innodb_log_buffer_size = 64M innodb_buffer_pool_size = 4G innodb_thread_concurrency = 8 innodb_flush_method = O_DIRECT innodb_log_file_size = 512M [mysqld_safe] log-error=/var/log/mysqld.log pid-file=/var/run/mysqld/mysqld.pid sql_mode=STRICT_ALL_TABLES 配置组件数据库新建各组件数据库，为后续安装做准备（这里可以根据安装的组件进行选择创建，其中密码'1234'建议设置为自己的密码） CREATE DATABASE scm DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci; GRANT ALL ON scm.* TO 'scm'@'%' IDENTIFIED BY '1234'; CREATE DATABASE hue DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci; GRANT ALL ON hue.* TO 'hue'@'%' IDENTIFIED BY '1234'; CREATE DATABASE metastore DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci; GRANT ALL ON metastore.* TO 'metastore'@'%' IDENTIFIED BY '1234'; CREATE DATABASE sentry DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci; GRANT ALL ON sentry.* TO 'sentry'@'%' IDENTIFIED BY '1234'; CREATE DATABASE oozie DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci; GRANT ALL ON oozie.* TO 'oozie'@'%' IDENTIFIED BY '1234'; 配置连接jar包上传mysql连接包到/usr/share/java/目录下（如果没有则创建一个），改名为：mysql-connector-java.jar 注意：需要连接MySQL数据库的节点都需要上传连接包 [root@cdh java]# pwd /usr/share/java [root@cdh java]# ls mysql-connector-java-5.1.47.jar [root@cdh java]# mv mysql-connector-java-5.1.47.jar mysql-connector-java.jar [root@cdh java]# ls mysql-connector-java.jar 安装jdk 安装cloudera manager节点必须安装，其他节点现在可以不安装，在进行CDH安装时还可以安装 由于我们下载的cloudera cm包中有jdk并且配置好了yum离线源，所以直接用yum安装官方推荐的jdk（前提是已经配置了yum离线源的repo仓库地址）安装后的jdk目录为：/usr/java/jdk1.8.0_181-cloudera，如有需要，可以自行配置环境变量 [root@cdh java]# yum -y install oracle-j2sdk1.8 Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile * base: mirrors.aliyun.com * extras: mirrors.aliyun.com * updates: mirrors.aliyun.com Resolving Dependencies --> Running transaction check ---> Package oracle-j2sdk1.8.x86_64 0:1.8.0+update181-1 will be installed --> Finished Dependency Resolution Dependencies Resolved ======================================================================================================================================================================================= Package Arch Version Repository Size ======================================================================================================================================================================================= Installing: oracle-j2sdk1.8 x86_64 1.8.0+update181-1 cm 176 M Transaction Summary ======================================================================================================================================================================================= Install 1 Package Total download size: 176 M Installed size: 364 M Downloading packages: oracle-j2sdk1.8-1.8.0+update181-1.x86_64.rpm | 176 MB 00:00:05 Running transaction check Running transaction test Transaction test succeeded Running transaction Installing : oracle-j2sdk1.8-1.8.0+update181-1.x86_64 1/1 Verifying : oracle-j2sdk1.8-1.8.0+update181-1.x86_64 1/1 Installed: oracle-j2sdk1.8.x86_64 0:1.8.0+update181-1 Complete! 安装Cloudera Manager可以不用手动安装cloudera-manager-daemons，安装server或者agent时会自动安装daemons [root@cdh ~]# yum -y install cloudera-manager-daemons cloudera-manager-agent cloudera-manager-server Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile * base: mirrors.aliyun.com * extras: mirrors.aliyun.com * updates: mirrors.aliyun.com ... Complete! 安装agent时可能遇到的问题：如果不是纯净的Centos镜像包（经过修改或升级）安装的操作系统，则可能遇到以下问题： [root@cdh ~]# yum -y install cloudera-manager-agent ... Error: Package: krb5-devel-1.15.1-34.el7.x86_64 (iso-7.6) Requires: krb5-libs(x86-64) = 1.15.1-34.el7 Installed: krb5-libs-1.15.1-37.el7_6.x86_64 (@updates) krb5-libs(x86-64) = 1.15.1-37.el7_6 Available: krb5-libs-1.15.1-18.el7.x86_64 (iso) krb5-libs(x86-64) = 1.15.1-18.el7 Available: krb5-libs-1.15.1-34.el7.x86_64 (iso-7.6) krb5-libs(x86-64) = 1.15.1-34.el7 Error: Package: 1:openssl-devel-1.0.2k-16.el7.x86_64 (iso-7.6) Requires: openssl-libs(x86-64) = 1:1.0.2k-16.el7 Installed: 1:openssl-libs-1.0.2k-16.el7_6.1.x86_64 (@updates) openssl-libs(x86-64) = 1:1.0.2k-16.el7_6.1 Available: 1:openssl-libs-1.0.2k-12.el7.x86_64 (iso) openssl-libs(x86-64) = 1:1.0.2k-12.el7 Available: 1:openssl-libs-1.0.2k-16.el7.x86_64 (iso-7.6) openssl-libs(x86-64) = 1:1.0.2k-16.el7 Error: Package: 32:bind-libs-9.9.4-72.el7.x86_64 (iso-7.6) Requires: bind-license = 32:9.9.4-72.el7 Installed: 32:bind-license-9.9.4-74.el7_6.1.noarch (@updates) bind-license = 32:9.9.4-74.el7_6.1 Available: 32:bind-license-9.9.4-61.el7.noarch (iso) bind-license = 32:9.9.4-61.el7 Available: 32:bind-license-9.9.4-72.el7.noarch (iso-7.6) bind-license = 32:9.9.4-72.el7 Error: Package: libkadm5-1.15.1-34.el7.x86_64 (iso-7.6) Requires: krb5-libs(x86-64) = 1.15.1-34.el7 Installed: krb5-libs-1.15.1-37.el7_6.x86_64 (@updates) krb5-libs(x86-64) = 1.15.1-37.el7_6 Available: krb5-libs-1.15.1-18.el7.x86_64 (iso) krb5-libs(x86-64) = 1.15.1-18.el7 Available: krb5-libs-1.15.1-34.el7.x86_64 (iso-7.6) krb5-libs(x86-64) = 1.15.1-34.el7 You could try using --skip-broken to work around the problem You could try running: rpm -Va --nofiles --nodigest ... 根据提示可以看处是yum依赖包冲突，已经安装了更高的版本，解决方法是对相关rpm包降级。以下解决krb5-devel包的冲突，其他包操作步骤类似：根据保存提示可以知道，krb5-devel依赖的krb5-libs包需要的版本为34，但是已经安装了37版本，高于要求的版本1)搜索目前可用的版本 [root@cdh ~]# yum search --showduplicates krb5-libs Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile =================================================================================== N/S matched: krb5-libs ==================================================================================== krb5-libs-1.15.1-18.el7.i686 : The non-admin shared libraries used by Kerberos 5 krb5-libs-1.15.1-18.el7.x86_64 : The non-admin shared libraries used by Kerberos 5 krb5-libs-1.15.1-34.el7.i686 : The non-admin shared libraries used by Kerberos 5 krb5-libs-1.15.1-34.el7.x86_64 : The non-admin shared libraries used by Kerberos 5 krb5-libs-1.15.1-37.el7_6.x86_64 : The non-admin shared libraries used by Kerberos 5 Name and summary matches only, use \"search all\" for everything. 2)将包降级为34版本 [root@cdh ~]# yum -y downgrade krb5-libs-1.15.1-34.el7.x86_64 ... Removed: krb5-libs.x86_64 0:1.15.1-37.el7_6 Installed: krb5-libs.x86_64 0:1.15.1-34.el7 Complete! 注：如果降级还是报冲突错误，则可以将包卸载后重新安装： #查看已安装版本 rpm -qa | grep bind-libs #卸载已安装版本 rpm -e --nodeps [完整包名] #安装需要的版本 rpm -ivh [需要安装的rpm包rpm文件] 初始化Cloudera Manager数据库参照官网：https://www.cloudera.com/documentation/enterprise/6/6.3/topics/prepare_cm_database.html由于我们MySQL是安装在本地，所以直接执行 [root@cdh ~]# /opt/cloudera/cm/schema/scm_prepare_database.sh mysql scm scm Enter SCM password: # 输入创建数据库时的密码 JAVA_HOME=/usr/java/jdk1.8.0_181-cloudera Verifying that we can write to /etc/cloudera-scm-server Creating SCM configuration file in /etc/cloudera-scm-server Executing: /usr/java/jdk1.8.0_181-cloudera/bin/java -cp /usr/share/java/mysql-connector-java.jar:/usr/share/java/oracle-connector-java.jar:/usr/share/java/postgresql-connector-java.jar:/opt/cloudera/cm/schema/../lib/* com.cloudera.enterprise.dbutil.DbCommandExecutor /etc/cloudera-scm-server/db.properties com.cloudera.cmf.db. Tue Aug 20 02:09:39 EDT 2019 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification. [ main] DbCommandExecutor INFO Successfully connected to database. All done, your SCM database is configured correctly! [root@cdh ~]# 如果mysql是安装在其他节点（例如：db01.example.com节点），则运行：/opt/cloudera/cm/schema/scm_prepare_database.sh mysql -h db01.example.com --scm-host cm01.example.com scm scm 启动Cloudera Manager Server输入以下命令启动Server [root@cdh ~]# systemctl start cloudera-scm-server 使用tail命令查看运行日志，当出现Started Jetty server.字眼时表示启动成功 [root@cdh ~]# tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log 2019-08-20 02:13:30,437 INFO main:org.kie.api.internal.utils.ServiceDiscoveryImpl: Loading kie.conf from jar:file:/opt/cloudera/cm/common_jars/kie-internal-7.13.0.Final.11622bc00754050ffd86f282138da203.jar!/META-INF/kie.conf in classloader sun.misc.Launcher$AppClassLoader@67f89fa3 2019-08-20 02:13:30,438 INFO main:org.kie.api.internal.utils.ServiceDiscoveryImpl: Adding Service org.kie.internal.services.KieAssemblersImpl ... 2019-08-20 02:15:58,334 INFO WebServerImpl:org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@179933a5{HTTP/1.1,[http/1.1]}{0.0.0.0:7180} 2019-08-20 02:15:58,350 INFO WebServerImpl:org.eclipse.jetty.server.Server: Started @193290ms 2019-08-20 02:15:58,350 INFO WebServerImpl:com.cloudera.server.cmf.WebServerImpl: Started Jetty server. 浏览器访问7180端口，进行CDH安装Cloudera Manager会根据浏览器的语言进行语言的切换，本文为中文初始用户名和密码均为：admin登录后看到第一个欢迎页面，点击继续接受许可条款选择安装版本，这里选择免费版（之前免费版会有100个节点限制，现在已经没有了） 进入第二个欢迎页面，左边列出了安装的步骤输入集群名称，本文默认输入主机名后进行搜索配置cloudera manager yum离线库地址，点击更多选项配置parcel库地址，前两个选项默认就行，远程Parcel库删除默认的地址，输入httpd服务的Parcel库地址，点击保存更改保存后会自动搜索Parcel包，如图，已经搜索到了之前下载的CDH6.3.0包，点击继续如果之前只安装了cm server节点的jdk，则需要勾选上，如果每个节点都安装了jdk就不需要勾选配置ssh，如果主机的密码不相同，则需要选择使用秘钥的形式，如果密码相同，直接输入密码即可安装cloudera agent（安装过程中遇到问题可以根据提示进行解决），点击继续开始自动安装Parcel包，由于需要拷贝到相应节点然后解压，所以时间消耗比较久，耐心等待完成进行集群检测，包括网络检测和节点其他检测，如果检测有问题可以按照提示进行修复建议完全通过检测后再点击继续 如果只有一个节点，网络检测不会通过 开始安装组件服务，可以选择官方的配置方案，也可以选择自定义本文选择自定义服务，先安装HDFS和Zookeeper按照之前的组件角色分配规划，选择组件相应服务安装的节点官网组件服务分配参考：https://www.cloudera.com/documentation/enterprise/6/6.3/topics/cm_ig_host_allocations.html选择组件初始化配置，比如选择HDFS DataNode储存目录等点击继续后就会开始安装组件，等待安装完成最后一步，没有问题直接点完成即可 常见问题无法复制安装文件allkeys.asc因为在配置Cloudera Manager yum库时没有下载allkeys.asc文件解决方法：到官网：https://archive.cloudera.com/cm6/6.3.0/下载allkeys.asc文件到yum离线库 安装Parcel提示主机运行状况不良解决方法：删除agent目录下面的cm_guid文件，并重启失败节点的agent服务恢复 [root@cdh ~]# cd /var/lib/cloudera-scm-agent/ [root@cdh cloudera-scm-agent]# ls active_parcels.json cm_guid response.avro uuid [root@cdh cloudera-scm-agent]# rm -rf cm_guid [root@cdh cloudera-scm-agent]# service cloudera-scm-agent restart Stopping cloudera-scm-agent: [ OK ] Starting cloudera-scm-agent: entropy was available（系统熵值过低）解决方法：提高系统熵值 查看目前熵值 [root@node2 ~]# cat /proc/sys/kernel/random/entropy_avail 34 安装rng-tools工具 [root@node3 ~]# yum install -y rng-tools Loaded plugins: fastestmirror Repository base is listed more than once in the configuration Repository updates is listed more than once in the configuration ... Installed: rng-tools.x86_64 0:6.3.1-3.el7 Complete! 修改/新建/etc/sysconfig/rngd文件，增加以下内容 OPTIONS=\"-r /dev/urandom\" 启动rngd服务 [root@node2 ~]# service rngd start Redirecting to /bin/systemctl start rngd.service 再次查看熵值 [root@node2 ~]# cat /proc/sys/kernel/random/entropy_avail 3081 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"CDH","slug":"CDH","permalink":"http://blog.hming.org/tags/CDH/"},{"name":"离线安装","slug":"离线安装","permalink":"http://blog.hming.org/tags/%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/"}]},{"title":"Centos7安装VNC服务","slug":"Centos7安装VNC服务","date":"2019-08-06T08:00:24.000Z","updated":"2019-08-06T08:00:24.000Z","comments":true,"path":"2019/08/06/centos7-an-zhuang-vnc-fu-wu/","link":"","permalink":"http://blog.hming.org/2019/08/06/centos7-an-zhuang-vnc-fu-wu/","excerpt":"","text":"安装gnome桌面如果Centos7为最小化安装，则需要单独安装gnome图形化桌面 [root@AccessGateway ~]# yum groupinstall -y \"GNOME Desktop\" 安装vnc server[root@AccessGateway ~]# yum install -y tigervnc-server 配置服务 复制一个服务设置模板，命名为vncserver@:1.service cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service 修改服务配置， [root@AccessGateway ~]# vim /etc/systemd/system/vncserver\\@\\:1.service [Unit] Description=Remote desktop service (VNC) After=syslog.target network.target [Service] Type=forking User=root #设置登录用户为root # Clean any existing files in /tmp/.X11-unix environment ExecStartPre=/bin/sh -c '/usr/bin/vncserver -kill %i > /dev/null 2>&amp;1 || :' #将这里的User改为root，-geometry 1920x1080选项指定连接分辨率，也可以不指定 ExecStart=/usr/sbin/runuser -l root -c \"/usr/bin/vncserver -geometry 1920x1080 %i\" PIDFile=/root/.vnc/%H%i.pid #这里指向root根目录地址 ExecStop=/bin/sh -c '/usr/bin/vncserver -kill %i > /dev/null 2>&amp;1 || :' [Install] WantedBy=multi-user.target 如果需要配置其他用户登录，则重复1,2步骤，再复制一个配置文件，修改相应用户 更新systemctl [root@AccessGateway ~]# systemctl daemon-reload 设置VNC密码VNC的密码跟系统的用户密码不一样，是使用VNC Viewer登陆时需要使用的密码 [root@AccessGateway ~]# vncpasswd Password: Verify: Would you like to enter a view-only password (y/n)? n A view-only password is not used # 这里不添加只读账号密码 # 每个不用的系统用户，设置密码时，需要切换到该用户下，执行此命令 # 如：su zhangsan 切换到zhangsan用户再执行上vncpasswd设置密码 启动服务启动刚才配置的服务，如果配置了多个，则需要启动相应的服务 [root@AccessGateway ~]# systemctl start vncserver@:1.service 设置开机自启动 [root@AccessGateway ~]# systemctl enable vncserver@:1.service 查看端口信息，VNC默认端口为5901，因为我启动了两个服务，所以还有一个5902端口存在 [root@AccessGateway ~]# netstat -lnpt|grep Xvnc tcp 0 0 0.0.0.0:5901 0.0.0.0:* LISTEN 10196/Xvnc tcp 0 0 0.0.0.0:5902 0.0.0.0:* LISTEN 11394/Xvnc tcp 0 0 0.0.0.0:6001 0.0.0.0:* LISTEN 10196/Xvnc tcp 0 0 0.0.0.0:6002 0.0.0.0:* LISTEN 11394/Xvnc tcp6 0 0 :::5901 :::* LISTEN 10196/Xvnc tcp6 0 0 :::5902 :::* LISTEN 11394/Xvnc tcp6 0 0 :::6001 :::* LISTEN 10196/Xvnc tcp6 0 0 :::6002 :::* LISTEN 11394/Xvnc 配置防火墙，开通端口如果没有开启防火墙，则这一步可以跳过根据监听的端口，进行端口开放，每个用户会对应一个端口，第一个用户默认为5901端口，如果配置多个，则需要开放相应端口 [root@AccessGateway ~]# firewall-cmd --add-port=5901/tcp --permanent [root@AccessGateway ~]# firewall-cmd --reload Windows安装VNC，连接Centos远程桌面 到官方下载地址：https://www.realvnc.com/en/connect/download/viewer/选择对应版本下载客户端 新建连接中VNC Server输入IP地址:1，输入密码即可连接成功 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.hming.org/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://blog.hming.org/tags/Linux/"},{"name":"VNC Viewer","slug":"VNC-Viewer","permalink":"http://blog.hming.org/tags/VNC-Viewer/"}]},{"title":"HDP与CDH对比","slug":"HDP与CDH对比","date":"2019-07-03T06:25:43.000Z","updated":"2019-07-19T03:22:22.000Z","comments":true,"path":"2019/07/03/hdp-yu-cdh-dui-bi/","link":"","permalink":"http://blog.hming.org/2019/07/03/hdp-yu-cdh-dui-bi/","excerpt":"","text":"HDP与CDH的对比版本更新对比HDP版本更新较快，因为Hortonworks内部大部分员工都是apache代码贡献者，尤其是Hadoop 2.0的贡献者。 CDH版本更新比Apache版本慢。 目前Apache社区Hadoop最新版本：3.2.0 目前CDH最新版支持Hadoop版本：3.0.0 目前HDP最新版支持Hadoop版本：3.1.1 架构对比CDH HDP 原装支持组件对比 CDH支持的存储组件更丰富 HDP支持的数据分析组件更丰富 HDP对多维分析及可视化有了支持，引入Druid和Superset HDP的HBase数据使用Phoenix的jdbc查询；CDH的HBase数据使用映射Hive到Impala的jdbc查询（CDH6.2支持Phoenix5），但分析数据可以存储Impala内部表，提高查询响应 多维分析Druid纳入集群，会方便管理；但可视化工具Superset可以单独安装使用 CDH没有时序数据库，HDP将Druid作为时序数据库使用 安全权限模块对比 HDP包含Ranger组件，即使在没有Kerberos的情况下，也能作一些简单的权限分配管理。由于100%开源，所以支持Ldap+Kerberos+Ranger的权限配置方式，分配权限简单易用。另外，Kerberos配置具有向导式界面。 CDH包含Sentry组件，Sentry与Ranger差别较大，Sentry没有图像化界面，只负责同步组件间的ACL授权。Cloudera express免费版只支持集成Kerberos，需要Ldap支持的需要企业版（CDH免费版和企业版区别对比）。 运维管理对比HDP采用Apache Ambari进行统一管理，Ambari2.7之后的版本相对2.6有很大的改动，2.6个人看来也不够人性化，2.7界面布局更加人性化。 Ambari不支持中文，整个管理页面都是英文呈现。 组件比较重要的基本配置都以图形化的方式呈现，比直接配文字版体验效果好。鼠标hover到配置项上面会有该项配置的说明。 其他配置都是按照节点（如下图中的NameNode）、配置文件（如下图中的Advanced hdfs-site）来进行组织的，方便运维人员快速定位。另外配置有版本记录，可以回退到任意版本。 组件界面可以直接看到该组件的哪些服务以及服务情况，右边就有该服务的快速链接，下图为Yarn的界面。 部分组件可以看到链接地址，比如Hive。 Ambari服务本身不支持高可用。 CDH采用Cloudera Manager（下文统一用cm代替）进行统一管理。 cm可以根据浏览器配置进行语言选择，支持中文。 配置界面左边将所有配置按照范围、类别、状态进行分类，也能很方便的找到配置。右边提供每个配置的说明，点看可以看到各项配置的说明。 配置版本控制免费版不支持参考官网：Viewing and Reverting Configuration Changes 组件服务的快速链接在tab页上 cm服务可以配置高可用参考官网：Installing and Configuring Cloudera Manager Server for High Availability cm支持数据加密，无论是静态加密或保护数据传输，但是可惜的是免费版cm支持很有限。另外加密前官方强烈建议安装Kerberos参考官网：Encryption Overview CDH版本说明CDH6.X组件版本对应https://www.cloudera.com/documentation/enterprise/6/release-notes/topics/rg_cdh_6_packaging.html CDH5.X组件版本对应https://www.cloudera.com/documentation/enterprise/release-notes/topics/cdh_vd_cdh_package_tarball.html Impala版本说明Impala在3.1之后才支持ORC格式HDFS文件，目前最高版本为3.2，CDH6.1对应的Impala版本为3.1，CDH6.2对应的Impala版本为3.2 Docker QuickStart版本说明Cloudera Quickstart和HDP的sandbox类似，都是单机版的供学习交流使用的大数据集群。目前Docker版启动的quickstart CDH版本最新为5.13.0，对应部分组件版本为： 组件 组件包版本 压缩包下载地址 版本发布说明 更改文件 Apache Hadoop hadoop-2.6.0+cdh5.13.0+2639 Tarball Release notes Changes Hadoop Mrv1 hadoop-0.20-mapreduce-2.6.0+cdh5.13.0+2639 (none) (none) (none) Hbase hbase-1.2.0+cdh5.13.0+411 Tarball Release notes Changes Apache Hive hive-1.1.0+cdh5.13.0+1269 Tarball Release notes Changes Hue hue-3.9.0+cdh5.13.0+7079 Tarball Release notes Changes Apache Impala impala-2.10.0+cdh5.13.0+0 (none) Release notes Changes Apache Kudu kudu-1.5.0+cdh5.13.0+0 (none) Release notes Changes Apache Oozie oozie-4.1.0+cdh5.13.0+458 Tarball Release notes Changes Cloudera Search search-1.0.0+cdh5.13.0+0 Tarball Release notes Changes Apache Solr solr-4.10.3+cdh5.13.0+519 Tarball Release notes Changes Apache Spark spark-1.6.0+cdh5.13.0+530 Tarball Release notes Changes Apache Sqoop sqoop-1.4.6+cdh5.13.0+116 Tarball Release notes Changes Apache Sqoop2 sqoop2-1.99.5+cdh5.13.0+46 Tarball Release notes Changes Zookeeper zookeeper-3.4.5+cdh5.13.0+118 Tarball Release notes Changes CDH免费版和企业版区别注：1.snmp traps：SNMP是指简单网络管理协议，trap是它规定的一种通信方式，用于被管理的设备主动向充当管理者的设备报告自己的异常信息。 官网参考地址截图来自CSDN document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"CDH","slug":"CDH","permalink":"http://blog.hming.org/tags/CDH/"},{"name":"HDP","slug":"HDP","permalink":"http://blog.hming.org/tags/HDP/"}]},{"title":"文档网站生成工具选型","slug":"文档网站生成工具选型","date":"2019-05-15T01:16:04.000Z","updated":"2019-05-15T01:16:04.000Z","comments":true,"path":"2019/05/15/wen-dang-wang-zhan-sheng-cheng-gong-ju-xuan-xing/","link":"","permalink":"http://blog.hming.org/2019/05/15/wen-dang-wang-zhan-sheng-cheng-gong-ju-xuan-xing/","excerpt":"","text":"需求 要求部署一个静态网站，用于开发者文档的呈现。 要求所有文档采用markdown格式书写，md文件保存到git仓库（github），并且目录结构必须清晰 要求md文件解析操作是在前端完成 方案选择 方式一 预先渲染HTML 方式二 运行时解析md 描述 先将所有md文件解析成HTML文件，然后前端进行HTML文件的展示参考：Hexo 前端直接读取md文件，在渲染页面时进行md文件的解析参考：docsify 优点 由于前端不需要渲染，直接展示，理论上速度没有延迟 由于每次都是即时渲染，所以在更新md文件时不会有额外工作量 缺点 在更新md文件，哪怕只更新一点，也需要所有md文件重新编译解析一次，工作量较大 需要前端实时解析md文件，在文件较大时可能会有延迟 选择 x √ 网站生成逻辑 各种开源工具对比 开源工具对比 Hexo VuePress Docute Docsify 文档生成方式 预先渲染HTML 预先渲染HTML 运行时解析 运行时解析 对SEO友好程度 友好 友好 不友好 不友好 官网地址 hexo vuepress docute docsify 适用场景 个人博客 需要SEO支持的技术文档 公司或团队内部的文档系统 公司或团队内部的文档系统 特点 与主题解耦，更换主题成本低 采用vue，对vue开发友好 Docute（60kB）使用Vue，Vue Router 和 Vuex Docsify（20kB）使用的是 vanilla JavaScript Docute与Docsify区别 Docsify官方文档更友好，内容更多，本身占用空间更小 同样的md文件，Docute解析代码段有问题，Docsify没问题 Docute提供一些官方组件，Badge、Note等，但是插件较少，而Docsify没有自带组件，但是支持很多有用的插件，如评论插件（Gitalk等）、全文搜索、谷歌统计等。而Docsify也支持Note插件：flexible-alerts Docsify支持封面主页，Docute不支持 Docsify样式配置可以通过md文件进行配置，而Docute只能在index.html中配置 Docsify支持热部署，更新配置和文章不需要重启服务，Docute不支持 最终选型最终选型：Docsify查看演示：https://docs.hming.org document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"部署","slug":"部署","permalink":"http://blog.hming.org/categories/%E9%83%A8%E7%BD%B2/"}],"tags":[{"name":"文档","slug":"文档","permalink":"http://blog.hming.org/tags/%E6%96%87%E6%A1%A3/"},{"name":"网站生成工具","slug":"网站生成工具","permalink":"http://blog.hming.org/tags/%E7%BD%91%E7%AB%99%E7%94%9F%E6%88%90%E5%B7%A5%E5%85%B7/"}]},{"title":"SandBox HDFS上传文件失败问题","slug":"SandBox-HDFS上传文件失败问题","date":"2019-04-16T02:02:55.000Z","updated":"2019-04-16T02:02:55.000Z","comments":true,"path":"2019/04/16/sandbox-hdfs-shang-chuan-wen-jian-shi-bai-wen-ti/","link":"","permalink":"http://blog.hming.org/2019/04/16/sandbox-hdfs-shang-chuan-wen-jian-shi-bai-wen-ti/","excerpt":"","text":"问题描述远程（非Docker容器内、非宿主机）上传文件，新建文件成功，写入文件内容失败。查看/var/log/hadoop/hdfs/hadoop-hdfs-namenode-sandbox-hdp.hortonworks.com.log文件，发现如下错误： 2019-04-15 10:51:33,322 INFO ipc.Server (Server.java:logException(2726)) - IPC Server handler 74 on 8020, call Call#4 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock from 172.18.0.3:48170 java.io.IOException: File /tmp/1.csv could only be written to 0 of the 1 minReplication nodes. There are 1 datanode(s) running and 1 node(s) are excluded in this operation. at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2121) at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:286) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2706) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:875) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:561) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:422) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682)原因分析上传文件过程中，Client先向NameNode发送上传文件请求，NameNode将DataNode的地址返回给Client，Client再通过该地址，写入文件内容。由于SandBox HDP是搭建在Docker容器内部，所以NameNode返回的是Docker容器的ip地址（这和Docker的网络模式有关），因为SandBox默认启动的是自定义网络，所以容器内部ip为172.18.0.3，返回给Client之后，Client通过该IP是无法找到DataNode的，所以导致文件的元数据存到了NameNode上，而文件内容无法写入DataNode。 解决方案方案一（推荐）修改代码和增加端口映射因为NameNode返回的是Docker的ip，Client访问不了DataNode，所以可以让NameNode返回主机名，然后Client配置host的方式请求到宿主机的地址 修改Client host文件配置，增加host映射 10.75.4.32 sandbox-hdp.hortonworks.com java代码修改： Configuration conf = new Configuration(); conf.set(\"fs.defaultFS\", \"hdfs://10.75.4.32:8020/\"); //增加下面一行，设置返回DataNode的主机名而不是ip conf.set(\"dfs.client.use.datanode.hostname\",\"true\"); 此时还是不能访问到DataNode，因为sandbox-proxy容器并没有映射DataNode的端口（默认为50010）。3. 修改sandbox-proxy端口映射，增加50010端口停止、删除sandbox-proxy容器 [root@sandbox-host ~]# docker stop sandbox-proxy sandbox-proxy [root@sandbox-host ~]# docker rm sandbox-proxy sandbox-proxy 修改generate-proxy-deploy-script.sh脚本，在tcpPortsHDP=(...)部分新增50010端口映射VMware版本脚本路径：/sandbox/proxy/generate-proxy-deploy-script.sh纯Docker版脚本路径：./assets/generate-proxy-deploy-script.sh ... tcpPortsHDP=( ... [50010]=50010 ... ) 重新执行docker-deploy-hdp30.sh脚本中配置代理容器的脚本 #Deploy the proxy container. sed 's/sandbox-hdp-security/sandbox-hdp/g' assets/generate-proxy-deploy-script.sh > assets/generate-proxy-deploy-script.sh.new mv -f assets/generate-proxy-deploy-script.sh.new assets/generate-proxy-deploy-script.sh chmod +x assets/generate-proxy-deploy-script.sh assets/generate-proxy-deploy-script.sh 2>/dev/null 方案二（不推荐）暴力取消Docker网络隔离层，这样也就失去了Docker容器网络隔离的特性，具体利弊需要斟酌。因为原因是Client连不上DataNode节点，所以直接将Docker容器的网络模式设置成host模式（详细参照Docker网络模式），将容器的ip和端口直接和宿主机打通，这样就能远程连接DataNode了。 纯Docker模式 停止、删除已生成容器（sandbox-proxy和sandbox-hdp） [root@sandbox proxy]# docker stop $(docker ps -aq) ef35a5989c71 25f814082615 [root@sandbox proxy]# docker rm $(docker ps -aq) ef35a5989c71 25f814082615 修改脚本文件docker-deploy-hdp30.sh，将容器启动改为host网络模式，注释代理容器相关代码 脚本文件为运行sandbox时的启动脚本 #!/usr/bin/env sh #This script downloads HDP sandbox along with their proxy docker container set -x # CAN EDIT THESE VALUES registry=\"hortonworks\" name=\"sandbox-hdp\" version=\"3.0.1\" proxyName=\"sandbox-proxy\" proxyVersion=\"1.0\" flavor=\"hdp\" # NO EDITS BEYOND THIS LINE # housekeeping # 这里已经没用了，注释 #echo $flavor > sandbox-flavor # create necessary folders for nginx and copy over our rule generation script there #这里也注释，不需要代理容器了 #mkdir -p sandbox/proxy/conf.d #mkdir -p sandbox/proxy/conf.stream.d # pull and tag the sandbox and the proxy container # 本地已经存在镜像文件，这里可以注释减少脚本执行时间 #docker pull \"$registry/$name:$version\" #docker pull \"$registry/$proxyName:$proxyVersion\" # start the docker container and proxy if [ \"$flavor\" == \"hdf\" ]; then hostname=\"sandbox-hdf.hortonworks.com\" elif [ \"$flavor\" == \"hdp\" ]; then hostname=\"sandbox-hdp.hortonworks.com\" fi version=$(docker images | grep $registry/$name | awk '{print $2}'); # Create cda docker network # 因为采用host网络模式，这里创建网络cda也注释 #docker network create cda 2>/dev/null # Deploy the sandbox into the cda docker network # 将原本的run语句注释，修改为以下语句（将网络模式修改为host） #docker run --privileged --name $name -h $hostname --network=cda --network-alias=$hostname -d \"$registry/$name:$version\" docker run --privileged --name $name -h $hostname --network=host -d \"$registry/$name:$version\" echo \" Remove existing postgres run files. Please wait\" sleep 2 docker exec -t \"$name\" sh -c \"rm -rf /var/run/postgresql/*; systemctl restart postgresql-9.6.service;\" #Deploy the proxy container. # 这里为代理容器配置，因为host模式自动将所有端口映射到宿主机上，所以不再需要sandbox-proxy容器的支持 #sed 's/sandbox-hdp-security/sandbox-hdp/g' assets/generate-proxy-deploy-script.sh > assets/generate-proxy-deploy-script.sh.new #mv -f assets/generate-proxy-deploy-script.sh.new assets/generate-proxy-deploy-script.sh #chmod +x assets/generate-proxy-deploy-script.sh #assets/generate-proxy-deploy-script.sh 2>/dev/null #check to see if it's windows # 以下为window环境代码，也注释 #if uname | grep MINGW; then # sed -i -e 's/\\( \\/[a-z]\\)/\\U\\1:/g' sandbox/proxy/proxy-deploy.sh #fi #chmod +x sandbox/proxy/proxy-deploy.sh 2>/dev/null #sandbox/proxy/proxy-deploy.sh 重新运行docker-deploy-hdp30.sh脚本文件 [root@sandbox opt]# sh docker-deploy-hdp30.sh + registry=hortonworks + name=sandbox-hdp + version=3.0.1 + proxyName=sandbox-proxy + proxyVersion=1.0 + flavor=hdp + echo hdp + mkdir -p sandbox/proxy/conf.d + mkdir -p sandbox/proxy/conf.stream.d + '[' hdp == hdf ']' + '[' hdp == hdp ']' + hostname=sandbox-hdp.hortonworks.com ++ docker images ++ grep hortonworks/sandbox-hdp ++ awk '{print $2}' + version=3.0.1 + docker run --privileged --name sandbox-hdp -h sandbox-hdp.hortonworks.com --network=host -d hortonworks/sandbox-hdp:3.0.1 b91b70d7792a806310c067e7792f4c3930a5329261128d5a4c211b804a923342 + echo ' Remove existing postgres run files. Please wait' Remove existing postgres run files. Please wait + sleep 2 + docker exec -t sandbox-hdp sh -c 'rm -rf /var/run/postgresql/*; systemctl restart postgresql-9.6.service;' # 可以看到此时只剩下sandbox-hdp一个容器在运行 [root@sandbox opt]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES b91b70d7792a hortonworks/sandbox-hdp:3.0.1 \"/usr/sbin/init\" 8 minutes ago Up 8 minutes sandbox-hdp 最后进行各种初始化配置即可进入sandbox容器，重置Ambari admin密码 [root@sandbox sandbox]# docker exec -it sandbox-hdp /bin/bash [root@sandbox-hdp /]# ambari-admin-password-reset Please set the password for admin: Please retype the password for admin: The admin password has been set. Restarting ambari-server to make the password change effective... Using python /usr/bin/python Restarting ambari-server Ambari Server is not running Ambari Server running with administrator privileges. Organizing resource files at /var/lib/ambari-server/resources... Ambari database consistency check started... Server PID at: /var/run/ambari-server/ambari-server.pid Server out at: /var/log/ambari-server/ambari-server.out Server log at: /var/log/ambari-server/ambari-server.log Waiting for server start............................ Server started listening on 8080 DB configs consistency check: no errors and warnings were found. 访问8080端口，到Ambari界面，登录后重启服务即可。 SandBox使用参照：SandBox-HDP使用详解注意：由于没有运行sandbox-proxy容器，1080端口已经无法访问 VMware模式 通过ssh连接22端口登录到VMware虚拟机（sandbox的宿主机）里面也可以通过XShell等工具进入默认root初始密码为hadoop [root@localhost ~]# ssh 10.75.4.6 -p 22 root@10.75.4.6's password: Last failed login: Tue Apr 16 15:38:03 UTC 2019 from 10.75.4.32 on ssh:notty There was 1 failed login attempt since the last successful login. Last login: Mon Apr 15 16:34:49 2019 from 10.75.4.11 [root@sandbox-host ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE hortonworks/sandbox-proxy 1.0 ca272ae0e63a 4 months ago 109MB hortonworks/sandbox-hdp-security 3.0 ae1d1779b081 4 months ago 27.5GB 停止、删除已生成容器（sandbox-proxy和sandbox-hdp-security） [root@sandbox-host proxy]# docker stop $(docker ps -aq) ef35a5989c71 25f814082615 [root@sandbox-host proxy]# docker rm $(docker ps -aq) ef35a5989c71 25f814082615 修改脚本文件/sandbox/sandbox-deploy.sh，将容器启动改为host网络模式，注释代理容器相关代码 #!/usr/bin/env bash flavor=$(cat /sandbox-flavor) if [ \"$flavor\" == \"hdf\" ]; then name=\"sandbox-hdf-standalone-cda-ready\" hostname=\"sandbox-hdf.hortonworks.com\" elif [ \"$flavor\" == \"hdp\" ]; then name=\"sandbox-hdp-security\" hostname=\"sandbox-hdp.hortonworks.com\" fi version=$(docker images | grep $name | awk '{print $2}'); image=\"hortonworks/$name:$version\"; # Create cda docker network # 因为采用host网络模式，这里注释创建网络cda #docker network create cda # Deploy the sandbox into the cda docker network # 将原本的run语句注释，修改为以下语句（将网络模式修改为host） #docker run --privileged --name $name -h $hostname --network=cda --network-alias=$hostname -d $image docker run --privileged --name $name -h $hostname --network=host -d $image # Deploy the proxy container. This script was generated by running # 这里为代理容器配置，因为host模式自动将所有端口映射到宿主机上，所以不再需要sandbox-proxy容器的支持 #/sandbox/proxy/generate-proxy-deploy-script.sh #/sandbox/proxy/proxy-deploy.sh 运行脚本文件/sandbox/sandbox-deploy.sh，重新生成容器 [root@sandbox-host sandbox]# sh sandbox-deploy.sh 12e3df82d057057c6af78eea1c8bd9eb9156ebe0bac3dc90d2fec8377f48aa6f # 可以看到此时只剩下sandbox-hdp-security一个容器在运行 [root@sandbox-host sandbox]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 12e3df82d057 hortonworks/sandbox-hdp-security:3.0 \"/usr/sbin/init\" 6 seconds ago Up 3 seconds sandbox-hdp-security 最后进行各种初始化配置即可进入sandbox容器，重置Ambari admin密码 [root@sandbox-host sandbox]# docker exec -it sandbox-hdp-security /bin/bash [root@sandbox-hdp /]# ambari-admin-password-reset Please set the password for admin: Please retype the password for admin: The admin password has been set. Restarting ambari-server to make the password change effective... Using python /usr/bin/python Restarting ambari-server Ambari Server is not running Ambari Server running with administrator privileges. Organizing resource files at /var/lib/ambari-server/resources... Ambari database consistency check started... Server PID at: /var/run/ambari-server/ambari-server.pid Server out at: /var/log/ambari-server/ambari-server.out Server log at: /var/log/ambari-server/ambari-server.log Waiting for server start............................ Server started listening on 8080 DB configs consistency check: no errors and warnings were found. 访问8080端口，到Ambari界面，登录后重启服务即可。 SandBox使用参照：SandBox-HDP使用详解注意：由于没有运行sandbox-proxy容器，1080端口已经无法访问 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"HDP","slug":"HDP","permalink":"http://blog.hming.org/tags/HDP/"},{"name":"SandBox","slug":"SandBox","permalink":"http://blog.hming.org/tags/SandBox/"},{"name":"HDFS","slug":"HDFS","permalink":"http://blog.hming.org/tags/HDFS/"}]},{"title":"SandBox-HDP使用详解","slug":"SandBox-HDP使用详解","date":"2019-04-04T01:36:23.000Z","updated":"2019-04-04T01:36:23.000Z","comments":true,"path":"2019/04/04/sandbox-hdp-shi-yong-xiang-jie/","link":"","permalink":"http://blog.hming.org/2019/04/04/sandbox-hdp-shi-yong-xiang-jie/","excerpt":"","text":"官方文档介绍得非常详细，本文提取一些关键点作介绍，参考官网教程：Sandbox DocsSandbox Port ForwardsSandbox ArchitectureLearning the Ropes of the HDP Sandbox SandBox是什么 The Sandbox is a straightforward, pre-configured, learning environment that contains the latest developments from Apache Hadoop, specifically the Hortonworks Data Platform (HDP). The Sandbox comes packaged in a virtual environment that can run in the cloud or on your personal machine. The Sandbox allows you to learn and explore HDP on your own. SandBox是Hortonworks提供的单机版HDP或HDF环境，主要用于测试和学习使用，对于没有服务器集群又想使用HDP/HDF的情况，SandBox是不二之选。另外，SandBox里面内置了DAS（Data Analytics Studio），非SandBox版本是没有这个的，需要购买Hortonworks服务才的获取到安装包。SandBox提供三种安装方式：VirtualBox虚拟机、VMware虚拟机、Docker容器。本文主要针对讲SandBox-HDP，HDF安装使用和HDP大致相同。安装教程参考：安装SandBox HDP（Docker版）安装SandBox HDP（VMware版） 环境准备一个运行中的SandBox-HDP 3.0.1 web访问1080端口为sandbox容器web服务端口，可以通过浏览器访问该端口，得到以下界面：左侧launch dashboard直接进入ambari管理界面，登录admin账号需要进入容器修改ambari管理员密码右侧则是一些链接，包括ambari管理地址、Ranger地址、DAS地址等 4200端口则提供了一个浏览器访问命令行的接口：使用root登录，默认密码为hadoop，第一次登录会提示修改root密码，对密码强度会有要求 登录到HDP环境主机在运行docker的主机上可以通过2222端口登录到HDP docker主机中，也可以通过docker exec命令进入在其他机器上想登录到HDP主机就只能通过SSH了 # SSH登录需要输入密码，root初始密码为hadoop [root@sandbox opt]# ssh 127.0.0.1 -p 2222 root@127.0.0.1`s password: Last login: Thu Apr 4 08:22:27 2019 from 172.18.0.3 [root@sandbox-hdp ~]# # docker命令可以直接进入 [root@sandbox opt]# docker exec -it sandbox-hdp /bin/bash [root@sandbox-hdp /]# 登录到Ambari界面默认提供的账户，更多账号信息参考官网 用户 密码 admin 参考重置管理员密码 maria_dev maria_dev raj_ops raj_ops holger_gov holger_gov amy_ds amy_ds 重置Ambari管理员密码 以root用户登录到HDP主机 [root@sandbox opt]# ssh 127.0.0.1 -p 2222 root@127.0.0.1`s password: Last login: Thu Apr 4 08:22:27 2019 from 172.18.0.3 [root@sandbox-hdp ~]# 运行ambari-admin-password-reset命令，根据提示修改密码 [root@sandbox-hdp /]# ambari-admin-password-reset Please set the password for admin: Please retype the password for admin: The admin password has been set. Restarting ambari-server to make the password change effective... Using python /usr/bin/python Restarting ambari-server Waiting for server stop... Ambari Server stopped Ambari Server running with administrator privileges. Organizing resource files at /var/lib/ambari-server/resources... Ambari database consistency check started... Server PID at: /var/run/ambari-server/ambari-server.pid Server out at: /var/log/ambari-server/ambari-server.out Server log at: /var/log/ambari-server/ambari-server.log Waiting for server start.................................................................................................... DB configs consistency check: no errors and warnings were found. ERROR: Exiting with exit code 1. REASON: Server not yet listening on http port 8080 after 90 seconds. Exiting. 可能会遇到报错 ERROR: Exiting with exit code 1. REASON: Server not yet listening on http port 8080 after 90 seconds. Exiting. 这是由于SandBox中所有服务都在一个节点上，启动Ambari比较慢，超过了90秒，实际上这个错不会有任何影响 可以通过编辑/etc/ambari-server/conf/ambari.properties文件，添加一行server.startup.web.timeout = 150来增加超时时间的方法解决 执行命令后Ambari服务会重启，然后就可以通过新的admin密码登录Ambari 新增host映射Ambari中有些内部链接是通过sandbox-hdp.hortonworks.com域名去访问的，比如HDFS NameNode UI可以在需要访问的主机上增加host映射方便访问 数据库初始密码PostgreSQL查看ambari用户的密码，默认为bigdata [root@sandbox-hdp ~]# grep \"password\" /etc/ambari-server/conf/ambari.properties server.jdbc.rca.user.passwd=/etc/ambari-server/conf/password.dat server.jdbc.user.passwd=/etc/ambari-server/conf/password.dat [root@sandbox-hdp ~]# cat /etc/ambari-server/conf/password.dat bigdata 使用ambari用户登录postgreSQL [root@sandbox-hdp ~]# psql -U ambari -W Password for user ambari: psql (9.6.11) Type \"help\" for help. ambari=> MySQL内置MySQL使用的是Hive新建的MySQL，初始密码为hortonworks1登录ambari postgreSQL查找密码 [root@sandbox-hdp ~]# psql -U ambari -W Password for user ambari: psql (9.6.11) Type \"help\" for help. ambari=> select version,config_id,type_name,config_data from clusterconfig where type_name='hive-site'; 在结果里查找内容：javax.jdo.option.ConnectionPassword 常见错误远程向HDFS上传文件失败问题参照SandBox HDFS上传文件失败问题 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"HDP","slug":"HDP","permalink":"http://blog.hming.org/tags/HDP/"},{"name":"SandBox","slug":"SandBox","permalink":"http://blog.hming.org/tags/SandBox/"}]},{"title":"安装SandBox HDP（VMware版）","slug":"安装SandBox-HDP（VMware版）","date":"2019-04-02T03:28:35.000Z","updated":"2019-04-02T03:28:35.000Z","comments":true,"path":"2019/04/02/an-zhuang-sandbox-hdp-vmware-ban/","link":"","permalink":"http://blog.hming.org/2019/04/02/an-zhuang-sandbox-hdp-vmware-ban/","excerpt":"","text":"参考官网教程：Deploying Hortonworks Sandbox on VMWare 环境准备 方面 要求 软件 安装VMware 内存 推荐16G以上（会开一个内存为10G的虚拟机） 运行原理VMware启动了一个Linux虚拟机，在Linux虚拟机里面会启动两个docker容器 [root@sandbox-host ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE hortonworks/sandbox-proxy 1.0 ca272ae0e63a 4 months ago 109MB hortonworks/sandbox-hdp-security 3.0 ae1d1779b081 4 months ago 27.5GB sandbox-proxy容器负责代理转发一些端口sandbox-hdp-security容器则是HDP环境所以，要对HDP环境进行修改，比如修改ambari管理员密码，就需要进入docker容器里面可以通过ssh登录2222端口，也可以通过docker exec命令进入，docker相关命令参考Docker替换镜像源与常用命令 下载镜像文件到官网下载ova格式的镜像文件（HDP_3.0.1_vmware_181205.ova 20.5G）下载可能需要注册，随便填就行了 将.ova镜像导入到VMware中 打开VMware，点击文件-&gt;打开，导入刚才下载的文件：HDP_3.0.1_vmware_181205.ova 开启虚拟机（这里可以看到虚拟机的一些信息，包括内存磁盘等） 开启后可能会遇到无法连接网络的问题，这时候选择桥接模式，重启一下就行如何使用成功运行后窗口会打印一些信息，可以通过这些信息连接到虚拟机上图中的1080端口为sandbox端口，可以通过浏览器访问该端口，得到以下界面：左侧launch dashboard直接进入ambari管理界面，右侧则是一些链接，包括ambari管理地址、Ranger地址、DAS地址等4200端口则提供了一个浏览器访问命令行的接口：使用root登录，默认密码为hadoop，第一次登录会提示修改root密码，对密码强度会有要求 本文到此为止，更详细的使用教程，请参照SandBox-HDP使用详解 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"HDP","slug":"HDP","permalink":"http://blog.hming.org/tags/HDP/"},{"name":"SandBox","slug":"SandBox","permalink":"http://blog.hming.org/tags/SandBox/"},{"name":"虚拟机","slug":"虚拟机","permalink":"http://blog.hming.org/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"VMware","slug":"VMware","permalink":"http://blog.hming.org/tags/VMware/"}]},{"title":"安装SandBox HDP（Docker版）","slug":"安装SandBox-HDP（Docker版）","date":"2019-04-02T03:28:17.000Z","updated":"2019-06-05T04:00:53.000Z","comments":true,"path":"2019/04/02/an-zhuang-sandbox-hdp-docker-ban/","link":"","permalink":"http://blog.hming.org/2019/04/02/an-zhuang-sandbox-hdp-docker-ban/","excerpt":"","text":"参考官网教程：Deploying Hortonworks Sandbox on Docker 环境准备 方面 要求 软件 安装docker 内存 官方推荐docker容器至少10G 磁盘 docker镜像目录至少30G（sandbox镜像27.5G） 下载脚本文件到官网下载zip格式的shell脚本文件下载可能需要注册，随便填就行了。压缩包内容如下：)需要将脚本上传到Linux并解压 [root@sandbox opt]# ls assets docker-deploy-hdp30.sh 执行脚本1. 在Linux中执行docker-deploy-hdp30.sh脚本，拉取镜像，运行容器[root@sandbox opt]# sh docker-deploy-hdp30.sh + registry=hortonworks + name=sandbox-hdp + version=3.0.1 + proxyName=sandbox-proxy + proxyVersion=1.0 + flavor=hdp + echo hdp + mkdir -p sandbox/proxy/conf.d + mkdir -p sandbox/proxy/conf.stream.d + docker pull hortonworks/sandbox-hdp:3.0.1 Trying to pull repository docker.io/hortonworks/sandbox-hdp ... 3.0.1: Pulling from docker.io/hortonworks/sandbox-hdp 70799bbf2226: Pull complete 40963917cdad: Pull complete 3fe9adbb8d7e: Pull complete ee3ec4e8cb3d: Pull complete 7ea5917732c0: Pull complete 2d951411620c: Pull complete f4c5e354e7fd: Pull complete 22ffa6ef360f: Pull complete 2060aa0f3751: Pull complete ca01ba34744d: Pull complete 83326dded077: Pull complete eb3d71b90b73: Pull complete bdd1cab41c81: Pull complete 500cc770c4bd: Pull complete 0cb1decd5474: Pull complete b9591f4b6855: Pull complete f28e56086127: Pull complete e7de4e7d0bca: Pull complete ec77967d2166: Pull complete 4fdcae170114: Pull complete 6347f5df8ffc: Pull complete 6a6ecc232709: Pull complete ea845898ff50: Pull complete 02135573b1bf: Pull complete cb0176867cd8: Pull complete 3c08321268fd: Pull complete 82e82a97c465: Pull complete 8aaaa48ed101: Pull complete 74b321ac2ac5: Pull complete 569da02c0a66: Pull complete af40820407ef: Pull complete Digest: sha256:7b767af7b42030fb1dd0f672b801199241e6bef1258e3ce57361edb779d95921 Status: Downloaded newer image for docker.io/hortonworks/sandbox-hdp:3.0.1 + docker pull hortonworks/sandbox-proxy:1.0 Trying to pull repository docker.io/hortonworks/sandbox-proxy ... 1.0: Pulling from docker.io/hortonworks/sandbox-proxy 951bdea65c93: Pull complete 4b9047c5fbbb: Pull complete 773156407aae: Pull complete d8524176841d: Pull complete Digest: sha256:42e4cfbcbb76af07e5d8f47a183a0d4105e65a1e7ef39fe37ab746e8b2523e9e Status: Downloaded newer image for docker.io/hortonworks/sandbox-proxy:1.0 + '[' hdp == hdf ']' + '[' hdp == hdp ']' + hostname=sandbox-hdp.hortonworks.com ++ docker images ++ awk '{print $2}' ++ grep hortonworks/sandbox-hdp + version=3.0.1 + docker network create cda 7f641a6c16cf73df1079f241e76a318f3094f4303feaeae1c0a50c1b58c9d1ee + docker run --privileged --name sandbox-hdp -h sandbox-hdp.hortonworks.com --network=cda --network-alias=sandbox-hdp.hortonworks.com -d hortonworks/sandbox-hdp:3.0.1 59cb51cd71faa11218a12ee3f8c8ea1e58790025428a4573e476c1ddd118c202 + echo ' Remove existing postgres run files. Please wait' Remove existing postgres run files. Please wait + sleep 2 + docker exec -t sandbox-hdp sh -c 'rm -rf /var/run/postgresql/*; systemctl restart postgresql-9.6.service;' + sed s/sandbox-hdp-security/sandbox-hdp/g assets/generate-proxy-deploy-script.sh + mv -f assets/generate-proxy-deploy-script.sh.new assets/generate-proxy-deploy-script.sh + chmod +x assets/generate-proxy-deploy-script.sh + assets/generate-proxy-deploy-script.sh + grep MINGW + uname + chmod +x sandbox/proxy/proxy-deploy.sh + sandbox/proxy/proxy-deploy.sh c1f52cfec560982477e4b6c69f4cc95309bd93907196761ed5eff7222744743e 注意：镜像文件特别大，国内拉取非常慢，可通过代理等方式拉取。 2. 使用docker ps查看生成的容器可以看到有两个容器生成正在运行sandbox-proxy容器负责将HDP中的各个端口映射到主机上sandbox-hdp则是HDP主要环境的容器，所有的hdp组件都是在这个容器里面运行 3. 执行完脚本，相应的目录下会生成一个文件sandbox-flavor和一个文件夹sandbox[root@centos4 opt]# ls assets docker-deploy-hdp30.sh sandbox sandbox-flavor 4. 脚本文件只需要执行一次，如果需要停止或重启HDP环境，只需要停止/重启相应的docker容器停止HDP集群 docker stop sandbox-hdp docker stop sandbox-proxy 启动HDP集群 docker start sandbox-hdp docker start sandbox-proxy 删除HDP容器 docker stop sandbox-hdp docker stop sandbox-proxy docker rm sandbox-hdp docker rm sandbox-proxy 移除sandbox镜像 docker rmi hortonworks/sandbox-hdp:{release} 如何使用上图中的1080端口为sandbox端口，可以通过浏览器访问该端口，得到以下界面：左侧launch dashboard直接进入ambari管理界面，右侧则是一些链接，包括ambari管理地址、Ranger地址、DAS地址等4200端口则提供了一个浏览器访问命令行的接口：使用root登录，默认密码为hadoop，第一次登录会提示修改root密码，对密码强度会有要求 本文到此为止，更详细的使用教程，请参照SandBox-HDP使用详解 可能遇到的问题[root@centos4 opt]# docker logs sandbox-proxy 2019/04/04 05:53:28 [emerg] 1#1: host not found in upstream \"sandbox-hdp\" in /etc/nginx/conf.d/http-hdp.conf:9 nginx: [emerg] host not found in upstream \"sandbox-hdp\" in /etc/nginx/conf.d/http-hdp.conf:9 这种情况是因为docker网络没有配置好，导致proxy容器无法使用nginx代理hdp容器检查docker网络配置 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Docker","slug":"Docker","permalink":"http://blog.hming.org/tags/Docker/"},{"name":"HDP","slug":"HDP","permalink":"http://blog.hming.org/tags/HDP/"},{"name":"SandBox","slug":"SandBox","permalink":"http://blog.hming.org/tags/SandBox/"}]},{"title":"Linux制作离线yum源","slug":"Linux制作离线yum源","date":"2019-03-29T06:40:35.000Z","updated":"2019-03-29T06:40:35.000Z","comments":true,"path":"2019/03/29/linux-zhi-zuo-chi-xian-yum-yuan/","link":"","permalink":"http://blog.hming.org/2019/03/29/linux-zhi-zuo-chi-xian-yum-yuan/","excerpt":"","text":"参考 基本步骤 制作或挂载一个本地yum源目录 修改或增加repo配置文件指向 离线yum包制作利用官方包下载ISO文件到官网http://isoredirect.centos.org/下载镜像包，尽量下载Everything ISO版本，这里面的包最全，另外一个“DVD ISO”是通用版，里面的包并不全，还有一个“Minimal ISO”是Centos最小安装版（相当于是windows的纯净系统）。下载文件名如：CentOS-7-x86_64-Everything-1810.iso 挂载ISO到目录自己制作包查看rpm包依赖与下载依赖包 查看.rpm 包依赖：rpm -qpR [package] 通过yum install --downloadonly --downloaddir=[download_dir] [package] 来只下载所有依赖包不安装包(前提是当前环境没有安装该包) 在CentOS/RHEL 6或更早期的版本中，你需要安装一个单独yum插件(名称为yum-plugin-downloadonly)才能使用--downloadonly命令选项： yum install -y yum-plugin-downloadonly #如果没有该插件，你会在使用yum时得到以下错误： Command line error: no such option: --downloadonly&lt;/package> 运行yum list [package] --showduplicates 来查看包的多个版本 利用rpm包制作yum包 安装createrepo工具createrepo命令用来制作yum包，没有安装该软件可以通过下载createrepo的rpm包，通过rpm命令进行安装。 将所有的rpm包放到一个目录下 到rpm包的目录执行createrepo .命令[root@hadoop001 yum-repo]# createrepo . 之后会生成一个repodata的目录,该目录就成了一个yum源 离线yum源配置 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.hming.org/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://blog.hming.org/tags/Linux/"},{"name":"yum","slug":"yum","permalink":"http://blog.hming.org/tags/yum/"},{"name":"离线","slug":"离线","permalink":"http://blog.hming.org/tags/%E7%A6%BB%E7%BA%BF/"}]},{"title":"Linux修改命令终端提示符","slug":"Linux修改命令终端提示符","date":"2019-03-29T03:47:18.000Z","updated":"2019-03-29T03:47:18.000Z","comments":true,"path":"2019/03/29/linux-xiu-gai-ming-ling-zhong-duan-ti-shi-fu/","link":"","permalink":"http://blog.hming.org/2019/03/29/linux-xiu-gai-ming-ling-zhong-duan-ti-shi-fu/","excerpt":"","text":"命令行提示符代表含义命令行提示符一般格式含义：[root@sandbox ~]# 其中@前root表示当前用户，@后sandbox表示当前主机名，~表示当前目录为家目录 Linux命令行结尾的提示符有#和$两种不同的符号，如下所示： [root@sandbox ~]# #&lt;==这是超级管理员root用户对应的命令行。 [liming@sandbox ~]$ #&lt;==这是普通用户liming对应的命令行。 修改命令行提示符格式Linux命令提示符由PS1环境变量控制，可以通过全局配置文件/etc/bashrc或/etc/profile中进行按需配置和调整。查看当前PS1设置： [root@sandbox /]# set|grep PS1 PS1='[\\u@\\h \\W]\\$ ' PS1变量最终使用： export PS1='[\\[\\e[32;1m\\]\\u@\\h \\W\\[\\e[0m\\]]\\$ ' 参考：1 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.hming.org/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://blog.hming.org/tags/Linux/"},{"name":"命令行提示符","slug":"命令行提示符","permalink":"http://blog.hming.org/tags/%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%8F%90%E7%A4%BA%E7%AC%A6/"}]},{"title":"Docker Alpine容器介绍","slug":"Docker-Alpine容器介绍","date":"2019-03-06T12:44:02.000Z","updated":"2019-03-06T12:44:02.000Z","comments":true,"path":"2019/03/06/docker-alpine-rong-qi-jie-shao/","link":"","permalink":"http://blog.hming.org/2019/03/06/docker-alpine-rong-qi-jie-shao/","excerpt":"","text":"http://www.voidcn.com/article/p-ulbbnkky-brh.htmlhttps://blog.phpgao.com/docker_alpine.htmlhttps://marshal.ohtly.com/2016/12/21/docker-container-and-alpine-bash-not-found/ document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"容器","slug":"容器","permalink":"http://blog.hming.org/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"容器","slug":"容器","permalink":"http://blog.hming.org/tags/%E5%AE%B9%E5%99%A8/"},{"name":"Docker","slug":"Docker","permalink":"http://blog.hming.org/tags/Docker/"},{"name":"Alpine","slug":"Alpine","permalink":"http://blog.hming.org/tags/Alpine/"}]},{"title":"CentOS7离线安装HDF","slug":"CentOS7离线安装HDF","date":"2019-02-14T00:48:27.000Z","updated":"2019-02-14T00:48:27.000Z","comments":true,"path":"2019/02/14/centos7-chi-xian-an-zhuang-hdf/","link":"","permalink":"http://blog.hming.org/2019/02/14/centos7-chi-xian-an-zhuang-hdf/","excerpt":"","text":"本文环境已存在Ambari和HDP环境，Ambari搭建参照CentOS7离线安装HDP 下载离线包HDF仓库地址找到对应操作系统的包，下载HDF Management Pack与HDF RPM tarball两个包即可。（本文为CentOS7的包） 注意：HDF RPM tarball包大小3.6G左右，HDF Management Pack包96M左右，请确保保存路径有足够空间 [root@master ambari]# ll -h total 3.7G drwxr-xr-x 3 root root 4.0K Jan 16 15:00 ambari -rw-r--r-- 1 root root 3.6G Dec 15 02:36 HDF-3.3.1.0-centos7-rpm.tar.gz -rw-r--r-- 1 root root 96M Dec 15 02:13 hdf-ambari-mpack-3.3.1.0-10.tar.gz drwxr-xr-x 3 ambari-qa users 4.0K Dec 11 11:49 HDP drwxr-xr-x 3 ambari-qa users 4.0K Aug 13 2018 HDP-UTILS 其中ambari、HDP、HDP-UTILS为CentOS7离线安装HDP中制作的yum本地源地址 制作HDF yum镜像源参考制作本地源，将HDF-3.3.1.0-centos7-rpm.tar.gz包解压，制作yum本地源。 解压到httpd服务路径(本文httpd服务路径为/cloud/ambari) [root@master ambari]# pwd /cloud/ambari [root@master ambari]# tar -zxvf HDF-3.3.1.0-centos7-rpm.tar.gz [root@node1 ambari]# ll -h total 3.7G drwxr-xr-x 3 root root 4.0K Jan 16 15:00 ambari drwxr-xr-x 3 ambari-qa users 4.0K Dec 15 02:19 HDF -rw-r--r-- 1 root root 3.6G Dec 15 02:36 HDF-3.3.1.0-centos7-rpm.tar.gz -rw-r--r-- 1 root root 96M Dec 15 02:13 hdf-ambari-mpack-3.3.1.0-10.tar.gz drwxr-xr-x 3 ambari-qa users 4.0K Dec 11 11:49 HDP drwxr-xr-x 3 ambari-qa users 4.0K Aug 13 2018 HDP-UTILS 修改./HDF/centos7/3.3.1.0-10/hdf.repo文件为以下内容 #VERSION_NUMBER=3.3.1.0-10 [HDF-3.3.1.0] name=HDF Version - HDF-3.3.1.0 baseurl=http://192.168.0.151:88/ambari/HDF/centos7/3.3.1.0-10 gpgcheck=1 gpgkey=http://192.168.0.151:88/ambari/HDF/centos7/3.3.1.0-10/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins enabled=1 priority=1 [HDP-UTILS-1.1.0.22] name=HDP-UTILS Version - HDP-UTILS-1.1.0.22 baseurl=http://192.168.0.151:88/ambari/HDP-UTILS/centos7/1.1.0.22 gpgcheck=1 gpgkey=http://192.168.0.151:88/ambari/HDP-UTILS/centos7/1.1.0.22/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins enabled=1 priority=1 1)其中192.168.0.151:88为httpd的路径和端口，需根据实际情况修改。2)HDP-UTILS如果在HDP中已经配置过，则这里可以删除。 拷贝hdf.repo文件到/etc/yum.repos.d/目录下，进行yum更新 [root@master ambari]# cp hdf.repo /etc/yum.repos.d/ [root@master ambari]# yum clean all [root@master ambari]# yum makecache [root@master ambari]# yum repolist 如果yum报错，则可能是hdf源没有配置成功，或者hdf.repo文件有误，更正后重试即可。 将hdf.repo拷贝到其他节点，然后每个节点进行yum更新 安装HDF Management Pack此处参考官方文档 使用ambari-server install-mpack命令安装Management Pack [root@master ambari]# ambari-server install-mpack --mpack=./hdf-ambari-mpack-3.3.1.0-10.tar.gz --verbose Using python /usr/bin/python Installing management pack INFO: Loading properties from /etc/ambari-server/conf/ambari.properties INFO: Installing management pack ./hdf-ambari-mpack-3.3.1.0-10.tar.gz INFO: Loading properties from /etc/ambari-server/conf/ambari.properties INFO: Download management pack to temp location /var/lib/ambari-server/data/tmp/hdf-ambari-mpack-3.3.1.0-10.tar.gz INFO: Loading properties from /etc/ambari-server/conf/ambari.properties ... INFO: Loading properties from /etc/ambari-server/conf/ambari.properties INFO: Successfully switched addon services using config file /var/lib/ambari-server/resources/mpacks/hdf-ambari-mpack-3.3.1.0-10/hooks/HDF-3.3.json INFO: Loading properties from /etc/ambari-server/conf/ambari.properties Ambari Server 'install-mpack' completed successfully. 使用ambari-server restart命令重启ambari服务 [root@master ambari]# ambari-server restart Using python /usr/bin/python Restarting ambari-server Waiting for server stop... Ambari Server stopped Ambari Server running with administrator privileges. Organizing resource files at /var/lib/ambari-server/resources... Ambari database consistency check started... Server PID at: /var/run/ambari-server/ambari-server.pid Server out at: /var/log/ambari-server/ambari-server.out Server log at: /var/log/ambari-server/ambari-server.log Waiting for server start....................... Server started listening on 8080 DB configs consistency check: no errors and warnings were found. 更新ambari服务中HDF源地址参考官方文档 浏览器进入Ambari服务地址（默认端口为8080） 在右上角admin下拉框中选择Manage Ambari 选择左边栏的Versions，点击HDP版本链接 此时会发现Repositories中多出HDF-3.3一栏，填入之前制作的本地源地址即可本文地址为：http://192.168.0.151:88/ambari/HDF/centos7/3.3.1.0-10 点击save保存 返回主界面，添加service时就会发现多了NiFi等HDF支持的组件 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"HDF","slug":"HDF","permalink":"http://blog.hming.org/tags/HDF/"},{"name":"离线安装","slug":"离线安装","permalink":"http://blog.hming.org/tags/%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/"}]},{"title":"Maven使用Hortonworks依赖包","slug":"Maven使用Hortonworks依赖包","date":"2019-01-12T03:32:16.000Z","updated":"2019-01-17T00:53:14.000Z","comments":true,"path":"2019/01/12/maven-shi-yong-hortonworks-yi-lai-bao/","link":"","permalink":"http://blog.hming.org/2019/01/12/maven-shi-yong-hortonworks-yi-lai-bao/","excerpt":"","text":"参考链接：where can i find HDP maven Repos在项目中连接HDP时，会出现HortonWorks的Maven依赖包下载不了的情况，只需要在pom.xml中添加如下代码： &lt;repositories> &lt;repository> &lt;releases> &lt;enabled>true&lt;/enabled> &lt;/releases> &lt;snapshots> &lt;enabled>true&lt;/enabled> &lt;/snapshots> &lt;id>hortonworks.extrepo&lt;/id> &lt;name>Hortonworks HDP&lt;/name> &lt;url>http://repo.hortonworks.com/content/repositories/releases&lt;/url> &lt;/repository> &lt;repository> &lt;releases> &lt;enabled>true&lt;/enabled> &lt;/releases> &lt;snapshots> &lt;enabled>true&lt;/enabled> &lt;/snapshots> &lt;id>hortonworks.other&lt;/id> &lt;name>Hortonworks Other Dependencies&lt;/name> &lt;url>http://repo.hortonworks.com/content/groups/public&lt;/url> &lt;/repository> &lt;/repositories> 另外，在mvnrepository官网最新版可能没有更新，可以去HortonWorks依赖包官网查看最新版本 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Maven","slug":"Maven","permalink":"http://blog.hming.org/tags/Maven/"},{"name":"HDP","slug":"HDP","permalink":"http://blog.hming.org/tags/HDP/"},{"name":"Hortonworks","slug":"Hortonworks","permalink":"http://blog.hming.org/tags/Hortonworks/"}]},{"title":"CentOS7离线安装HDP","slug":"CentOS7离线安装HDP","date":"2019-01-09T12:07:15.000Z","updated":"2019-04-09T01:52:24.000Z","comments":true,"path":"2019/01/09/centos7-chi-xian-an-zhuang-hdp/","link":"","permalink":"http://blog.hming.org/2019/01/09/centos7-chi-xian-an-zhuang-hdp/","excerpt":"","text":"本文环境 节点 IP地址 hdp001 192.168.171.10 hdp002 192.168.171.11 hdp003 192.168.171.12 环境准备磁盘准备离线安装包共计10G左右，解压后共计11G左右，请保证有足够空间。 配置免密登录配置免密码登录教程请点击这里 关闭防火墙查看防火墙状态firewall-cmd --state或systemctl status firewalld临时关闭防火墙systemctl stop firewalld禁止开机启动systemctl disable firewalld 设置SELinux模式不关闭可能导致Apache http服务无法访问。 查看SELinux状态：getenforce如果是Permissive或者Disabled则可以继续安装，如果显示enforcing，则需要进行以下步骤修改模式 编辑/etc/selinux/config文件 修改SELINUX=enforcing行内容为SELINUX=permissive或者SELINUX=disabled 重启系统或者运行setenforce 0命令禁用SELinux 安装jdk、Python（所有节点）、MySQL（安装一个即可） 配置java环境教程点击这里 安装/更新Python yum -y install python 离线安装MySQL教程点击这里新建数据库hive、ambari（为后续安装做准备）。 mysql> create database hive; Query OK, 1 row affected (0.00 sec) mysql> create database ambari; Query OK, 1 row affected (0.00 sec) 下载离线包（包含HDP、ambari、HDP-UTILS、HDP-GPL（非必须））Ambari-2.7.3.0下载地址HDP-3.1.0.0相关包下载地址 注意：ambari包大小1.81G左右，HDP包8.44G左右，HDP-UTILS包86.4M左右，请确保保存路径有足够空间 安装httpd服务（Apache服务，ambari-server节点安装即可） 注意：selinux未关闭可能导致Apache服务地址403。 [root@hdp001 ~]# yum -y install httpd [root@hdp001 ~]# service httpd restart Redirecting to /bin/systemctl restart httpd.service 访问服务器80端口，查看httpd服务是否开启。 注意：配置信息如端口、映射路径可以通过编辑/etc/httpd/conf/httpd.conf文件进行修改 将压缩包解压到/var/www/html/下 注意：1.如果httpd映射路径修改过，则以修改后的为准。2.解压后一共约11G左右大小，请确保有足够空间。 [root@hdp001 ambari]# pwd /var/www/html/ambari [root@hdp001 html]# du -h -d 1 11G ./ambari 11G . [root@hdp001 ambari]# ls ambari-2.7.3.0-centos7.tar.gz HDP-3.1.0.0-centos7-rpm.tar.gz HDP-UTILS-1.1.0.22-centos7.tar.gz # 解压... [root@hdp001 ambari]# ls ambari ambari-2.7.3.0-centos7.tar.gz HDP HDP-3.1.0.0-centos7-rpm.tar.gz HDP-UTILS HDP-UTILS-1.1.0.22-centos7.tar.gz 访问服务器80端口相应/ambari/地址，可以访问到文件和文件夹即可 制作本地源 修改repo源文件 [root@hdp001 ambari]# vim ambari/centos7/2.7.3.0-139/ambari.repo 修改baseurl与gpgkey值为Apache httpd服务能访问到的地址，如下： #VERSION_NUMBER=2.7.3.0-139 [ambari-2.7.3.0] #json.url = http://public-repo-1.hortonworks.com/HDP/hdp_urlinfo.json name=ambari Version - ambari-2.7.3.0 baseurl=http://hdp001:80/ambari/ambari/centos7/2.7.3.0-139 gpgcheck=1 gpgkey=http://hdp001:80/ambari/ambari/centos7/2.7.3.0-139/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins priority=1 HDP源修改方式同上 [root@hdp001 ambari]# vim HDP/centos7/3.1.0.0-78/hdp.repo #VERSION_NUMBER=3.1.0.0-78 [HDP-3.1.0.0] name=HDP Version - HDP-3.1.0.0 baseurl=http://hdp001:80/ambari/HDP/centos7/3.1.0.0-78 gpgcheck=1 gpgkey=http://hdp001:80/ambari/HDP/centos7/3.1.0.0-78/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins enabled=1 priority=1 [HDP-UTILS-1.1.0.22] name=HDP-UTILS Version - HDP-UTILS-1.1.0.22 baseurl=http://hdp001:80/ambari/HDP-UTILS/centos7/1.1.0.22 gpgcheck=1 gpgkey=http://hdp001:80/ambari/HDP-UTILS/centos7/1.1.0.22/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins enabled=1 priority=1 将repo文件拷贝到/etc/yum.repos.d/目录 [root@hdp001 ambari]# cp ambari/centos7/2.7.3.0-139/ambari.repo /etc/yum.repos.d/ [root@hdp001 ambari]# cp HDP/centos7/3.1.0.0-78/hdp.repo /etc/yum.repos.d/ 将repo文件拷贝到子节点 [root@hdp001 ambari]# cd /etc/yum.repos.d/ [root@hdp001 yum.repos.d]# pwd /etc/yum.repos.d [root@hdp001 yum.repos.d]# scp ambari.repo hdp002:/etc/yum.repos.d/ ambari.repo 100% 329 467.5KB/s 00:00 [root@hdp001 yum.repos.d]# scp ambari.repo hdp003:/etc/yum.repos.d/ ambari.repo 100% 329 510.4KB/s 00:00 [root@hdp001 yum.repos.d]# scp hdp.repo hdp002:/etc/yum.repos.d/ hdp.repo 100% 483 570.3KB/s 00:00 [root@hdp001 yum.repos.d]# scp hdp.repo hdp003:/etc/yum.repos.d/ hdp.repo 100% 483 352.4KB/s 00:00 每个节点清除yum缓存，重新建立缓存 该环节遇到报错说明yum源配置不正确，检查一下所有repo文件 [root@hdp001 ambari]# yum clean all ... [root@hdp001 ambari]# yum makecache ... [root@hdp001 ambari]# yum repolist ... 安装Ambari-server本次安装使用第三方数据库MySQL模式，默认为PostgreSQL模式（生产环境不推荐）。需提前准备好MySQL数据库连接jar包，MySQL连接驱动包下载方法 Ambari-server节点（主节点）安装Ambari-server[root@hdp001 ~]# yum -y install ambari-server ... 初始化设置使用ambari-server setup命令进行初始化操作。 以下代码段中#(1)类似标识为注解。 [root@hdp001 home]# ambari-server setup Using python /usr/bin/python Setup ambari-server Checking SELinux... SELinux status is 'disabled' Customize user account for ambari-server daemon [y/n] (n)? y #(1)选择自定义配置 Enter user account for ambari-server daemon (root): #(2)选择用户 Adjusting ambari-server permissions and ownership... Checking firewall status... Checking JDK... [1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8 [2] Custom JDK ============================================================================== Enter choice (1): 2 #(3)选择2，自定义jdk WARNING: JDK must be installed on all hosts and JAVA_HOME must be valid on all hosts. WARNING: JCE Policy files are required for configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited Strength Jurisdiction Policy Files are valid on all hosts. Path to JAVA_HOME: /home/jdk #(4)输入自己安装的jdk路径 Validating JDK on Ambari Server...done. Check JDK version for Ambari Server... JDK version found: 8 Minimum JDK version is 8 for Ambari. Skipping to setup different JDK for Ambari Server. Checking GPL software agreement... GPL License for LZO: https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html Enable Ambari Server to download and install GPL Licensed LZO packages [y/n] (n)? #(5)是否安装GPL，这里默认选择否 Completing setup... Configuring database... Enter advanced database configuration [y/n] (n)? y #(6)高级数据库配置，选是 Configuring database... ============================================================================== Choose one of the following options: [1] - PostgreSQL (Embedded) [2] - Oracle [3] - MySQL / MariaDB [4] - PostgreSQL [5] - Microsoft SQL Server (Tech Preview) [6] - SQL Anywhere [7] - BDB ============================================================================== Enter choice (1): 3 #(7)选择MySQL Hostname (localhost): hdp002 #(8)MySQL地址，这里选择hdp002主机上安装的MySQL Port (3306): #(9)MySQL端口，默认3306 Database name (ambari): #(10)MySQL中数据库名称，默认ambari（之前步骤提前建好的） Username (ambari): root #(11)MySQL用户名 Enter Database Password (bigdata): #(12)MySQL密码 Re-enter password: #(13)再次输入密码 Configuring ambari database... Enter full path to custom jdbc driver: /home/mysql-connector-java-5.1.47.jar #(14)这里输入提前准备好的MySQL连接包地址 Copying /home/mysql-connector-java-5.1.47.jar to /usr/share/java Configuring remote database connection properties... WARNING: Before starting Ambari Server, you must run the following DDL directly from the database shell to create the schema: /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql #(15)这里会提示开启ambari服务之前需要执行DDl建表语句 Proceed with configuring remote database connection properties [y/n] (y)? #(16)继续配置远程数据库连接属性 Extracting system views... ambari-admin-2.7.3.0.139.jar .... Ambari repo file contains latest json url http://public-repo-1.hortonworks.com/HDP/hdp_urlinfo.json, updating stacks repoinfos with it... Adjusting ambari-server permissions and ownership... Ambari Server 'setup' completed successfully. 根据上文提示执行DDL语句。将/var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql文件拷贝到MySQL安装节点，并在ambari数据库中执行该脚本。 [root@hdp001 home]# scp /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql hdp002:/home Ambari-DDL-MySQL-CREATE.sql 100% 82KB 39.1MB/s 00:00 [root@hdp002 home]# pwd /home [root@hdp002 home]# ls Ambari-DDL-MySQL-CREATE.sql jdk [root@hdp002 home]# mysql -uroot -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 4 Server version: 5.7.24 MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> use ambari; Database changed mysql> source /home/Ambari-DDL-MySQL-CREATE.sql; ... ... 启动ambari-server执行ambari-server start命令启动服务 [root@hdp001 home]# ambari-server start Using python /usr/bin/python Starting ambari-server Ambari Server running with administrator privileges. ERROR: Exiting with exit code -1. REASON: Before starting Ambari Server, you must copy the MySQL JDBC driver JAR file to /usr/share/java and set property \"server.jdbc.driver.path=[path/to/custom_jdbc_driver]\" in ambari.properties. 报错。根据提示信息，将MySQL连接包拷贝到/usr/share/java/目录下，并设置参数路径（也可在之后安装hive相关组件时设置该参数）。可能会遇到/usr/share/java不是一个目录的情况，此时删掉该文件，新建一个java目录即可。 [root@hdp001 home]# cp /home/mysql-connector-java-5.1.47.jar /usr/share/java/ 再次启动ambari-server即可启动成功 [root@hdp001 home]# ambari-server start Using python /usr/bin/python Starting ambari-server Ambari Server running with administrator privileges. Organizing resource files at /var/lib/ambari-server/resources... Ambari database consistency check started... Server PID at: /var/run/ambari-server/ambari-server.pid Server out at: /var/log/ambari-server/ambari-server.out Server log at: /var/log/ambari-server/ambari-server.log Waiting for server start............................................................ Server started listening on 8080 DB configs consistency check: no errors and warnings were found. Ambari Server 'start' completed successfully. 访问服务器8080端口默认用户名和密码都为admin根据提示安装集群设置集群名字，比如my_hadoop选择HDP版本，配置yum源地址配置host与ssh确认后开始在节点上安装ambari-agent 安装agent时可能报错： ... Connection to node1 closed. SSH command execution finished host=node1, exitcode=0 Command end time 2019-01-15 15:52:22 Registering with the server... Registration with the server failed. 解决方法：报错的节点编辑文件：/etc/ambari-agent/conf/ambari-agent.ini，将hostname修改为正确值 ... [server] hostname=master1 url_port=8440 secured_url_port=8441 connect_retry_delay=10 max_reconnect_retry_delay=30 ... ambari-agent安装成功选择hadoop组件进行安装，建议安装少量组件，之后可以再添加选择主节点安装位置（如NameNode）选择从节点安装位置（如DataNode）进行其他设置（如密码、数据保存路径、用户/用户组、参数配置等）配置完成后，查看配置项是否无误，确认无误后点击发布开始安装等待安装进度完成即可，如果安装过程中出错，可根据报错信息进行修改直到安装成功 使用HDPHDP安装路径 名称 安装路径 HDP各组件默认安装目录 /usr/hdp/版本号 ambari-server安装目录 /usr/lib/ambari-server ambari-agent安装目录 /usr/lib/ambari-agent 日志安装目录 /var/log ambari安装的hdp路径是不能更改的，但是可以用软链接将以上路径链接到其他路径。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"离线安装","slug":"离线安装","permalink":"http://blog.hming.org/tags/%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/"},{"name":"HDP","slug":"HDP","permalink":"http://blog.hming.org/tags/HDP/"}]},{"title":"Hive2之LLAP搭建","slug":"Hive2之LLAP搭建","date":"2019-01-03T11:22:48.000Z","updated":"2019-01-03T11:22:48.000Z","comments":true,"path":"2019/01/03/hive2-zhi-llap-da-jian/","link":"","permalink":"http://blog.hming.org/2019/01/03/hive2-zhi-llap-da-jian/","excerpt":"","text":"官方介绍llap-longlived-execution-in-hiveHortonworks介绍参考搭建文章：tez hive llap安装Hive llap服务安装说明及测试Hive Llap尝试（0） document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Hive","slug":"Hive","permalink":"http://blog.hming.org/tags/Hive/"},{"name":"LLAP","slug":"LLAP","permalink":"http://blog.hming.org/tags/LLAP/"},{"name":"Tez","slug":"Tez","permalink":"http://blog.hming.org/tags/Tez/"}]},{"title":"Tez以及Tez UI安装方法","slug":"Tez以及Tez-UI安装方法","date":"2019-01-03T07:16:17.000Z","updated":"2019-01-03T07:16:17.000Z","comments":true,"path":"2019/01/03/tez-yi-ji-tez-ui-an-zhuang-fang-fa/","link":"","permalink":"http://blog.hming.org/2019/01/03/tez-yi-ji-tez-ui-an-zhuang-fang-fa/","excerpt":"","text":"本文Tez版本：0.9.1 安装Tez安装Tez 0.9.0 Tez UI安装官方文档yarn timeline server大致步骤： 安装tomcat（ui需要运行在tomcat下） 将tez-ui.war包解压到tomcat中webapp/tez-ui/目录下 修改../tomcat/webapps/tez-ui/config/configs.env文件指定timeline地址和resourceManager地址 修改tez-site.xml文件，修改yarn-site.xml文件，使其支持timeline 启动timeline，yarn-daemon.sh start timelineserver或者yarn timelineserver 启动tomcat，访问http://hadoopmaster:8080/tez-ui地址 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Tez","slug":"Tez","permalink":"http://blog.hming.org/tags/Tez/"}]},{"title":"CentOS7下搭建HBase集群+HBase基本操作","slug":"CentOS7下搭建HBase集群+HBase基本操作","date":"2018-12-15T07:47:39.000Z","updated":"2018-12-18T03:12:45.000Z","comments":true,"path":"2018/12/15/centos7-xia-da-jian-hbase-ji-qun-hbase-ji-ben-cao-zuo/","link":"","permalink":"http://blog.hming.org/2018/12/15/centos7-xia-da-jian-hbase-ji-qun-hbase-ji-ben-cao-zuo/","excerpt":"","text":"本文环境 节点 IP地址 hadoopmaster 192.168.171.10 hadoop001 192.168.171.11 hadoop002 192.168.171.12 下载安装包下载地址：http://archive.apache.org/dist/hbase/根据需要选择合适的版本，本文为hbase-1.4.8-bin.tar.gz 上传、解压使用rz 命令上传到服务器并解压 [root@hadoopmaster opt]# tar -zxvf hbase-1.4.8-bin.tar.gz 配置环境变量（每个节点都需要配置）vim /etc/profile # hbase export HBASE_HOME=/home/hbase # hbase解压安装路径 export PATH=$PATH:$HBASE_HOME/bin 配置后使用source /etc/profile刷新配置文件 配置java路径，关闭内置zk集群修改hbase/conf/hbase-env.sh，修改或增加以下内容 ... export JAVA_HOME=/home/jdk ... export HBASE_MANAGES_ZK=fakse 修改配置文件 修改hbase/conf/hbase-site.xml配置文件 更多参数配置参考：hbase_default_configurations &lt;configuration> &lt;property> &lt;name>hbase.cluster.distributed&lt;/name> &lt;value>true&lt;/value> &lt;/property> &lt;property> &lt;name>hbase.rootdir&lt;/name> &lt;value>hdfs://hadoopmaster:9000/hbase&lt;/value> &lt;/property> &lt;property> &lt;!-- 配置master节点ip地址/主机名 --> &lt;name>hbase.master.hostname&lt;/name> &lt;value>hadoopmaster&lt;/value> &lt;/property> &lt;property> &lt;!-- 配置master节点端口 --> &lt;name>hbase.master.port&lt;/name> &lt;value>16000&lt;/value> &lt;/property> &lt;property> &lt;name>dfs.replication&lt;/name> &lt;value>2&lt;/value> &lt;/property> &lt;property> &lt;name>hbase.zookeeper.quorum&lt;/name> &lt;value>hadoopmaster:2181,hadoop001:2181,hadoop002:2181&lt;/value> &lt;/property> &lt;!-- 不需要 &lt;property> &lt;name>hbase.zookeeper.property.dataDir&lt;/name> &lt;value>/home/centos/hbase/zk&lt;/value> &lt;/property> --> &lt;/configuration> 注意： 需要指定HDFS中储存路径，hadoop集群搭建参考：CentOS7下搭建Hadoop集群 需要指定Zookeeper服务，Zookeeper集群搭建参考：搭建Zookeeper集群 修改hbase/conf/regionservers文件 # 增加从节点地址（这里由于配置了hosts，直接使用主机名，也可以配ip地址） hadoop001 hadoop002 将文件夹copy到其他子节点通过scp 命令将修改好的文件夹拷贝到各个从节点上[root@hadoopmaster ~]# scp -r /opt/hbase-1.4.8/ hadoop001:/opt ... [root@hadoopmaster ~]# scp -r /opt/hbase-1.4.8/ hadoop002:/opt 确保HDFS与Zookeeper启动xzk_cluster脚本参考：zk集群脚本编写xzk-cluster.sh start start-dfs.sh 启动HBase集群[root@hadoopmaster opt]# start-hbase.sh running master, logging to /home/hbase/logs/hbase-root-master-hadoopmaster.out hadoop001: running regionserver, logging to /home/hbase/bin/../logs/hbase-root-regionserver-hadoop001.out hadoop002: running regionserver, logging to /home/hbase/bin/../logs/hbase-root-regionserver-hadoop002.out 出现警告：Java HotSpot(TM) 64-Bit Server VM warning: ignoring option PermSize=128m; support was removed in 8.0解决方法：注释hbase/conf/hbase-env.sh脚本中以下代码，分发到节点 # Configure PermSize. Only needed in JDK7. You can safely remove it for JDK8+ export HBASE_MASTER_OPTS=\"$HBASE_MASTER_OPTS -XX:PermSize=128m -XX:MaxPermSize=128m -XX:ReservedCodeCacheSize=256m\" export HBASE_REGIONSERVER_OPTS=\"$HBASE_REGIONSERVER_OPTS -XX:PermSize=128m -XX:MaxPermSize=128m -XX:ReservedCodeCacheSize=256m\" 验证web界面访问：http://hadoopmaster:16010 单例管理HBase的每个进程$> start-hbase.sh //启动所有节点 $> stop-hbase.sh //停止所有节点 $> hbase-daemon.sh start master //启动master节点 $> hbase-daemons.sh start regionserver //启动所有rs节点 $> hbase-daemon.sh start regionserver //启动单个rs节点 HBase在HDFS中目录表示含义 路径 含义 /hbase/WALs 写前日志 /hbase/data 数据 /hbase/data/default hbase内置默认名字空间 /hbase/data/hbase hbase内置的名字空间（相当于hive中的数据库） 文件表示完整路径示意：/hbase/data/${namespace}/${tablename}/${region_name}/${column_family}/${file_name} HBase常用命令$> hbase shell //进入hbase shell $hbase> help //查看帮助 $hbase> list_namespace //查看名字空间(数据库) $hbase> list_namespace_tables 'hbase' //查看指定空间（hbase空间）下的表 $hbase> scan 'hbase:meta' //查看表 $hbase> create_namespace 'ns1' //创建名字空间 $hbase> create 'ns1:t1' , 'f1' //创建表 $hbase> scan 'ns1:t1' //扫描表 $hbase> describe 't1' 或者 desc 't1' //查看表结构 $hbase> truncate 'ns1:t1' //清空表数据 $hbase> put 'ns1:t1','row1','f1:id',1 //插入数据table,row,f:c,value $hbase> delete 'ns1:t1','row1','f1:id' //删除 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"HBase","slug":"HBase","permalink":"http://blog.hming.org/tags/HBase/"},{"name":"集群","slug":"集群","permalink":"http://blog.hming.org/tags/%E9%9B%86%E7%BE%A4/"}]},{"title":"搭建Zookeeper集群","slug":"搭建Zookeeper集群","date":"2018-12-15T03:18:14.000Z","updated":"2018-12-15T08:29:28.000Z","comments":true,"path":"2018/12/15/da-jian-zookeeper-ji-qun/","link":"","permalink":"http://blog.hming.org/2018/12/15/da-jian-zookeeper-ji-qun/","excerpt":"","text":"本文环境 节点 IP地址 hadoopmaster 192.168.171.10 hadoop001 192.168.171.11 hadoop002 192.168.171.12 下载安装包下载地址：http://mirrors.shu.edu.cn/apache/zookeeper/根据需要选择合适的版本，本文为zookeeper-3.4.12.tar.gz 上传、解压使用rz 命令上传到服务器并解压 [root@hadoopmaster opt]# tar -zxvf zookeeper-3.4.12.tar.gz 配置环境变量（每个节点都需要配置）vim /etc/profile # zookeeper export ZK_HOME=/home/zookeeper # zookeeper解压安装目录 export PATH=$PATH:$ZK_HOME/bin 配置后使用source /etc/profile刷新配置文件 配置参数文件 配置conf/zoo.cfg文件 拷贝配置文件cp zoo_sample.cfg zoo.cfg [root@hadoopmaster conf]# ls configuration.xsl log4j.properties zoo_sample.cfg [root@hadoopmaster conf]# cp zoo_sample.cfg zoo.cfg [root@hadoopmaster conf]# ls configuration.xsl log4j.properties zoo.cfg zoo_sample.cfg 编辑配置文件(每个节点配置一样) tickTime=2000 initLimit=5 syncLimit=2 dataDir=/home/zookeeper/data clientPort=2181 server.1=hadoopmaster:2888:3888 server.2=hadoop001:2888:3888 server.3=hadoop002:2888:3888 配置data/myid文件 新建myid文件，路径为zoo.cfg文件中dataDir指定的路径，本文为/home/zookeeper/data hadoopmaster节点： [root@hadoopmaster conf]# echo 1 >> /home/zookeeper/data/myid hadoop001节点： [root@hadoop001 conf]# echo 2 >> /home/zookeeper/data/myid hadoop002节点： [root@hadoop002 conf]# echo 3 >> /home/zookeeper/data/myid 启动服务器集群（每个节点都要启动）[root@hadoopmaster opt]# /home/zookeeper/bin/zkServer.sh start [root@hadoop001 opt]# /home/zookeeper/bin/zkServer.sh start [root@hadoop002 opt]# /home/zookeeper/bin/zkServer.sh start 使用zkServer.sh status命令查看状态[root@hadoopmaster conf]# /home/zookeeper/bin/zkServer.sh status ZooKeeper JMX enabled by default Using config: /home/zookeeper/bin/../conf/zoo.cfg Mode: follower zk集群脚本编写将脚本放到/usr/local/bin/目录方便使用vim /usr/local/bin/xzk-cluster.shchmod 755 /usr/local/bin/xzk-cluster.sh修改权限脚本内容如下#!/bin/bash cmd=$1 servers=\"hadoopmaster hadoop001 hadoop002\" for s in $servers ; do tput setaf 3 echo ========== $s ========== tput setaf 7 ssh $s \"source /etc/profile ; zkServer.sh $cmd\" done 使用脚本范例：[root@hadoopmaster conf]# xzk-cluster.sh status ========== hadoopmaster ========== ZooKeeper JMX enabled by default Using config: /home/zookeeper/bin/../conf/zoo.cfg Mode: follower ========== hadoop001 ========== ZooKeeper JMX enabled by default Using config: /home/zookeeper/bin/../conf/zoo.cfg Mode: leader ========== hadoop002 ========== ZooKeeper JMX enabled by default Using config: /home/zookeeper/bin/../conf/zoo.cfg Mode: follower [root@hadoopmaster conf]# xzk-cluster.sh stop ========== hadoopmaster ========== ZooKeeper JMX enabled by default Using config: /home/zookeeper/bin/../conf/zoo.cfg Stopping zookeeper ... STOPPED ========== hadoop001 ========== ZooKeeper JMX enabled by default Using config: /home/zookeeper/bin/../conf/zoo.cfg Stopping zookeeper ... STOPPED ========== hadoop002 ========== ZooKeeper JMX enabled by default Using config: /home/zookeeper/bin/../conf/zoo.cfg Stopping zookeeper ... STOPPED document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://blog.hming.org/tags/Zookeeper/"}]},{"title":"Hive使用Spark引擎替代MR（Hive on Spark）","slug":"Hive使用Spark引擎替代MR（Hive-on-Spark）","date":"2018-12-09T09:19:50.000Z","updated":"2018-12-09T09:19:50.000Z","comments":true,"path":"2018/12/09/hive-shi-yong-spark-yin-qing-ti-dai-mr-hive-on-spark/","link":"","permalink":"http://blog.hming.org/2018/12/09/hive-shi-yong-spark-yin-qing-ti-dai-mr-hive-on-spark/","excerpt":"","text":"官方文档参考文章 编译成功示例： ... [INFO] [INFO] --- maven-antrun-plugin:1.8:run (default) @ spark-assembly_2.11 --- [INFO] Executing tasks main: [INFO] Executed tasks [INFO] ------------------------------------------------------------------------ [INFO] Reactor Summary: [INFO] [INFO] Spark Project Parent POM 2.0.0 ..................... SUCCESS [02:06 min] [INFO] Spark Project Tags ................................. SUCCESS [01:33 min] [INFO] Spark Project Sketch ............................... SUCCESS [ 12.649 s] [INFO] Spark Project Networking ........................... SUCCESS [ 22.077 s] [INFO] Spark Project Shuffle Streaming Service ............ SUCCESS [ 15.268 s] [INFO] Spark Project Unsafe ............................... SUCCESS [ 24.808 s] [INFO] Spark Project Launcher ............................. SUCCESS [ 54.464 s] [INFO] Spark Project Core ................................. SUCCESS [07:09 min] [INFO] Spark Project GraphX ............................... SUCCESS [ 31.348 s] [INFO] Spark Project Streaming ............................ SUCCESS [01:04 min] [INFO] Spark Project Catalyst ............................. SUCCESS [02:22 min] [INFO] Spark Project SQL .................................. SUCCESS [02:50 min] [INFO] Spark Project ML Local Library ..................... SUCCESS [ 27.201 s] [INFO] Spark Project ML Library ........................... SUCCESS [02:25 min] [INFO] Spark Project Tools ................................ SUCCESS [ 7.599 s] [INFO] Spark Project Hive ................................. SUCCESS [01:15 min] [INFO] Spark Project REPL ................................. SUCCESS [ 9.934 s] [INFO] Spark Project YARN Shuffle Service ................. SUCCESS [ 14.017 s] [INFO] Spark Project YARN ................................. SUCCESS [ 39.637 s] [INFO] Spark Project Assembly ............................. SUCCESS [ 3.878 s] [INFO] Spark Project External Flume Sink .................. SUCCESS [ 24.054 s] [INFO] Spark Project External Flume ....................... SUCCESS [ 21.908 s] [INFO] Spark Project External Flume Assembly .............. SUCCESS [ 5.095 s] [INFO] Spark Integration for Kafka 0.8 .................... SUCCESS [ 20.951 s] [INFO] Spark Project Examples ............................. SUCCESS [ 37.750 s] [INFO] Spark Project External Kafka Assembly .............. SUCCESS [ 6.523 s] [INFO] Spark Integration for Kafka 0.10 ................... SUCCESS [ 20.073 s] [INFO] Spark Integration for Kafka 0.10 Assembly .......... SUCCESS [ 5.019 s] [INFO] Spark Project Java 8 Tests 2.0.0 ................... SUCCESS [ 11.790 s] [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 27:45 min [INFO] Finished at: 2018-12-09T20:51:07+08:00 [INFO] ------------------------------------------------------------------------ + rm -rf /opt/spark-2.0.0/dist + mkdir -p /opt/spark-2.0.0/dist/jars + echo 'Spark 2.0.0 built for Hadoop 2.7.2' + echo 'Build flags: -Pyarn,hadoop-provided,hadoop-2.7,parquet-provided' ... document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Hive","slug":"Hive","permalink":"http://blog.hming.org/tags/Hive/"},{"name":"Spark","slug":"Spark","permalink":"http://blog.hming.org/tags/Spark/"}]},{"title":"MySQL连接驱动包下载方法","slug":"MySQL连接驱动包下载方法","date":"2018-12-09T06:43:33.000Z","updated":"2018-12-09T06:43:33.000Z","comments":true,"path":"2018/12/09/mysql-lian-jie-qu-dong-bao-xia-zai-fang-fa/","link":"","permalink":"http://blog.hming.org/2018/12/09/mysql-lian-jie-qu-dong-bao-xia-zai-fang-fa/","excerpt":"","text":"下载链接地址官方下载地址：https://dev.mysql.com/downloads/connector/j/ 下载步骤选择版本默认为最新版本，可以按如下所示选择历史版本 选择操作系统 确认下载后缀为.tar.gz 跳过登录直接下载 压缩包中jar包 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"数据库","slug":"数据库","permalink":"http://blog.hming.org/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.hming.org/tags/MySQL/"},{"name":"驱动包","slug":"驱动包","permalink":"http://blog.hming.org/tags/%E9%A9%B1%E5%8A%A8%E5%8C%85/"},{"name":"连接","slug":"连接","permalink":"http://blog.hming.org/tags/%E8%BF%9E%E6%8E%A5/"}]},{"title":"CentOS7下离线安装MySQL","slug":"CentOS7下离线安装MySQL","date":"2018-12-08T06:22:14.000Z","updated":"2019-07-22T07:06:59.000Z","comments":true,"path":"2018/12/08/centos7-xia-chi-xian-an-zhuang-mysql/","link":"","permalink":"http://blog.hming.org/2018/12/08/centos7-xia-chi-xian-an-zhuang-mysql/","excerpt":"","text":"下载社区版离线安装包本文为mysql-5.7.24-1.el7.x86_64.rpm-bundle.tar下载路径：https://dev.mysql.com/downloads/mysql/5.7.html#downloads 选择适合CentOS的版本 跳过登录直接下载 卸载系统自带的mariadb-lib[root@hadoopmaster opt]# rpm -qa|grep mariadb mariadb-libs-5.5.56-2.el7.x86_64 [root@hadoopmaster opt]# rpm -e --nodeps mariadb-libs-5.5.56-2.el7.x86_64 解压mysql 使用rz 命令上传文件到服务器 解压[root@hadoopmaster mysql]# tar -xf mysql-5.7.24-1.el7.x86_64.rpm-bundle.tar [root@hadoopmaster mysql]# ls mysql-5.7.24-1.el7.x86_64.rpm-bundle.tar mysql-community-client-5.7.24-1.el7.x86_64.rpm mysql-community-common-5.7.24-1.el7.x86_64.rpm mysql-community-devel-5.7.24-1.el7.x86_64.rpm mysql-community-embedded-5.7.24-1.el7.x86_64.rpm mysql-community-embedded-compat-5.7.24-1.el7.x86_64.rpm mysql-community-embedded-devel-5.7.24-1.el7.x86_64.rpm mysql-community-libs-5.7.24-1.el7.x86_64.rpm mysql-community-libs-compat-5.7.24-1.el7.x86_64.rpm mysql-community-minimal-debuginfo-5.7.24-1.el7.x86_64.rpm mysql-community-server-5.7.24-1.el7.x86_64.rpm mysql-community-server-minimal-5.7.24-1.el7.x86_64.rpm mysql-community-test-5.7.24-1.el7.x86_64.rpm 安装使用rpm -ivh命令依次进行安装按顺序安装以下软件包 mysql-community-common-5.7.24-1.el7.x86_64.rpm mysql-community-libs-5.7.24-1.el7.x86_64.rpm mysql-community-client-5.7.24-1.el7.x86_64.rpm mysql-community-server-5.7.24-1.el7.x86_64.rpm 有时可能需要安装以下包 mysql-community-libs-compat-5.7.24-1.el7.x86_64.rpm 安装具体如下 [root@hadoopmaster mysql]# rpm -ivh mysql-community-common-5.7.24-1.el7.x86_64.rpm 警告：mysql-community-common-5.7.24-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY 准备中... ################################# [100%] 正在升级/安装... 1:mysql-community-common-5.7.24-1.e################################# [100%] [root@hadoopmaster mysql]# rpm -ivh mysql-community-libs-5.7.24-1.el7.x86_64.rpm 警告：mysql-community-libs-5.7.24-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY 准备中... ################################# [100%] 正在升级/安装... 1:mysql-community-libs-5.7.24-1.el7################################# [100%] [root@hadoopmaster mysql]# rpm -ivh mysql-community-client-5.7.24-1.el7.x86_64.rpm 警告：mysql-community-client-5.7.24-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY 准备中... ################################# [100%] 正在升级/安装... 1:mysql-community-client-5.7.24-1.e################################# [100%] [root@hadoopmaster mysql]# rpm -ivh mysql-community-server-5.7.24-1.el7.x86_64.rpm 警告：mysql-community-server-5.7.24-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY 准备中... ################################# [100%] 正在升级/安装... 1:mysql-community-server-5.7.24-1.e################################# [100%] 注意：安装mysql-community-server-5.7.24-1.el7.x86_64.rpm时可能会遇到问题:` [root@hadoopmaster mysql]# rpm -ivh mysql-community-server-5.7.24-1.el7.x86_64.rpm 警告：mysql-community-server-5.7.24-1.el7.x86_64.rpm: 头V3 DSA/SHA1 Signature, 密钥 ID 5072e1f5: NOKEY 错误：依赖检测失败： libaio.so.1()(64bit) 被 mysql-community-server-5.7.24-1.el7.x86_64 需要 libaio.so.1(LIBAIO_0.1)(64bit) 被 mysql-community-server-5.7.24-1.el7.x86_64 需要 libaio.so.1(LIBAIO_0.4)(64bit) 被 mysql-community-server-5.7.24-1.el7.x86_64 需要 net-tools 被 mysql-community-server-5.7.24-1.el7.x86_64 需要 解决办法： 1）缺少libaio [root@hadoopmaster mysql]# yum -y install libaio 2）缺少net-tools [root@hadoopmaster mysql]# yum -y install net-tools 初始化数据库初始化后会在/var/log/mysqld.log生成随机密码 [root@hadoopmaster mysql]# mysqld --initialize [root@hadoopmaster mysql]# cat /var/log/mysqld.log 2018-12-08T07:53:52.970182Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details). 2018-12-08T07:53:54.251035Z 0 [Warning] InnoDB: New log files created, LSN=45790 2018-12-08T07:53:54.313973Z 0 [Warning] InnoDB: Creating foreign key constraint system tables. 2018-12-08T07:53:54.388855Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: 68ce693c-fabe-11e8-a2ff-000c298184c2. 2018-12-08T07:53:54.389442Z 0 [Warning] Gtid table is not ready to be used. Table 'mysql.gtid_executed' cannot be opened. 2018-12-08T07:53:54.390177Z 1 [Note] A temporary password is generated for root@localhost: qHQHahCw(7n) 最后一串随机字符串为初始密码，本文中为qHQHahCw(7n) 修改用户及用户组，启动mysql数据库修改mysql数据库目录的所属用户及其所属组，然后启动mysql数据库 [root@hadoopmaster mysql]# chown mysql:mysql /var/lib/mysql -R [root@hadoopmaster mysql]# systemctl start mysqld.service [root@hadoopmaster mysql]# systemctl status mysqld.service ● mysqld.service - MySQL Server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since 六 2018-12-08 15:59:12 CST; 6s ago Docs: man:mysqld(8) http://dev.mysql.com/doc/refman/en/using-systemd.html Process: 23162 ExecStart=/usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid $MYSQLD_OPTS (code=exited, status=0/SUCCESS) Process: 23145 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS) Main PID: 23165 (mysqld) CGroup: /system.slice/mysqld.service └─23165 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid 12月 08 15:59:10 hadoopmaster systemd[1]: Starting MySQL Server... 12月 08 15:59:12 hadoopmaster systemd[1]: Started MySQL Server. 设置开机自启动查看是否开启开机自启动 [root@hadoopmaster mysql-install]# systemctl list-unit-files | grep mysqld mysqld.service enabled mysqld@.service disabled 注意：mysql5.7.23安装后已默认设置为开机启动，如果没有设置，可以使用下面命令设置为开机启动 [root@hadoopmaster mysql]# systemctl enable mysqld.service 登录，更改root用户密码登录mysql，更改root用户密码（系统强制要求，否则不能操作mysql） [root@hadoopmaster mysql-install]# mysql -uroot -p'qHQHahCw(7n)' mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 2 Server version: 5.7.24 Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> set password=password('1234'); Query OK, 0 rows affected, 1 warning (0.00 sec) mysql> show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.00 sec) 远程登录授权命令为：grant all privileges on *.* to 'root'@'%' identified by '1234' with grant option;flush privileges; *.* 表示授权任何库任何表，如果想只授权test库的user表可以写为：test.user'root'@'%' 其中root表示以root用户授权，@为连接符，%表示匹配所有的主机，如果想单独给某主机授权，可以将%替换为需要授权的主机ip地址'1234' 表示授权访问的密码，可以自行设置密码设置授权后需要用flush privileges命令刷新一下 示例： mysql> grant all privileges on *.* to 'root'@'%' identified by '1234' with grant option; Query OK, 0 rows affected, 1 warning (0.00 sec) mysql> flush privileges; Query OK, 0 rows affected (0.00 sec) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"数据库","slug":"数据库","permalink":"http://blog.hming.org/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://blog.hming.org/tags/Linux/"},{"name":"MySQL","slug":"MySQL","permalink":"http://blog.hming.org/tags/MySQL/"}]},{"title":"使用图形化界面工具DbVisualizer连接Hive数据库","slug":"使用图形化界面工具DbVisualizer连接Hive数据库","date":"2018-12-08T02:53:42.000Z","updated":"2018-12-08T02:53:42.000Z","comments":true,"path":"2018/12/08/shi-yong-tu-xing-hua-jie-mian-gong-ju-dbvisualizer-lian-jie-hive-shu-ju-ku/","link":"","permalink":"http://blog.hming.org/2018/12/08/shi-yong-tu-xing-hua-jie-mian-gong-ju-dbvisualizer-lian-jie-hive-shu-ju-ku/","excerpt":"","text":"参考链接：https://www.cnblogs.com/qingyunzong/p/8715250.html document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"Hive","slug":"Hive","permalink":"http://blog.hming.org/tags/Hive/"},{"name":"DbVisualizer","slug":"DbVisualizer","permalink":"http://blog.hming.org/tags/DbVisualizer/"},{"name":"图形化工具","slug":"图形化工具","permalink":"http://blog.hming.org/tags/%E5%9B%BE%E5%BD%A2%E5%8C%96%E5%B7%A5%E5%85%B7/"}]},{"title":"CentOS7下搭建Hive","slug":"CentOS7下搭建Hive","date":"2018-12-06T07:18:49.000Z","updated":"2019-01-03T12:45:43.000Z","comments":true,"path":"2018/12/06/centos7-xia-da-jian-hive/","link":"","permalink":"http://blog.hming.org/2018/12/06/centos7-xia-da-jian-hive/","excerpt":"","text":"搭建Hadoop集群参考CentOS7下搭建Hadoop集群 下载Hive压缩包找到合适版本下载hive，本文压缩包为apache-hive-2.3.4-bin.tar.gz下载地址 解压，配置环境变量 解压到指定目录（本文目录为/home/hive）tar -zxvf apache-hive-2.3.4-bin.tar.gz 配置环境变量vim /etc/profile，添加以下代码 # hive export HIVE_HOME=/home/hive # 为hive解压目录 export PATH=$PATH:${HIVE_HOME}/bin 刷新配置文件source /etc/profile 验证hive版本hive --version [root@hadoopmaster hive]# hive --version Hive 2.3.4 Git git://daijymacpro-2.local/Users/daijy/commit/hive -r 56acdd2120b9ce6790185c679223b8b5e884aaf2 Compiled by daijy on Wed Oct 31 14:20:50 PDT 2018 From source with checksum 9f2d17b212f3a05297ac7dd40b65bab0 hive-env.sh配置 复制/home/hive/conf/hive-env.sh.template -&gt; /home/hive/conf/hive-env.sh[root@hadoopmaster ~]# cd /home/hive/conf [root@hadoopmaster conf]# cp hive-env.sh.template hive-env.sh 修改/home/hive/conf/hive-env.sh，找到以下配置，根据实际情况修改export JAVA_HOME=/home/jdk #jdk安装目录 export HADOOP_HOME=/home/hadoop #hadoop安装目录 export HIVE_HOME=/home/hive #hive安装目录 hive-site.xml配置 复制/home/hive/conf/hive-default.template -&gt; /home/hive/conf/hive-site.xml [root@hadoopmaster conf]# cp hive-default.xml.template hive-site.xml 修改/home/hive/conf/hive-site.xml，找到文件中以下配置，根据实际情况修改hive其他配置参考：Hive Configuration Properties &lt;configuration> &lt;!-- mysql数据库配置 --> &lt;property> &lt;name>javax.jdo.option.ConnectionPassword&lt;/name> &lt;value>1234&lt;/value> &lt;description>mysql密码&lt;/description> &lt;/property> &lt;property> &lt;name>javax.jdo.option.ConnectionUserName&lt;/name> &lt;value>root&lt;/value> &lt;description>mysql用户名&lt;/description> &lt;/property> &lt;property> &lt;name>javax.jdo.option.ConnectionURL&lt;/name> &lt;value>jdbc:mysql://hadoopmaster:3306/hive?useSSL=false&lt;/value> &lt;description>JDBC连接路径&lt;/description> &lt;/property> &lt;property> &lt;name>javax.jdo.option.ConnectionDriverName&lt;/name> &lt;value>com.mysql.jdbc.Driver&lt;/value> &lt;description>Driver class name for a JDBC metastore&lt;/description> &lt;/property> &lt;!-- 其他配置 --> &lt;property> &lt;name>hive.cli.print.header&lt;/name> &lt;value>true&lt;/value> &lt;description>是否显示查询结果的列名，默认为不显示。 &lt;/description> &lt;/property> &lt;property> &lt;name>hive.cli.print.current.db&lt;/name> &lt;value>true&lt;/value> &lt;description>是否显示数据库名称，默认为不显示&lt;/description> &lt;/property> &lt;property> &lt;name>hive.server2.webui.port&lt;/name> &lt;value>10002&lt;/value> &lt;description>HiveServer2 Web页面端口设置&lt;/description> &lt;/property> &lt;property> &lt;name>hive.exec.local.scratchdir&lt;/name> &lt;value>/home/hive/tmp&lt;/value> &lt;description>Hive作业的本地临时空间&lt;/description> &lt;/property> &lt;property> &lt;name>hive.downloaded.resources.dir&lt;/name> &lt;value>/home/hive/downloads&lt;/value> &lt;description>用于在远程文件系统中添加资源的临时本地目录。&lt;/description> &lt;/property> &lt;property> &lt;name>hive.querylog.location&lt;/name> &lt;value>/home/hive/querylog&lt;/value> &lt;description>Hive 实时查询日志所在的目录，如果该值为空，将不创建实时的查询日志。&lt;/description> &lt;/property> &lt;property> &lt;name>hive.server2.logging.operation.log.location&lt;/name> &lt;value>/home/hive/server2_logs&lt;/value> &lt;description>如果启用了日志记录功能，则存储操作日志的顶级目录&lt;/description> &lt;/property> &lt;/configuration> 复制mysql驱动到hive安装目录的lib下mysql-connector-java-5.1.46.jar点我查看驱动包下载方式 初始化元数据 在mysql中创建hive数据库 运行hive的SchemaTool进行初始化hive的元数据schematool -dbType mysql -initSchema[root@hadoopmaster ~]# cd /home/hive/bin [root@hadoopmaster bin]# ./schematool # 查看帮助 [root@hadoopmaster bin]# ./schematool -dbType mysql -initSchema document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Hive","slug":"Hive","permalink":"http://blog.hming.org/tags/Hive/"},{"name":"数据仓库","slug":"数据仓库","permalink":"http://blog.hming.org/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"}]},{"title":"使用Docker搭建Nginx图片服务器","slug":"使用Docker搭建Nginx图片服务器","date":"2018-12-04T16:04:13.000Z","updated":"2018-12-04T16:04:13.000Z","comments":true,"path":"2018/12/05/shi-yong-docker-da-jian-nginx-tu-pian-fu-wu-qi/","link":"","permalink":"http://blog.hming.org/2018/12/05/shi-yong-docker-da-jian-nginx-tu-pian-fu-wu-qi/","excerpt":"","text":"安装Docker见Docker常用命令 编写Nginx配置文件vim default.conf server { listen 80; server_name localhost; #(5) #charset koi8-r; #access_log /var/log/nginx/host.access.log main; location / { root /usr/share/nginx/html; index index.html index.htm; } #(1) location /images/ { root /mnt/; autoindex on; #(2) autoindex_exact_size off; #(3) autoindex_localtime on; #(4) charset utf-8,gbk; #(5) } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } } 参数说明：(1)：添加图片目录映射，映射目录为/mnt/images/(2)：在Nginx下默认是不允许列出整个目录的。如需此功能，将该项设置为on(3)：默认为on，显示出文件的确切大小，单位是bytes 改为off后，显示出文件的大概大小，单位是kB或者MB或者GB(4)：默认为off，显示的文件时间为GMT时间 注意:改为on后，显示的文件时间为文件的服务器时间(5):设置编码（防止中文乱码），可以设置对全局生效或者部分路径生效 编写Dockerfilevim Dockerfile # 使用最小化镜像（只有17.7m） FROM nginx:stable-alpine # 这里替换为自己的信息 MAINTAINER liming # 覆盖容器里默认配置 COPY default.conf /etc/nginx/conf.d/default.conf EXPOSE 80 构建镜像docker build -t image-nginx . 运行生成容器docker run -d --name image-nginx -p 80:80 -v /mnt/nginx/images:/mnt/images image-nginx -v 将服务器本地/mnt/nginx/images映射到容器内/mnt/images目录，容器目录与default.conf文件中配置对应 访问图片通过ip地址/images/aaa.jpg访问图片配置文件服务器同理 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.hming.org/categories/Linux/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://blog.hming.org/tags/Docker/"},{"name":"Nginx","slug":"Nginx","permalink":"http://blog.hming.org/tags/Nginx/"},{"name":"服务器","slug":"服务器","permalink":"http://blog.hming.org/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}]},{"title":"Spring-Boot使用JDBC连接Hive","slug":"Spring-Boot使用JDBC连接Hive","date":"2018-11-19T11:57:43.000Z","updated":"2019-02-16T04:01:41.000Z","comments":true,"path":"2018/11/19/spring-boot-shi-yong-jdbc-lian-jie-hive/","link":"","permalink":"http://blog.hming.org/2018/11/19/spring-boot-shi-yong-jdbc-lian-jie-hive/","excerpt":"","text":"添加Maven依赖&lt;!-- hive --> &lt;dependency> &lt;groupId>org.apache.hive&lt;/groupId> &lt;artifactId>hive-jdbc&lt;/artifactId> &lt;version>2.3.3&lt;/version> &lt;/dependency> &lt;!-- hive === end --> 编写配置文件数据库连接池使用HikariCP，参数设置参考：https://github.com/brettwooldridge/HikariCP 在../resources目录下创建配置文件application-hive.yml，文件格式也可以使用properties格式 hive: jdbcurl: jdbc:hive2://10.75.4.31:10000/mydb driver-class-name: org.apache.hive.jdbc.HiveDriver username: root password: 123456 # 下面为连接池的补充设置，应用到上面所有数据源中 # 初始化大小，最小连接数，最大连接数 initialSize: 1 minimumIdle: 3 maximumPoolSize: 10 # 等待来自池的连接的最大毫秒数(创建连接超时时间) connectionTimeout: 120000 # 验证超时时间 validationTimeout: 10000 # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 idleTimeout: 30000 # 配置一个连接在池中最大生存的时间，单位是毫秒 maxLifeTime: 600000 在application.yml文件中指定激活application-hive.yml配置文件（这里也可以不配置，在config类中另外配置）。 spring: application: name: ProjectName profiles: active: hive 编写config配置类，将Hive的JdbcTemplate加载到Spring容器中 采用手动加载DataSource配置方式（不推荐） import com.zaxxer.hikari.HikariDataSource; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.boot.autoconfigure.jdbc.DataSourceProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.core.env.Environment; import org.springframework.jdbc.core.JdbcTemplate; import javax.annotation.Resource; import javax.sql.DataSource; import java.util.Objects; /** * Hive-JDBC配置 * * @author liming * @date Created in 2018/11/15 11:58 */ @Configuration public class HiveJdbcConfig { private static final Logger logger = LoggerFactory.getLogger(HiveJdbcConfig.class); @Resource private Environment env; @Bean(name = \"hiveJdbcDataSource\") public DataSource dataSource() { DataSourceProperties dataSourceProperties = new DataSourceProperties(); dataSourceProperties.setUrl(env.getProperty(\"hive.url\")); dataSourceProperties.setDriverClassName(env.getProperty(\"hive.driver-class-name\")); dataSourceProperties.setUsername(env.getProperty(\"hive.username\")); dataSourceProperties.setPassword(env.getProperty(\"hive.password\")); HikariDataSource dataSource = dataSourceProperties.initializeDataSourceBuilder().type(HikariDataSource.class).build(); //下面的配置根据实际情况添加、修改 //连接超时时间 dataSource.setConnectionTimeout(Long.valueOf(Objects.requireNonNull(env.getProperty(\"hive.connectionTimeout\")))); //连接池最大连接数 dataSource.setMaximumPoolSize(Integer.valueOf(Objects.requireNonNull(env.getProperty(\"hive.maximumPoolSize\")))); //最小闲置连接数 dataSource.setMinimumIdle(Integer.valueOf(Objects.requireNonNull(env.getProperty(\"hive.minimumIdle\")))); //配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 dataSource.setIdleTimeout(Long.parseLong(Objects.requireNonNull(env.getProperty(\"hive.idleTimeout\")))); //连接最大生存时间 dataSource.setMaxLifetime(Long.parseLong(Objects.requireNonNull(env.getProperty(\"hive.maxLifeTime\")))); //验证超时时间 dataSource.setValidationTimeout(Long.parseLong(Objects.requireNonNull(env.getProperty(\"hive.validationTimeout\")))); logger.debug(\"Hive DataSource Inject Successfully...\"); return dataSource; } @Bean(name = \"hiveJdbcTemplate\") public JdbcTemplate hiveJdbcTemplate(@Qualifier(\"hiveJdbcDataSource\") DataSource dataSource) { return new JdbcTemplate(dataSource); } } 采用自动加载DataSource配置方式（推荐）该方式需要yml配置文件中变量名与DataSource类里面的变量名对应 package tech.segma.bi.config; import com.zaxxer.hikari.HikariDataSource; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.boot.autoconfigure.jdbc.DataSourceProperties; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.jdbc.core.JdbcTemplate; import javax.sql.DataSource; /** * Hive-JDBC配置 * * @author liming * @date Created in 2018/11/15 11:58 */ @Configuration public class HiveJdbcConfig { private static final Logger LOGGER = LoggerFactory.getLogger(HiveJdbcConfig.class); @Bean @ConfigurationProperties(prefix = \"hive\")//需要配置前缀 public DataSourceProperties dataSourceProperties() { return new DataSourceProperties(); } @Bean(name = \"hiveJdbcDataSource\") @ConfigurationProperties(prefix = \"hive\")//需要配置前缀 public DataSource dataSource() { return dataSourceProperties().initializeDataSourceBuilder().type(HikariDataSource.class).build(); } @Bean(name = \"hiveJdbcTemplate\") public JdbcTemplate hiveJdbcTemplate(@Qualifier(\"hiveJdbcDataSource\") DataSource dataSource) { LOGGER.debug(\"Hive DataSource Inject Successfully...\"); return new JdbcTemplate(dataSource); } } 在代码中使用JdbcTemplate@Resource(name = \"hiveJdbcTemplate\") private JdbcTemplate hiveJdbcTemplate; public boolean loadFileToTable(String filePath, String tableName) { // String filePath = \"/home/hadoop/user_sample.txt\"; String sql = \"load data local inpath '\" + filePath + \"' into table \" + tableName; try { hiveJdbcTemplate.execute(sql); return true; } catch (DataAccessException dae) { logger.error(\"Load data into table encounter an error: \" + dae.getMessage()); return false; } } document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"Hive","slug":"Hive","permalink":"http://blog.hming.org/tags/Hive/"},{"name":"Spring Boot","slug":"Spring-Boot","permalink":"http://blog.hming.org/tags/Spring-Boot/"},{"name":"JDBC","slug":"JDBC","permalink":"http://blog.hming.org/tags/JDBC/"}]},{"title":"Hadoop修改端口后Hive连接方法","slug":"Hadoop修改端口后Hive连接方法","date":"2018-11-16T06:31:10.000Z","updated":"2018-11-19T11:48:44.000Z","comments":true,"path":"2018/11/16/hadoop-xiu-gai-duan-kou-hou-hive-lian-jie-fang-fa/","link":"","permalink":"http://blog.hming.org/2018/11/16/hadoop-xiu-gai-duan-kou-hou-hive-lian-jie-fang-fa/","excerpt":"","text":"场景描述Hadoop修改端口后，hive继续操作会报错，找不到HDFS，此时需要到元数据库中（本文为mysql）修改对应数据 操作步骤元数据库mysql里面两张表：DBS ： Hive数据仓库的路径SDS ： Hive每张表对应的路径找到对应路径端口，修改 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Hive","slug":"Hive","permalink":"http://blog.hming.org/tags/Hive/"},{"name":"Hadoop","slug":"Hadoop","permalink":"http://blog.hming.org/tags/Hadoop/"}]},{"title":"CentOS7下搭建Kubernetes环境","slug":"CentOS7下搭建kubernetes环境","date":"2018-10-31T12:32:27.000Z","updated":"2018-11-14T12:36:28.000Z","comments":true,"path":"2018/10/31/centos7-xia-da-jian-kubernetes-huan-jing/","link":"","permalink":"http://blog.hming.org/2018/10/31/centos7-xia-da-jian-kubernetes-huan-jing/","excerpt":"","text":"1.11多主高可用1.10kubeadm安装 安装配置docker v1.11.0版本推荐使用docker v17.03, v1.11,v1.12,v1.13, 也可以使用，再高版本的docker可能无法正常使用。 测试发现17.09无法正常使用，不能使用资源限制(内存CPU) 如下操作在所有节点操作 安装docker # 卸载安装指定版本docker-ce [root@master ~]# yum remove -y docker-ce docker-ce-selinux container-selinux [root@master ~]# yum install -y --setopt=obsoletes=0 \\ docker-ce-17.03.1.ce-1.el7.centos \\ docker-ce-selinux-17.03.1.ce-1.el7.centos 启动docker [root@master ~]# systemctl enable docker &amp;&amp; systemctl restart docker 安装 kubeadm, kubelet 和 kubectl 如下操作在所有节点操作 # 配置源 [root@master ~]# cat &lt;&lt;EOF > /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF # 安装 [root@master ~]# yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes 禁用交换分区swap查看交换分区：free -h [root@localhost ~]# free -h total used free shared buff/cache available Mem: 2.8G 159M 404M 112M 2.2G 2.3G Swap: 3.0G 2.8M 3.0G swapoff -a 临时禁用所有交换 [root@k8s003 save]# swapoff -a [root@k8s003 save]# free -h total used free shared buff/cache available Mem: 2.8G 158M 403M 113M 2.2G 2.3G Swap: 0B 0B 0B 永久禁用，vim /etc/fstab注释swap行，重启 # # /etc/fstab # Created by anaconda on Mon Nov 5 19:49:25 2018 # # Accessible filesystems, by reference, are maintained under '/dev/disk' # See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info # /dev/mapper/centos-root / xfs defaults 0 0 UUID=daffff7e-bc4d-4cf0-bcdd-9b4a99a77ccc /boot xfs defaults 0 0 # 注释该行 # /dev/mapper/centos-swap swap swap defaults 0 0 初始化[root@k8smaster opt]# kubeadm init --kubernetes-version=v1.10.0 --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=192.168.40.100 k8s1.6 pod apiPod是kubernetes REST API中的顶级资源类型。在kuberentes1.6的V1 core API版本中的Pod的数据结构如下图所示： docker指令和k8s指令对比指令对比 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"容器","slug":"容器","permalink":"http://blog.hming.org/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"集群","slug":"集群","permalink":"http://blog.hming.org/tags/%E9%9B%86%E7%BE%A4/"},{"name":"K8s","slug":"K8s","permalink":"http://blog.hming.org/tags/K8s/"},{"name":"容器","slug":"容器","permalink":"http://blog.hming.org/tags/%E5%AE%B9%E5%99%A8/"}]},{"title":"使用Phoenix操作HBase","slug":"使用Phoenix操作HBase","date":"2018-10-30T12:09:11.000Z","updated":"2018-12-22T10:07:12.000Z","comments":true,"path":"2018/10/30/shi-yong-phoenix-cao-zuo-hbase/","link":"","permalink":"http://blog.hming.org/2018/10/30/shi-yong-phoenix-cao-zuo-hbase/","excerpt":"","text":"HBase集群环境搭建参考：CentOS7下搭建HBase集群+HBase基本操作 下载与HBase版本兼容的Phoenixapache-phoenix-4.14.1-HBase-1.4-bin.tar.gz下载地址：http://archive.apache.org/dist/phoenix/ 解压复制phoenix-4.14.1-HBase-1.4-server.jar到hbase/lib下并分发到从节点 [root@hadoopmaster phoenix]# pwd /home/phoenix [root@hadoopmaster phoenix]# cp phoenix-4.14.1-HBase-1.4-server.jar /home/hbase/lib/ //分发 [root@hadoopmaster phoenix]# scp phoenix-4.14.1-HBase-1.4-server.jar hadoop001:/home/hbase/lib/ phoenix-4.14.1-HBase-1.4-server.jar 100% 40MB 60.4MB/s 00:00 [root@hadoopmaster phoenix]# scp phoenix-4.14.1-HBase-1.4-server.jar hadoop002:/home/hbase/lib/ phoenix-4.14.1-HBase-1.4-server.jar 100% 40MB 55.1MB/s 00:00 重启HBase[root@hadoopmaster bin]# stop-hbase.sh ... [root@hadoopmaster bin]# start-hbase.sh ... 使用sqlline.py命令行终端运行phoenix/bin/sqlline.py脚本，连接zookeeper [root@hadoopmaster bin]# pwd /home/phoenix/bin [root@hadoopmaster bin]# ./sqlline.py hadoopmaster:2181 报错： Error: SYSTEM.CATALOG (state=08000,code=101) org.apache.phoenix.exception.PhoenixIOException: SYSTEM.CATALOG at org.apache.phoenix.util.ServerUtil.parseServerException(ServerUtil.java:144) at org.apache.phoenix.query.ConnectionQueryServicesImpl.metaDataCoprocessorExec(ConnectionQueryServicesImpl.java:1379) at org.apache.phoenix.query.ConnectionQueryServicesImpl.metaDataCoprocessorExec(ConnectionQueryServicesImpl.java:1343) at org.apache.phoenix.query.ConnectionQueryServicesImpl.getTable(ConnectionQueryServicesImpl.java:1560) at org.apache.phoenix.schema.MetaDataClient.updateCache(MetaDataClient.java:643) ... at sqlline.SqlLine.start(SqlLine.java:398) at sqlline.SqlLine.main(SqlLine.java:291) Caused by: org.apache.hadoop.hbase.TableNotFoundException: SYSTEM.CATALOG at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegionInMeta(ConnectionManager.java:1283) at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1181) at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1165) ... at org.apache.phoenix.query.ConnectionQueryServicesImpl.metaDataCoprocessorExec(ConnectionQueryServicesImpl.java:1362) ... 31 more 解决方案：查看hdfs中/hbase/data/default/目录下是否有SYSTEM.*等文件。如果没有，则： 停止HBase，保留zookeeper启动 执行hbase clean --cleanZk命令 重新启动HBase，使用Phoenix连接参考链接：stackoverflow 连接成功[root@hadoopmaster bin]# ./sqlline.py hadoop001:2181 Setting property: [incremental, false] Setting property: [isolation, TRANSACTION_READ_COMMITTED] issuing: !connect jdbc:phoenix:hadoop001:2181 none none org.apache.phoenix.jdbc.PhoenixDriver Connecting to jdbc:phoenix:hadoop001:2181 SLF4J: Class path contains multiple SLF4J bindings. SLF4J: Found binding in [jar:file:/home/apache-phoenix-4.14.0-HBase-1.2-bin/phoenix-4.14.0-HBase-1.2-client.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: Found binding in [jar:file:/opt/hadoop/hadoop-2.7.6/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class] SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation. 18/10/30 03:59:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable Connected to: Phoenix (version 4.14) Driver: PhoenixEmbeddedDriver (version 4.14) Autocommit status: true Transaction isolation: TRANSACTION_READ_COMMITTED Building list of tables and columns for tab-completion (set fastconnect to true to skip)... 133/133 (100%) Done Done sqlline version 1.2.0 0: jdbc:phoenix:hadoopmaster:2181>| 开启schema对应namespacePhoenix默认使用的是HBase中default名字空间（namespace），如果要用自定义的namespace，Phoenix中与之对应的是schema的概念，但是默认是关闭的，需要单独配置。 在hbase/conf/hbase-site.xml、phoenix/bin/hbase-site.xml两个文件中增加以下代码： &lt;property> &lt;name>phoenix.schema.isNamespaceMappingEnabled&lt;/name> &lt;value>true&lt;/value> &lt;/property> &lt;property> &lt;name>phoenix.schema.mapSystemTablesToNamespace&lt;/name> &lt;value>true&lt;/value> &lt;/property> 如果HBase是分布式，则需要将文件分发到其他节点（最好是将该文件也复制到phoenix/bin/保证客户端与服务端的一致性） Phoenix其他相关配置参照：https://phoenix.apache.org/tuning.html[root@hadoopmaster conf]# scp hbase-site.xml hadoop001:/home/hbase/conf/ hbase-site.xml 100% 1569 2.2MB/s 00:00 [root@hadoopmaster conf]# scp hbase-site.xml hadoop002:/home/hbase/conf/ hbase-site.xml 100% 1569 1.6MB/s 00:00 重启HBase，重新连接 报错：Error: ERROR 726 (43M10): Inconsistent namespace mapping properties. Ensure that config phoenix.schema.isNamespaceMappingEnabled is consistent on client and server. (state=43M10,code=726) [root@hadoopmaster conf]#sqlline.py hadoopmaster:2181 Setting property: [incremental, false] Setting property: [isolation, TRANSACTION_READ_COMMITTED] issuing: !connect jdbc:phoenix:hadoopmaster:2181 none none org.apache.phoenix.jdbc.PhoenixDriver Connecting to jdbc:phoenix:hadoopmaster:2181 18/12/18 09:41:04 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable Error: ERROR 726 (43M10): Inconsistent namespace mapping properties. Ensure that config phoenix.schema.isNamespaceMappingEnabled is consistent on client and server. (state=43M10,code=726) java.sql.SQLException: ERROR 726 (43M10): Inconsistent namespace mapping properties. Ensure that config phoenix.schema.isNamespaceMappingEnabled is consistent on client and server. at org.apache.phoenix.exception.SQLExceptionCode$Factory$1.newException(SQLExceptionCode.java:494) at org.apache.phoenix.exception.SQLExceptionInfo.buildException(SQLExceptionInfo.java:150) at org.apache.phoenix.query.ConnectionQueryServicesImpl.checkClientServerCompatibility(ConnectionQueryServicesImpl.java:1310) at org.apache.phoenix.query.ConnectionQueryServicesImpl.ensureTableCreated(ConnectionQueryServicesImpl.java:1154) at org.apache.phoenix.query.ConnectionQueryServicesImpl.createTable(ConnectionQueryServicesImpl.java:1491) at org.apache.phoenix.schema.MetaDataClient.createTableInternal(MetaDataClient.java:2725) at org.apache.phoenix.schema.MetaDataClient.createTable(MetaDataClient.java:1114) at org.apache.phoenix.compile.CreateTableCompiler$1.execute(CreateTableCompiler.java:192) at org.apache.phoenix.jdbc.PhoenixStatement$2.call(PhoenixStatement.java:408) at org.apache.phoenix.jdbc.PhoenixStatement$2.call(PhoenixStatement.java:391) at org.apache.phoenix.call.CallRunner.run(CallRunner.java:53) at org.apache.phoenix.jdbc.PhoenixStatement.executeMutation(PhoenixStatement.java:390) at org.apache.phoenix.jdbc.PhoenixStatement.executeMutation(PhoenixStatement.java:378) at org.apache.phoenix.jdbc.PhoenixStatement.executeUpdate(PhoenixStatement.java:1806) at org.apache.phoenix.query.ConnectionQueryServicesImpl$12.call(ConnectionQueryServicesImpl.java:2536) at org.apache.phoenix.query.ConnectionQueryServicesImpl$12.call(ConnectionQueryServicesImpl.java:2499) at org.apache.phoenix.util.PhoenixContextExecutor.call(PhoenixContextExecutor.java:76) at org.apache.phoenix.query.ConnectionQueryServicesImpl.init(ConnectionQueryServicesImpl.java:2499) at org.apache.phoenix.jdbc.PhoenixDriver.getConnectionQueryServices(PhoenixDriver.java:255) at org.apache.phoenix.jdbc.PhoenixEmbeddedDriver.createConnection(PhoenixEmbeddedDriver.java:150) at org.apache.phoenix.jdbc.PhoenixDriver.connect(PhoenixDriver.java:221) at sqlline.DatabaseConnection.connect(DatabaseConnection.java:157) at sqlline.DatabaseConnection.getConnection(DatabaseConnection.java:203) at sqlline.Commands.connect(Commands.java:1064) at sqlline.Commands.connect(Commands.java:996) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at sqlline.ReflectiveCommandHandler.execute(ReflectiveCommandHandler.java:38) at sqlline.SqlLine.dispatch(SqlLine.java:809) at sqlline.SqlLine.initArgs(SqlLine.java:588) at sqlline.SqlLine.begin(SqlLine.java:661) at sqlline.SqlLine.start(SqlLine.java:398) at sqlline.SqlLine.main(SqlLine.java:291) sqlline version 1.2.0 原因：hbase和Phoenix配置不一致导致，需要将上述两个地方的文件都作修改。 基本操作（常用命令）注意：HBase是大小写敏感，Phoenix操作时需要添加双引号，如果不添加双引号的话会统一转换成大写 //查看帮助 $sqlline> !help //列出连接 $sqlline> !list //显式表 $sqlilne> !tables //列出所有列 $sqlline> !columns myns.test //创建schema（相当于数据库） $sqlline> create schema wndb; //删除表结构 $sqlline> drop table \"test\"; //创建表 $sqlline> create table \"ns1\".\"test\"(id integer primary key ,name varchar,age integer) ; //创建表并指定列族 $sqlline> create table \"ns1\".\"test\"(id integer primary key ,\"cf1\".name varchar,\"cf2\".age integer) ; //插入数据和更新数据 $sqlline> upsert into \"myns\".\"test\"(id,name,age) values(1,'tom',12) //删除 $sqlline> delete from \"myns\".\"test\" where id = 1 ; //条件查询 $sqlline> select * from \"myns\".\"test\" where name like 't%' ; 创建ID自增的表Phoenix中创建表时，必须制定主键。在关系型数据库中（如：mysql）设置主键自增非常容易，但是Phoenix中不能直接设置主键自增，需要额外新建一个自增序列sequence，当插入表数据时，根据sequence的值，来进行自增id的插入。 语法 CREATE SEQUENCE [IF NOT EXISTS] SCHEMA.SEQUENCE_NAME [START WITH number] [INCREMENT BY number] [MINVALUE number] [MAXVALUE number] [CYCLE] [CACHE number] 参数说明 start用于指定第一个值。如果不指定默认为1。 increment指定每次调用next value for后自增大小。 如果不指定默认为1。 minvalue和maxvalue一般与cycle连用, 让自增数据形成一个环，从最小值到最大值，再从最大值到最小值。 cache默认为100, 表示server端生成100个自增序列缓存在客户端，可以减少rpc次数。此值也可以通过phoenix.sequence.cacheSize来配置。 案例与注意事项 注意cache值：如果一次插入个数小于该数n，则断开连接后，由于缓存在客户端，下次重新连接后插入会接着生成n个缓存数来使用，导致自增序列不连续 案例如下： # 演示表a中无数据 $sqlline> select * from a; +-----+------+-------+ | ID | AGE | NAME | +-----+------+-------+ +-----+------+-------+ # 1、创建一个自增序列test，缓存大小设置为50 $sqlline> create sequence test cache 50; No rows affected (0.016 seconds) # 查看序列详情 $sqlline> select * from system.\"SEQUENCE\"; +---------+---------------+-------------+----------+-------------+------------+----------+--------------------+-----------------+ |TENANT_ID|SEQUENCE_SCHEMA|SEQUENCE_NAME|START_WITH|CURRENT_VALUE|INCREMENT_BY|CACHE_SIZE| MIN_VALUE | MAX_VALUE | +---------+---------------+-------------+----------+-------------+------------+----------+--------------------+-----------------+ | | |TEST |1 |1 |1 |50 |-9223372036854775808|92233720368547758| +---------+---------------+-------------+----------+-------------+------------+----------+--------------------+-----------------+ # 2、向演示表a中插入数据，id使用test序列中的值 $sqlline> upsert into a values(next value for test, 20, 'zhangsan'); 1 row affected (0.019 seconds) $sqlline> upsert into a values(next value for test, 30, 'zhangsan1'); 1 row affected (0.019 seconds) $sqlline> upsert into a values(next value for test, 40, 'zhangsan2'); 1 row affected (0.019 seconds) # 成功插入多条数据，id自增 $sqlline> select * from a; +-----+-------+-----------+ | ID | AGE | NAME | +-----+-------+-----------+ | 1 | 20.0 | zhangsan | | 2 | 30.0 | zhangsan1 | | 3 | 40.0 | zhangsan2 | +-----+-------+-----------+ # 3、退出当前连接 $sqlline> !quit Closing: org.apache.phoenix.jdbc.PhoenixConnection # 4、重新连接 [root@hadoopmaster shell]# sqlline.py hadoopmaster,hadoop001,hadoop002:2181 ... 155/155 (100%) Done Done sqlline version 1.2.0 # 查看当前自增序列状态，发现当前值CURRENT_VALUE已经变为51 $sqlline> select * from system.\"SEQUENCE\"; +---------+---------------+-------------+----------+-------------+------------+----------+--------------------+-----------------+ |TENANT_ID|SEQUENCE_SCHEMA|SEQUENCE_NAME|START_WITH|CURRENT_VALUE|INCREMENT_BY|CACHE_SIZE| MIN_VALUE | MAX_VALUE | +---------+---------------+-------------+----------+-------------+------------+----------+--------------------+-----------------+ | | |TEST |1 |51 |1 |50 |-9223372036854775808|92233720368547758| +---------+---------------+-------------+----------+-------------+------------+----------+--------------------+-----------------+ # 5、继续使用test序列值插入演示表a $sqlline> upsert into a values(next value for test, 21, 'lisi'); 1 row affected (0.067 seconds) # 6、发现id已经变为51，导致id不连续的问题 $sqlline> select * from a; +-----+-------+-----------+ | ID | AGE | NAME | +-----+-------+-----------+ | 1 | 20.0 | zhangsan | | 2 | 30.0 | zhangsan1 | | 3 | 40.0 | zhangsan2 | | 51 | 21.0 | lisi | +-----+-------+-----------+ 分页查询 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"HBase","slug":"HBase","permalink":"http://blog.hming.org/tags/HBase/"},{"name":"Phoenix","slug":"Phoenix","permalink":"http://blog.hming.org/tags/Phoenix/"}]},{"title":"Docker容器固定IP","slug":"Docker容器固定IP","date":"2018-10-20T07:13:14.000Z","updated":"2018-10-28T07:13:14.000Z","comments":true,"path":"2018/10/20/docker-rong-qi-gu-ding-ip/","link":"","permalink":"http://blog.hming.org/2018/10/20/docker-rong-qi-gu-ding-ip/","excerpt":"","text":"创建自定义网络[root@hadoopmaster bin]# docker network create --subnet=172.18.0.0/16 my_network 037291f820f9104928d786bc83d123cc2a3dbf459816d4c3145e98faf97a348a [root@hadoopmaster bin]# docker network ls NETWORK ID NAME DRIVER SCOPE 0c3c0925f725 bridge bridge local bb4ac16f1205 host host local 037291f820f9 my_network bridge local 077d509d5c30 none null local 创建容器时指定ipdocker run -itd --net my_network --ip 172.18.0.100 --add-host hdp001:172.18.0.101 --add-host hdp002:172.18.0.102 -h hdpmaster --name hdpmaster -p 8088:8088 -p 50070:50070 cyanidehm/hadoop:0.3 /bin/bash docker run -itd --net my_network --ip 172.18.0.101 --add-host hdpmaster:172.18.0.100 --add-host hdp002:172.18.0.102 -h hdp001 --name hdp001 cyanidehm/hadoop:0.3 /bin/bash docker run -itd --net my_network --ip 172.18.0.102 --add-host hdp001:172.18.0.101 --add-host hdpmaster:172.18.0.100 -h hdp002 --name hdp002 cyanidehm/hadoop:0.3 /bin/bash &gt; --net 指定网络类型。 &gt; --ip 指定ip地址。 &gt; --add-host 添加主机到hosts文件。 &gt; -h 指定hostname主机名。 &gt; --name 指定容器名称 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"容器","slug":"容器","permalink":"http://blog.hming.org/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"容器","slug":"容器","permalink":"http://blog.hming.org/tags/%E5%AE%B9%E5%99%A8/"},{"name":"Docker","slug":"Docker","permalink":"http://blog.hming.org/tags/Docker/"},{"name":"IP","slug":"IP","permalink":"http://blog.hming.org/tags/IP/"}]},{"title":"Keep-Class课程《跑步减脂不累腿的秘诀》笔记","slug":"Keep-Class课程《跑步减脂不累腿的秘诀》笔记","date":"2018-09-25T12:15:24.000Z","updated":"2018-11-06T06:14:02.000Z","comments":true,"path":"2018/09/25/keep-class-ke-cheng-pao-bu-jian-zhi-bu-lei-tui-de-mi-jue-bi-ji/","link":"","permalink":"http://blog.hming.org/2018/09/25/keep-class-ke-cheng-pao-bu-jian-zhi-bu-lei-tui-de-mi-jue-bi-ji/","excerpt":"","text":"原文作者：Amazing_H链接：https://www.jianshu.com/p/894f942005c9转载來源：简书 怎么跑才能不粗腿腿部的肌肉和脂肪任何一样占比过大都会让腿在视觉上看起来粗壮。 但是，跑步作为一种高能量的有氧运动，是不会让腿长出脂肪的。 跑步作为一种耐力运动，从运动生理学的角度，也不会让肌肉有明显的增长。 为什么有很多人会认为跑步会让腿变粗呢？有两种原因： 客观上：不正确的跑步姿势，过多动员了大腿的肌肉，而不是臀部的肌肉。 主观上：跑步之后，腿部的疲劳感，会让你觉得跑步练到了腿，会把腿练粗，并且错误的姿势还会加深腿部的疲劳感，让你更怀疑腿变粗了。 想通过跑步减脂而又不累腿，解决的方法就是： 学习正确的跑步姿势，减少腿部的发力，增加臀部的发力。 臀部是下肢最发达的部位，是奔跑的发动力，学会动员臀部的发力，可以减少大腿发力的代偿。你的腿不容易累，就不会怀疑腿会变粗了。 但，新手的普遍状况是没有掌握正确的跑步姿势，臀部发力不足，导致腿部发力过多。比如：跑步时是向上跳着跑，导致了做功主要是克服重力，浪费了很多能量，腿会感觉非常累。 跑步时腿部并不是主要向前迈步或者向下踏步，我们应该向后摆腿部，这样能让力高效地推动身体向前进。 向后摆腿发力可以： 动员到臀部的力量，减少腿部发力 可以利用到鞭打效应，增加跑步时力学传递的效率 理想的跑步姿势，是向后摆腿跑，充分调动臀部发力，将力量传递到足部，推动身体向前，而且可以借助鞭打效应，向前的做功也会提升，让跑步更省力。 跑前热身 很多人虽然可以模仿向后甩腿的动作，但还是并不容易掌握臀部发力的感觉。 每次跑步前，通过以下两个动作，可以激活臀大肌，放松髂腰肌，感受到臀部的用力。再结合keep的《跑前热身课程》，可以有效预防损伤，让跑步过程更易达到最佳状态。 注： 臀大肌，在屁股两侧，主要负责发力，负责向后最初始的动力 髂腰肌，在大腿根部，足够放松，才能不阻碍腿向后摆 动作1--箭步蹲--这是激活臀大肌常用的动作--每侧15-30次，每次2-3组腰部挺直，两手叉腰，向前迈出一步，和自己腿长差不多相等的距离，下蹲成弓步，注意膝关节和髋关节呈90度。然后，想象自己后面的脚踩在冰面上，稍微一用力就会踩碎，靠前面的腿、臀部的力量推动自己身体站起来。这样可以帮你找到臀部发力的感觉，避免过多使用腿部的力量。 注意：做这个动作的时候，不要向前移动中心，或者前倾身体。或者后面的腿发力过多，这样都不利于找到臀部发力的感觉。 动作2--弓箭步拉伸--可以放松髂腰肌--每侧拉伸2次，每次60秒。 首先做一个弓箭步，让后面的腿放在地上，身体挺直，重心向前下方移动。然后用力挺胯，让大腿的根部得到拉伸。还可以让身体转向被拉伸的另外一侧，可以体会到更明显的拉伸感。 跑后放松 跑后是肌肉最需要冷身和放松的时候，跑后腿部肌肉拉伸或者按摩，可以避免疲劳累积到第二天，也可以有效缓解第二天的酸痛、不适等症状的出现。 以下两个跑后拉伸动作，结合keep的《跑后拉伸课程》和《小腿按摩课程》可以有效实现。) 另外的两个动作： 动作1--髂胫束拉伸--可以缓解髂胫束的紧张造成的膝外侧疼痛--每侧30-60秒，每次1-2组 左脚向右脚前方交叉，身体倒向前偏左侧的方向，手摸到地面或者脚踝，膝盖保持平衡。体会拉伸大腿右外侧的部位。另外一侧的拉伸同理。 动作2--小腿拉伸--让小腿深层的肌肉得到充分地放松--每侧30-60秒，每次1-2组 伸直腿后，将被拉伸的腿向前移动40cm左右的距离，继续弯曲膝盖，中心下降拉伸小腿。体会靠近跟腱部位，及小腿深层的肌肉被拉伸。每一侧做30到60秒，重复1到2组。 注意：拉伸的过程中保持均匀呼吸，不用过分用力，体会肌肉被拉长的感觉即可。 怎么跑步不容易受伤在跑步姿势对的前提下，跑步时最简单有效的减脂运动方式之一。有效地慢跑每个小时可以消耗600-900大卡的热量，是单位时间里卡路里消耗最高的持续运动方式。但是，如果不注意跑步姿势和技巧，对身体的损伤则不堪设想。 正确的跑步姿势 一个远离受伤的跑步姿势，需要满足两个条件： 减小跑步时地面对双脚的冲击力 提高跑步时身体整体的稳定性 跑步有两种力量可能引起损伤： 是水平方向的扭转力，产生的研磨效应 是垂直方向的冲击力，产生的撞击效应 扭转力–提高身体的稳定性，可以有效减小扭转力 如果无法保证身体的稳定，会让我们的身体扭起来，会产生很多不必要的扭转力。扭转力比冲击力给关节的损伤更大，因为扭转力会对关节、韧带产生研磨效应，这种研磨效应发生在膝盖的髌骨就叫做髌骨软化，跑起来膝盖正前方就疼。研磨效应产生在髂胫束的末端，就叫髂胫束综合征，跑起来膝盖外侧就疼痛难忍。研磨效应还可能让半月板受损。 保持身体稳定 首先，保证躯干处于中立位置，调整头部，保持眼睛向水平方向看。想象自己想要量身高，尽可能向上伸展身体的感觉。还有感觉自己头顶有个苹果，不要让他掉下来。 其次，肩膀要放松，要让自己的肩膀有微微向后打开的感觉，并且保持整个躯干的竖立状态。 第三，收紧自己的腰腹，找到一种咳嗽，或者有人要打你腹部的感觉。 第四，保持自己的骨盆在中立位置上，不要前倾也不要后倾。 摆臂 摆臂是为了稳定身体。跑步的时候，腿部前后摆动会产生扭转的力矩，这个力矩会传递到上肢，刚好可以被手臂的摆动抵消掉，从而提高身体的稳定性。摆臂的时候，肘关节呈90度，肩膀放松，摆动自然。 通过保持躯干的中立位，以及自然的摆臂，就可以让身体从上到下保持稳定，避免产生多余的扭转力。 冲击力–减少冲击力的下半身模式 跑步每公里会产生几百上千次冲击，如果每次冲击力过大，可能会产生：胫骨前肌疼痛、足底筋膜炎、甚至是对关节造成伤害。 减少冲击力，需要一个良好的落地技巧 让落地点尽可能靠近身体的重心。经常有人跑步迈很大的步子，这样会让落地点超出身体很远，会产生一种刹车效应，每一步都会产生阻力，并增加落地时的冲击力。正确的落地方法，是让触地点，尽可能靠近身体重心的投影，有一种踩在重心上的感觉。 提高步频。提高步频可以减少身体腾空的时间，腾空的时间决定了腾空的高度，直接决定落地冲击力的大小 前脚掌落地和后脚跟落地的技巧。 落地最重要的是触地点落在身体的重心， 当速度低于12公里每小时，适合用脚跟先接触地面，这时如果用前脚掌接触地面，容易给小腿造成过多的压力。 当速度高于12公里每小时，适合用前脚掌先接触地面。 根据跑步的路况减少冲击力 塑胶跑道是最容易找到的适合跑步的路面，它有很好的缓冲减震效果，相当于一双高级跑鞋的效果。 公路硬度比较高，缓冲性能较强的跑鞋是必备的，另外，脚可以用一种滚动的感觉去落地，主动缓冲地面的冲击力，并且控制自己的脚步声尽可能的小。落地轻盈、声音小，就说明缓冲技巧控制的比较好。 跑步机和户外跑步的区别很大，户外跑是地面静止，腿推动身体向前移动。跑步机是履带向后，有一种带着人跑的感觉。使用跑步机跑步，需要有意的增加自己腿向后摆的幅度，尽可能与户外跑步保持一致。 远离损伤的跑步姿势和技巧： 稳定上身、自然摆臂、落地点靠近重心、用滚动的方式落地、保持一个高步频。 提升跑步速度与距离两大要领提升跑步速度 怎样跑步最省力 跑步不只是姿势那么简单，因为跑步不是静止的姿势，而是连贯的动作。前面两节通过静止的姿势讲解了正确的跑步姿势，静止的姿势是很容易模仿、实践的。但是如果想要跑更长时间，比如10公里，甚至是马拉松，就需要更高效的动作模式。 越跑越快、越跑越稳的动作模式应该是： 提高步频–推荐使用180每分钟的步频 步频就是每分钟的步数，高步频可以跑的更快，还可以提高稳定性，让腾空的时间更短，减少垂直方向重心的起伏。跑起来不仅可以更快，还能更省力。 提高步幅 步幅就是每一步的长度。提高步幅，并不是说步子迈的越大越好，有很多人想跑更快，就向前迈特别大的步子，这样子很容易让脚的落地点超越重心太远，产生刹车效应。 正确的提高步幅的方式是通过充分的蹬伸，提高每一步的步幅。 提高步幅的正确方式是，通过充分的蹬伸，提高每一步的步幅。这个过程可以拆分为四个阶段：落地、支撑、蹬伸、腾空。 落地：要想提高速度，落地要尽可能靠近重心的投影，落地的时候要注意膝盖自然弯曲，用肌肉的弹性做缓冲，把自己的双腿想象成弹簧，借助弹性，而不只是靠主动的发力去落地。 支撑：速度快的同时，支撑阶段也要尽可能地快。从双脚落地开始，迅速滚动到脚的中部做支撑。这个过程身体要保持稳定，保持手臂和腿的运动轨迹尽可能平行，不要出现交叉。 蹬伸：要想速度快，每一步需要有足够的力推动身体向前。有两个要点，一是以臀部为轴（臀部为轴，是指臀部向后发力要充分），用鞭打的方式传递力量。第二是提拉后摆，想要把后蹬的力量转化为向前的力量，就需要我们在蹬伸的过程中，收缩腘绳肌，改变力的方向，尽可能的向后发力，避免力量转化为向上的力量浪费掉。 /loading.gif\" data-original=\" 前摆：后摆最重要的是发力，前摆最重要的是省力。转动惯量和力矩成正比，滑冰运动员展开身体的时候速度会变慢，收紧身体的时候转动速度会变快。同样的道理，下肢折叠的越充分，向前摆动的时候就越省力。 跑步常见的困扰与危险信号跑步中经常会有以下感觉： 第一种感觉叫极点，一般出现在跑步的10-15分钟左右，或者跑到第2-3公里的时候。这时候会感觉非常累、非常煎熬，冥冥之中有一种力量阻碍你迈不开腿、踹不上气，让你想要放弃。 冥冥之中的这个力量是内脏系统的阻力。在安静状态下，身体的血液是集中在躯干的内脏中。而在运动状态，身体的血液集中在四肢的肌肉当中。刚刚开始运动的时候，血液还没来得及从内脏到达肌肉，就会产生一种生理惰性，阻碍跑步，这就是极点现象，又叫惰性极点。当你继续运动一段时间，等待血液逐渐到达肌肉，就会跨过第一极点。 第二种感觉就是跑步完以后感觉腿疼。疼痛是身体给我们发出的信号，最常见的是延迟性肌肉酸痛。有这样一种疼法，刚跑完的时候，你并没有什么感觉，而是运动后一天活第二天开始感觉疼痛，疼的时候可能会感觉上楼都困难。这种疼痛的特点是两条腿都疼，是对称的，痛点主要在肌肉上面。延期性肌肉酸痛是肌肉进行大量运动刺激后，进行自我更新的结果，肌纤维正在重建。这种疼痛一般会在一周之后消退。如果进行低强度的运动，比如走路、慢跑、拉伸之后，都可以促进疼痛更快恢复。 第三种是跑完后感觉腿粗了一圈。这种感觉不用担心，是会自行恢复的。人体的80%是水，我们的身体，特别是肌肉，受到体液分布的影响很大。安静的时候血液会在内脏、大脑当中。跑步中和跑步后，血液会集中在下肢，导致暂时的体液分布型水肿，可能会持续1-3天。在跑步后，平躺并通过手臂的辅助做一些腿部后侧的拉伸，每侧3分钟左右，可以让这种暂时的水肿很快恢复。或者通过泡沫轴滚压、按摩的方式也可以减轻水肿的现象 还有可能出现这种危险信号：运动中单腿越跑越疼。 随着运动的持续，一条腿越来越疼，并且疼痛出现在关节，这时候要立刻停止运动，如果停止运动后，症状继续加重，就需要寻求医生的治疗了。 危险信号的出现，往往是因为姿势的不正确，比如： 步子迈太大，每迈一步，就是一次刹车效应，损耗能量不说，还有可能将肌肉拉扯疼痛。 身体前倾，这样会给后背，尤其是腰部造成过重的负担，容易产生腰痛。跑步的时候让整个身体保持重心向前，微微前倾5度左右就可以了。 用脚尖着地，课程中所说的前脚掌不是脚尖，而是整个脚掌前二分之一的部位。如果用脚尖 跑步，会让脚趾关节受到很大的冲击力造成损伤。 横向摆臂，这样不仅不会稳定身体，反而可能产生更多的扭转力，身体的不稳定更容易引起岔气状况的出现。 膝盖内扣，女生常出现这种问题，这样可能导致膝关节的损伤。 几乎所有人都会觉得跑步挺简单的，但是跑步是一项周期性的运动。相同的一个动作，需要重复重复再重复，动作中小的错误，也可能积累起来给你造成困扰，跑步姿势有很多可以优化和改进的地方。如果想避免危险的疼痛，除了保证跑步的姿势正确，还需要注意训练总量的控制。每周的跑步总量不要超过上一周的10%，比如第一周10公里，第二周尽量不要超过11公里。跑步是一个循序渐进的过程，需要不断地练习才能越跑越瘦、越跑越远。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"运动","slug":"运动","permalink":"http://blog.hming.org/categories/%E8%BF%90%E5%8A%A8/"}],"tags":[{"name":"跑步","slug":"跑步","permalink":"http://blog.hming.org/tags/%E8%B7%91%E6%AD%A5/"},{"name":"Keep","slug":"Keep","permalink":"http://blog.hming.org/tags/Keep/"},{"name":"运动","slug":"运动","permalink":"http://blog.hming.org/tags/%E8%BF%90%E5%8A%A8/"}]},{"title":"Docker替换镜像源与常用命令","slug":"Docker替换镜像源与常用命令","date":"2018-09-18T09:25:53.000Z","updated":"2018-12-20T11:10:48.000Z","comments":true,"path":"2018/09/18/docker-ti-huan-jing-xiang-yuan-yu-chang-yong-ming-ling/","link":"","permalink":"http://blog.hming.org/2018/09/18/docker-ti-huan-jing-xiang-yuan-yu-chang-yong-ming-ling/","excerpt":"","text":"安装CentOS7下直接运行yum -y install docker 查看是否安装成功docker version或者docker info docker info显示内容需要启动docker服务才能看见 启动docker服务service docker start或者systemctl start docker 设置开机自启动systemctl enable docker 替换为国内镜像源修改或新增/etc/docker/daemon.json文件{ \"registry-mirrors\": [\"http://hub-mirror.c.163.com\"] } 修改之后重启一下docker服务 systemctl restart docker.service 或者 service docker restart Docker国内源Docker 官方中国区https://registry.docker-cn.com 网易http://hub-mirror.c.163.com 中国科技大学https://docker.mirrors.ustc.edu.cn 阿里云https://pee6w651.mirror.aliyuncs.com 基本命令列出本地所有image文件docker images 或者docker image ls 删除本地镜像docker image rm [镜像名] 拉取镜像docker image pull [镜像组/镜像名] 运行镜像生成容器docker container run [镜像名]或者docker run [镜像名] 如果本地没有该镜像，会自动去仓库pull 终止容器docker container kill [容器id]或者docker kill [容器id]或者docker stop [容器id] 制作docker容器步骤 编写Dockerfile文件 # 该 image 文件继承官方的 node image，冒号表示标签，这里标签是8.4，即8.4版本的 node。 FROM node:8.4 # 创建者信息 MAINTAINER cyanidehm # 将当前目录下的所有文件（除了.dockerignore排除的路径），都拷贝进入 image 文件的/app目录。 COPY . /app # 指定接下来的工作路径为/app。 WORKDIR /app # 在/app目录下，运行npm install命令安装依赖。注意，安装后所有的依赖，都将打包进入 image 文件。 RUN npm install --registry=https://registry.npm.taobao.org # 将容器 3000 端口暴露出来， 允许外部连接这个端口。 EXPOSE 3000 编写.dockerignore文件 .git node_modules npm-debug.log # 表示上面三个路径会排除，不打进image文件 创建image文件 有了 Dockerfile 文件以后，就可以使用docker image build命令创建 image 文件了。 $ docker image build -t demo . # 或者 $ docker image build -t demo:0.0.1 . # -t参数用来指定 image 文件的名字（该例中demo为image名），后面还可以用冒号指定标签。如果不指定，默认的标签就是latest。最后的那个点表示 Dockerfile 文件所在的路径，上例是当前路径，所以是一个点。 生成image之后就可以使用docker images查看到了 生成容器 $ docker container run -p 8000:3000 -itd --name my_demo -h master -v /opt/java:/home/java --privileged=true demo:0.0.1 /bin/bash -p参数：容器的 3000 端口映射到本机的 8000 端口。-it参数：容器的 Shell 映射到当前的 Shell，然后你在本机窗口输入的命令，就会传入容器。-d参数：容器后台运行。–name参数：表示生成的容器名称，这里为my_demo。-h参数：表示生成的容器主机名，这里为master。-v参数：表示主机地址/opt/java和容器中地址/home/java映射，上传到/opt/java目录就能同步上传到容器内。demo:0.0.1：镜像文件的名字（如果有标签，还需要提供标签，这里标签为0.0.1，如果不提供，默认是 latest 标签）。/bin/bash：容器启动以后，内部第一个执行的命令。这里是启动 Bash，保证用户可以使用 Shell。--privileged: CentOS7中安全模块selinux会把容器读写权限禁掉，添加该参数赋予容器权限，也可以禁用CentOS7的selinux模块。 将运行的容器打包成镜像 登录docker hub网站注册账号。 https://hub.docker.com/ docker login命令登录，输入相应用户名和密码 Username: cyanidehm Password: Login Succeeded # 表示登录成功 使用docker ps查看当前运行的容器 [root@hadoopCDH opt]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 9bffe3a2142e centos \"/bin/bash\" About an hour ago Up About an hour vigilant_dijkstra 得到容器id：9bffe3a2142e 使用docker commit 9bffe3a2142e my_centos命令提交到本地镜像，my_centos为镜像名（自己取名） docker commit [OPTIONS] [容器id或名称] [镜像名称：版本]，OPTIONS选项包括：-a，–author=””作者信息。-m，–message=””提交信息。-p，–pause=true提交时暂停容器运行。 查看本地镜像 [root@hadoopCDH opt]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE my_centos latest bcc2cf471c38 11 seconds ago 400 MB 将镜像改到自己账户名下，推送到docker hub [root@hadoopCDH opt]# docker tag my_centos cyanidehm/my_centos [root@hadoopCDH opt]# docker push cyanidehm/my_centos:latest 其他命令查看容器 docker ps查看正在运行的容器。 docker ps -a或docker container ls --all查看所有存在的容器。 退出容器bash 在容器的命令行，按下 Ctrl + c 停止 Node 进程，然后按下 Ctrl + d （或者输入 exit）退出容器。此外，也可以用docker container kill终止容器运行。 删除容器文件 容器停止运行后，不会消失，使用docker container ls --all查看所有存在的容器（id等信息）。 使用docker container rm [容器id]或者docker rm [容器id]删除容器。 清除所有容器 停止所有容器docker stop $(docker ps -aq) 删除所有容器docker rm $(docker ps -aq) 运行已存在的容器 docker container start [容器id]或者docker start [容器id] 进入已经运行的容器 docker container exec -it [容器id] [/bin/bash] 将容器里的文件拷贝到本机 docker container cp [容器id]:[/path/to/file] . 将镜像保存为tar文件、将tar文件加载到docker镜像 保存镜像docker save -o [路径/文件名] [镜像名]或者docker save [镜像名] &gt; [路径/文件名] [root@hadoopCDH opt]# docker save -o my_centos.tar cyanidehm/my_centos:latest [root@hadoopCDH opt]# ll my_centos.tar -rw-------. 1 root root 779944960 10月 17 03:40 my_centos.tar 可以通过指定打包格式来打包成压缩文件：docker save [镜像名] | gzip &gt; [路径/文件名.tar.gz] 加载镜像docker load --input [路径/文件名]或者docker load &lt; [路径/文件名] [root@hadoopmaster opt]# docker load &lt; my_centos.tar 1d31b5806ba4: Loading layer [==================================================>] 208.3 MB/208.3 MB a5789abfb72a: Loading layer [==================================================>] 571.6 MB/571.6 MB Loaded image: cyanidehm/my_centos:latest [root@hadoopmaster opt]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE cyanidehm/my_centos latest 3ced2987d19a Less than a second ago 765 MB 批量save/load镜像脚本地址hydra1983/docker_images.sh批量保存./docker_images.sh save-images批量加载./docker_images.sh load-images 脚本将镜像文件保存到./images目录下，另外一个images.db文件与之对应将这两个东西拷贝到其他主机，执行批量加载命令就行实现批量转移镜像 [root@localhost save]# ./docker_images.sh save-images Create /opt/save/images.db Read /opt/save/images.db Create /opt/save/images [DEBUG] save 00ead811e8ae docker.io/portainer/portainer:latest to /opt/save/images/00ead811e8ae.dim real 0m27.343s [DEBUG] save d63b9b4bd205 rancher/server:v1.6.14 to /opt/save/images/d63b9b4bd205.dim real 4m46.480s [DEBUG] save 34a453d374b9 docker.io/rancher/agent:v1.2.9 to /opt/save/images/34a453d374b9.dim real 0m28.037s [root@localhost save]# ./docker_images.sh load-images ... 容器启动后自动运行脚本情景：1、镜像已经存在。2、镜像内包含脚本/home/ssh.sh需要在容器启动后运行 docker run -itd cyanidehm/base_ssh /bin/bash -c \"sh /home/ssh.sh;/bin/bash\" 说明：/bin/bash -c \"\"表示容器运行后使用bash执行引号内语句。引号内的 ; 表示命令分割，执行多条命令时用;进行分割引号内最后的/bin/bash表示容器启动以bash方式运行（如果容器启动后没有线程在运行，容器会停止退出） 查看容器相关信息在容器外面不进入容器查看容器信息docker inspect [容器名/id]：查看到容器的相关信息 # 查看容器的具体IP地址，如果输出是空的说明没有配置IP地址 docker inspect --format '{{ .NetworkSettings.IPAddress }}' [容器名/id] document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"容器","slug":"容器","permalink":"http://blog.hming.org/categories/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"容器","slug":"容器","permalink":"http://blog.hming.org/tags/%E5%AE%B9%E5%99%A8/"},{"name":"Docker","slug":"Docker","permalink":"http://blog.hming.org/tags/Docker/"},{"name":"命令","slug":"命令","permalink":"http://blog.hming.org/tags/%E5%91%BD%E4%BB%A4/"},{"name":"镜像源","slug":"镜像源","permalink":"http://blog.hming.org/tags/%E9%95%9C%E5%83%8F%E6%BA%90/"}]},{"title":"CentOS7下搭建Hadoop集群","slug":"CentOS7下搭建Hadoop集群","date":"2018-09-16T15:40:16.000Z","updated":"2019-02-18T07:05:06.000Z","comments":true,"path":"2018/09/16/centos7-xia-da-jian-hadoop-ji-qun/","link":"","permalink":"http://blog.hming.org/2018/09/16/centos7-xia-da-jian-hadoop-ji-qun/","excerpt":"","text":"本文环境 节点 IP地址 hadoopmaster 192.168.171.10 hadoop001 192.168.171.11 hadoop002 192.168.171.12 准备环境虚拟机创建多个Linux系统并配置静态IP配置静态IP教程请点击这里 配置DNS（每个节点）进入配置文件，添加主节点和从节点的映射关系vim /etc/hosts，添加如下代码（ip以及主机名以自己配置为准） 192.168.171.10 hadoopmaster 192.168.171.11 hadoop001 192.168.171.12 hadoop002 关闭防火墙（每个节点）关闭服务systemctl stop firewalld关闭开机自启动systemctl disable firewalld 配置免密码登录配置免密码登录教程请点击这里 配置java环境（每个节点）配置java环境教程点击这里 搭建Hadoop完全分布式集群 在各个节点上安装与配置Hadoop的过程都基本相同，因此可以在每个节点上安装好Hadoop后，在主节点master上进行统一配置，然后通过scp 命令将修改的配置文件拷贝到各个从节点上即可。 下载hadoop安装包，解压，配置环境变量点击这里选择适合的版本进行安装包下载找个目录（本文为/opt目录），rz 命令上传到Linux系统 解压tar -zxvf hadoop-*.tar.gz配置环境变量（每个节点）vim /etc/profile添加如下代码 export HADOOP_HOME=/opt/hadoop-2.7.3 # 该目录为解压安装目录 export PATH=$PATH:$HADOOP_HOME/bin export PATH=$PATH:$HADOOP_HOME/sbin export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop 完成后刷新一下，使profile生效 [root@hadoopmaster ~]# source /etc/profile 配置环境脚本文件的JAVA_HOME参数进入hadoop安装目录下的etc/hadoop目录分别在hadoop-env.sh、mapred-env.sh、yarn-env.sh文件中添加或修改参数： export JAVA_HOME=\"/opt/jdk1.8\" # 路径为jdk安装路径修改配置文件 hadoop安装目录下的etc/hadoop目录,一共需要修改core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml、slaves(3.0之后为workers)文件，按实际情况修改配置信息 1.core-site.xml更多参数配置参考：core-default.xml &lt;configuration> &lt;property> &lt;!-- 配置hdfs地址 --> &lt;name>fs.defaultFS&lt;/name> &lt;value>hdfs://hadoopmaster:9000&lt;/value> &lt;/property> &lt;property> &lt;!-- 保存临时文件目录 --> &lt;name>hadoop.tmp.dir&lt;/name> &lt;value>/opt/hadoop/tmp&lt;/value> &lt;/property> &lt;property> &lt;name>hadoop.proxyuser.root.hosts&lt;/name> &lt;value>*&lt;/value> &lt;/property> &lt;property> &lt;name>hadoop.proxyuser.root.groups&lt;/name> &lt;value>*&lt;/value> &lt;/property> &lt;/configuration> 2.hdfs-site.xml更多参数配置参考：hdfs-default.xml &lt;configuration> &lt;property> &lt;!-- 主节点地址 --> &lt;name>dfs.namenode.http-address&lt;/name> &lt;value>hadoopmaster:50070&lt;/value> &lt;/property> &lt;property> &lt;name>dfs.namenode.name.dir&lt;/name> &lt;value>file:/opt/hadoop/dfs/name&lt;/value> &lt;/property> &lt;property> &lt;name>dfs.datanode.data.dir&lt;/name> &lt;value>file:/opt/hadoop/dfs/data&lt;/value> &lt;/property> &lt;property> &lt;!-- 备份份数 --> &lt;name>dfs.replication&lt;/name> &lt;value>2&lt;/value> &lt;/property> &lt;property> &lt;!-- 第二节点地址 --> &lt;name>dfs.namenode.secondary.http-address&lt;/name> &lt;value>hadoop001:9001&lt;/value> &lt;/property> &lt;property> &lt;name>dfs.webhdfs.enabled&lt;/name> &lt;value>true&lt;/value> &lt;/property> &lt;property> &lt;name>dfs.permissions&lt;/name> &lt;value>false&lt;/value> &lt;description>配置为false后，可以允许不要检查权限就生成dfs上的文件，方便倒是方便了，但是你需要防止误删除.&lt;/description> &lt;/property> &lt;/configuration> 3.mapred-site.xml更多参数配置参考：mapred-default.xml &lt;configuration> &lt;property> &lt;name>mapreduce.framework.name&lt;/name> &lt;value>yarn&lt;/value> &lt;/property> &lt;property> &lt;name>mapreduce.jobhistory.address&lt;/name> &lt;value>hadoopmaster:10020&lt;/value> &lt;/property> &lt;property> &lt;name>mapreduce.jobhistory.webapp.address&lt;/name> &lt;value>hadoopmaster:19888&lt;/value> &lt;/property> &lt;/configuration> 4.yarn-site.xml（资源管理器）更多参数配置参考：yarn-default.xml &lt;configuration> &lt;property> &lt;name>yarn.nodemanager.aux-services&lt;/name> &lt;value>mapreduce_shuffle&lt;/value> &lt;/property> &lt;property> &lt;name>yarn.nodemanager.auxservices.mapreduce.shuffle.class&lt;/name> &lt;value>org.apache.hadoop.mapred.ShuffleHandler&lt;/value> &lt;/property> &lt;property> &lt;name>yarn.resourcemanager.address&lt;/name> &lt;value>hadoopmaster:8032&lt;/value> &lt;/property> &lt;property> &lt;name>yarn.resourcemanager.scheduler.address&lt;/name> &lt;value>hadoopmaster:8030&lt;/value> &lt;/property> &lt;property> &lt;name>yarn.resourcemanager.resource-tracker.address&lt;/name> &lt;value>hadoopmaster:8031&lt;/value> &lt;/property> &lt;property> &lt;name>yarn.resourcemanager.admin.address&lt;/name> &lt;value>hadoopmaster:8033&lt;/value> &lt;/property> &lt;property> &lt;name>yarn.resourcemanager.webapp.address&lt;/name> &lt;value>hadoopmaster:8088&lt;/value> &lt;/property> &lt;property> &lt;name>yarn.nodemanager.resource.memory-mb&lt;/name> &lt;!-- NodeManage中的配置，这里配置过小可能导致nodemanager启动不起来 大小应该大于 spark中 executor-memory + driver的内存 --> &lt;value>6144&lt;/value> &lt;/property> &lt;property> &lt;!-- RsourceManager中配置 大小应该大于 spark中 executor-memory + driver的内存 --> &lt;name>yarn.scheduler.maximum-allocation-mb&lt;/name> &lt;value>61440&lt;/value> &lt;/property> &lt;property> &lt;!-- 使用核数 --> &lt;name>yarn.nodemanager.resource.cpu-vcores&lt;/name> &lt;value>2&lt;/value> &lt;/property> &lt;property> &lt;name>yarn.log-aggregation-enable&lt;/name> &lt;value>true&lt;/value> &lt;/property> &lt;property> &lt;name>yarn.log-aggregation.retain-seconds&lt;/name> &lt;value>604800&lt;/value> &lt;/property> &lt;property> &lt;name>yarn.nodemanager.vmem-check-enabled&lt;/name> &lt;value>false&lt;/value> &lt;discription>忽略虚拟内存的检查，如果你是安装在虚拟机上，这个配置很有用，配上去之后后续操作不容易出问题。&lt;/discription> &lt;/property> &lt;property> &lt;!-- 调度策略，设置为公平调度器 --> &lt;name>yarn.resourcemanager.scheduler.class&lt;/name> &lt;value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler&lt;/value> &lt;/property> &lt;/configuration> 5.slaves文件（3.0之后为workers文件）# 增加从节点地址（这里由于配置了hosts，直接使用主机名，也可以配ip地址） hadoop001 hadoop002将文件夹copy到其他子节点通过scp 命令将修改好的文件夹拷贝到各个从节点上 [root@hadoopmaster ~]# scp -r /opt/hadoop/ root@hadoop001:/opt ... [root@hadoopmaster ~]# scp -r /opt/hadoop/ root@hadoop002:/opt 初始化、启动[root@hadoopmaster hadoop]# bin/hdfs namenode -format 全部启动sbin/start-all.sh，也可以分开sbin/start-dfs.sh、sbin/start-yarn.sh启动 报错：Starting namenodes on [hadoopmaster]ERROR: Attempting to operate on hdfs namenode as rootERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.Starting datanodesERROR: Attempting to operate on hdfs datanode as rootERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.Starting secondary namenodes [hadoop001]ERROR: Attempting to operate on hdfs secondarynamenode as rootERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation.Starting resourcemanagerERROR: Attempting to operate on yarn resourcemanager as rootERROR: but there is no YARN_RESOURCEMANAGER_USER defined. Aborting operation.Starting nodemanagersERROR: Attempting to operate on yarn nodemanager as rootERROR: but there is no YARN_NODEMANAGER_USER defined. Aborting operation. 原因：是因为缺少用户定义造成的，所以分别编辑开始和关闭脚本$ vim sbin/start-dfs.sh$ vim sbin/stop-dfs.sh在顶部空白处添加内容：HDFS_DATANODE_USER=rootHADOOP_SECURE_DN_USER=hdfsHDFS_NAMENODE_USER=rootHDFS_SECONDARYNAMENODE_USER=root start-yarn.sh，stop-yarn.sh顶部也需添加以下：YARN_RESOURCEMANAGER_USER=rootHADOOP_SECURE_DN_USER=yarnYARN_NODEMANAGER_USER=root Web访问，要先开放端口或者直接关闭防火墙 关闭防火墙 # 查看防火墙状态 firewall-cmd --state # 临时关闭 systemctl stop firewalld # 禁止开机启动 systemctl disable firewalld 浏览器打开http://hadoopmaster:8088/ 浏览器打开http://hadoopmaster:50070/ 单例管理每个节点$> sbin/hadoop-daemon.sh start datanode # 启动数据节点 $> sbin/yarn-daemon.sh start nodemanager # 启动数据管理节点 $> bin/hadoop-daemon.sh start tasktracker # 启动任务管理器 yarn application命令介绍yarn application后接参数： -list 列出所有application信息 [root@master ~]# yarn application -list -appStates &lt;States&gt; 跟 -list 一起使用，用来筛选不同状态的 application，多个用”,”分隔； 所有状态：ALL, NEW, NEW_SAVING, SUBMITTED, ACCEPTED, RUNNING, FINISHED, FAILED, KILLED [root@master ~]# yarn application -list -appStates RUNNING -appTypes &lt;Types&gt; 跟 -list 一起使用，用来筛选不同类型的 application，多个用”,”分隔； 如 MAPREDUCE,TEZ [root@master ~]# yarn application -list -appTypes MAPREDUCE -kill &lt;Application ID&gt; 杀死一个 application，需要指定一个 Application ID [root@master ~]# yarn application -kill application_1526100291229_206393 -status &lt;Application ID&gt; 列出 某个application 的状态 [root@master ~]# yarn application -status application_1526100291229_206393 -movetoqueue &lt;Application ID&gt; 移动 application 到其他的 queue，不能单独使用 -queue &lt;Queue Name&gt; 与 movetoqueue 命令一起使用，指定移动到哪个 queue [root@master ~]# yarn application -movetoqueue application_1526100291229_206393 -queue other document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"集群","slug":"集群","permalink":"http://blog.hming.org/tags/%E9%9B%86%E7%BE%A4/"},{"name":"Linux","slug":"Linux","permalink":"http://blog.hming.org/tags/Linux/"},{"name":"Hadoop","slug":"Hadoop","permalink":"http://blog.hming.org/tags/Hadoop/"}]},{"title":"Linux集群配置免密码登录","slug":"Linux集群配置免密码登录","date":"2018-09-16T10:12:14.000Z","updated":"2019-05-20T08:45:43.000Z","comments":true,"path":"2018/09/16/linux-ji-qun-pei-zhi-mian-mi-ma-deng-lu/","link":"","permalink":"http://blog.hming.org/2018/09/16/linux-ji-qun-pei-zhi-mian-mi-ma-deng-lu/","excerpt":"","text":"本文环境 节点 IP地址 hadoopmaster 192.168.171.10 hadoop001 192.168.171.11 hadoop002 192.168.171.12 原理每台主机authorized_keys文件里面包含的主机（ssh秘钥），该主机都能无密码登录，所以只要每台主机的authorized_keys文件里面都放入其他主机（需要无密码登录的主机）的ssh秘钥就行了。 配置每个节点的hosts文件vim /etc/hosts编辑hosts文件，添加如下代码 192.168.171.10 hadoopmaster 192.168.171.11 hadoop001 192.168.171.12 hadoop002 每个节点生成ssh秘钥[root@hadoopmaster ~]# ssh-keygen -t rsa # 执行命令生成秘钥 ... [root@hadoopmaster .ssh]# ls id_rsa id_rsa.pub 执行命令后会在~目录下生成.ssh文件夹，里面包含id_rsa和id_rsa.pub两个文件。 执行生成秘钥命令时会让用户选择生成地址，如果想直接使用默认地址（不想交互），则可以使用ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa命令 将每个节点的id拷贝到所有节点的authorized_keys中方法一（推荐）每个节点执行ssh自带命令，将该节点的id拷贝到其他节点中[root@hadoopmaster /]# ssh-copy-id hadoopmaster [root@hadoopmaster /]# ssh-copy-id hadoop001 [root@hadoopmaster /]# ssh-copy-id hadoop002 [root@hadoop001 /]# ssh-copy-id hadoopmaster [root@hadoop001 /]# ssh-copy-id hadoop001 [root@hadoop001 /]# ssh-copy-id hadoop002 [root@hadoop002 /]# ssh-copy-id hadoopmaster [root@hadoop002 /]# ssh-copy-id hadoop001 [root@hadoop002 /]# ssh-copy-id hadoop002 方法二在主节点上将公钥拷贝到一个特定文件中[root@hadoopmaster /]# cd ~/.ssh [root@hadoopmaster .ssh]# cp id_rsa.pub authorized_keys # 拷贝到authorized_keys文件中 [root@hadoopmaster .ssh]# ls authorized_keys id_rsa id_rsa.pub 将authorized_keys文件拷贝至下一个节点，并将该节点的ssh秘钥加入该文件中[root@hadoopmaster .ssh]# scp authorized_keys root@hadoop001:/root/.ssh/ root@hadoop001's password: # 此时会提示输入密码，输入hadoop001主机root密码即可 authorized_keys 100% 399 450.9KB/s 00:00 # 进入001主机 [root@hadoop001 /]# cd ~/.ssh [root@hadoop001 .ssh]# ls authorized_keys id_rsa id_rsa.pub [root@hadoop001 .ssh]# cat id_rsa.pub>>authorized_keys # 使用cat追加到authorized_keys文件 ssh-rsa AAAAB.....TnYjJ root@hadoop001 ssh-rsa AAAAB.....Ah+n9 root@hadoopmaster [root@hadoop001 .ssh]# 关于scp命令请点击这里查看 重复上一步动作，将每个节点的ssh秘钥都加入authorized_keys文件中将最后节点生成的authorized_keys文件复制到每个节点下即可[root@hadoop002 .ssh]# scp authorized_keys root@hadoopmaster:/root/.ssh ... [root@hadoop002 .ssh]# scp authorized_keys root@hadoop001:/root/.ssh ... 测试登录使用ssh 用户名@节点名（或ip地址）命令进行无密码登录测试 [root@hadoopmaster .ssh]# ssh root@hadoop001 Last login: Sun Sep 16 17:51:27 2018 from 192.168.171.1 [root@hadoop001 ~]# ssh root@hadoop002 Last login: Sun Sep 16 17:51:31 2018 from 192.168.171.1 [root@hadoop002 ~]# ssh root@hadoopmaster Last login: Sun Sep 16 17:51:23 2018 from 192.168.171.1 [root@hadoopmaster ~]# document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.hming.org/categories/Linux/"}],"tags":[{"name":"集群","slug":"集群","permalink":"http://blog.hming.org/tags/%E9%9B%86%E7%BE%A4/"},{"name":"Linux","slug":"Linux","permalink":"http://blog.hming.org/tags/Linux/"},{"name":"SSH","slug":"SSH","permalink":"http://blog.hming.org/tags/SSH/"}]},{"title":"Linux下安装Java","slug":"Linux下安装Java","date":"2018-09-13T16:20:12.000Z","updated":"2019-04-09T01:50:46.000Z","comments":true,"path":"2018/09/14/linux-xia-an-zhuang-java/","link":"","permalink":"http://blog.hming.org/2018/09/14/linux-xia-an-zhuang-java/","excerpt":"","text":"将Java压缩包传到Linux使用rz命令将tar包上传到Linux系统 关于rz命令，点击查看介绍 解压安装包[root@hadoopmaster mnt]# ls jdk-8u101-linux-x64.tar.gz [root@hadoopmaster mnt]# tar -zxvf jdk-8u101-linux-x64.tar.gz ... jdk1.8.0_101/man/ja_JP.UTF-8/man1/javapackager.1 jdk1.8.0_101/man/ja_JP.UTF-8/man1/jstat.1 [root@hadoopmaster mnt]# ls jdk1.8.0_101 jdk-8u101-linux-x64.tar.gz [root@hadoopmaster mnt]# 配置环境变量 vim /etc/profile编辑配置文件，添加如下代码 # java export JAVA_HOME=/home/jdk # 该路径为java安装路径 export CLASSPATH=$JAVA_HOME/lib/ export PATH=$PATH:$JAVA_HOME/bin 保存后退出 source /etc/profile刷新配置文件 验证安装状态[root@hadoopmaster mnt]# java -version java version \"1.8.0_101\" Java(TM) SE Runtime Environment (build 1.8.0_101-b13) Java HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode) [root@hadoopmaster mnt]# document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.hming.org/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://blog.hming.org/tags/Linux/"},{"name":"Java","slug":"Java","permalink":"http://blog.hming.org/tags/Java/"}]},{"title":"云操作系统基础架构选型","slug":"云操作系统选型","date":"2018-08-18T11:16:24.000Z","updated":"2018-08-18T11:16:24.000Z","comments":true,"path":"2018/08/18/yun-cao-zuo-xi-tong-xuan-xing/","link":"","permalink":"http://blog.hming.org/2018/08/18/yun-cao-zuo-xi-tong-xuan-xing/","excerpt":"","text":"——by陶老师 为什么要有“云操作系统” 我自己的思考： 当有了大数据应用、用户应用集群时,我们如何高效地管理、协调、扩展集群中的应用，以及如何使应用本身高可用、使集群资源得到充分利用（弹性伸缩能力）? 引入 DCOS 数据中心操作系统（DCOS）是为整个数据中心提供分布式调度与协调功能，实现数据中心级弹性伸缩能力的软件堆栈，它将所有数据中心的资源当做一台计算机来调度。 主流有如下几种: Apache Mesos Apache Hadoop YARN Kubernetes DCOS 案例通过以下两个案例,我们应该就能清楚的了解到DCOS是什么、DCOS能做什么、DCOS能为我们带来什么收益了。 1.浙江移动浙江移动 讲述了 IT架构的演进、虚拟化问题以及实际场景应用。 2.天玑科技天玑科技 针对电信、银行、保险行业做的案例。 Apache mesos、Kubernetes 哪一个？ 为什么不考虑 Apache Hadoop YARN？在我看来，它比较适合大数据生态圈（hadoop和spark资源管理）,对于其他的生态圈不太友好，因此不考虑用来作为整个大平台的基础架构。 参考1有哪些是Apache Mesos能做到，而Kubernetes做不到的 社区，Mesos的社区比Kubernetes的小得多。Kubernetes得到了包括谷歌、英特尔、Mirantis、RedHat等在内的众多大公司的财务支持。Mesos主要由Mesosphere公司开发，并得到了苹果、微软等公司的支持 规模，Mesos从一开始就是专门面向大客户的。在Twitter、Apple、Verizon、Yelp和Netflix都有应用，并且在数千台服务器上运行了数十万个容器。Kubernetes总的来说：Mesos比较适合大型的公司，比较稳定。 参考2 实测 Kubernetes 和 Mesos 在高并发下的网络性能 并发测试，Kubernetes略好一点。 参考3Kubernetes和Mesos有啥区别，我该使用哪个好 节点，一万以下节点，Kubernetes 较好：开发、部署 开发难度，Mesos 开发难度较高，需要深度定制 参考4区块链与容器进阶应用发布会 阿里云开始提供Kubernetes服务 BaaS平台支持 总结现阶段总体来说，使用Kubernetes 是比较好的，二次开发较少，社区活跃，资料好查，发展快速，国内使用较多，带有谷歌光环。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://blog.hming.org/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"架构","slug":"架构","permalink":"http://blog.hming.org/tags/%E6%9E%B6%E6%9E%84/"},{"name":"云操作系统","slug":"云操作系统","permalink":"http://blog.hming.org/tags/%E4%BA%91%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"Linux常用命令","slug":"Linux常用命令","date":"2018-08-15T05:42:08.000Z","updated":"2019-09-18T07:22:43.000Z","comments":true,"path":"2018/08/15/linux-chang-yong-ming-ling/","link":"","permalink":"http://blog.hming.org/2018/08/15/linux-chang-yong-ming-ling/","excerpt":"","text":"输入界面快捷操作（命令行快捷操作）操作方式及操作效果 操作方式 操作效果 Ctrl+k 剪切命令行中光标所在处之后的所有字符（包括自身） Ctrl+u 剪切命令行中光标所在处之前的所有字符（不包括自身） Ctrl+y 粘贴刚才所删除、剪切的字符 Ctrl+o 回车效果 Ctrl+j 回车效果 Ctrl+f 光标向后移动一个字符位,相当与-&gt;（右方向键） Ctrl+b 光标向前移动一个字符位,相当与&lt;-（左方向键） Alt+f 光标向后移动一个单词位 Alt+b 光标向前移动一个单词位 Ctrl+a 移动到当前行的开头 Ctrl+e 移动到当前行的结尾 Ctrl+l 清屏 清理缓存命令 说明 命令 查看内存使用情况 free -h 强制被改变的内容立刻写入磁盘，更新超块信息 sync 仅清除页面缓存（PageCache） echo 1 &gt; /proc/sys/vm/drop_caches 清除目录项和inode echo 2 &gt; /proc/sys/vm/drop_caches 清除页面缓存，目录项和inode echo 3 &gt; /proc/sys/vm/drop_caches 每个 Linux 系统有三种选项来清除缓存而不需要中断任何进程或服务。 （LCTT 译注：Cache，译作“缓存”，指 CPU 和内存之间高速缓存。Buffer，译作“缓冲区”，指在写入磁盘前的存储再内存中的内容。） 参考： https://blog.csdn.net/ailice001/article/details/80353924 https://www.cnblogs.com/yorkyang/p/9226121.html 查看CPU信息总核数 = 物理CPU个数 X 每颗物理CPU的核数总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数 查看物理CPU个数[root@centos4 ~]# cat /proc/cpuinfo| grep \"physical id\"| sort| uniq| wc -l 1 查看每个物理CPU中core的个数（核数）[root@centos4 ~]# cat /proc/cpuinfo| grep \"cpu cores\"| uniq cpu cores : 4 查看逻辑CPU的个数[root@centos4 ~]# cat /proc/cpuinfo| grep \"processor\"| wc -l 4 查看CPU信息（型号）[root@centos4 ~]# cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c 4 Intel(R) Xeon(R) CPU E5-1603 0 @ 2.80GHz scp（跨服务器拷贝）命令格式scp [参数] [原路径] [目标路径] 命令功能scp是 secure copy的缩写, scp是linux系统下基于ssh登陆进行安全的远程文件拷贝命令。linux的scp命令可以在linux服务器之间复制文件和目录。 命令参数 -1 强制scp命令使用协议ssh1-2 强制scp命令使用协议ssh2-4 强制scp命令只使用IPv4寻址-6 强制scp命令只使用IPv6寻址-B 使用批处理模式（传输过程中不询问传输口令或短语）-C 允许压缩。（将-C标志传递给ssh，从而打开压缩功能）-p 保留原文件的修改时间，访问时间和访问权限。-q 不显示传输进度条。-r 递归复制整个目录。-v 详细方式显示输出。scp和ssh(1)会显示出整个过程的调试信息。这些信息用于调试连接，验证和配置问题。-c cipher 以cipher将数据传输进行加密，这个选项将直接传递给ssh。-F ssh_config 指定一个替代的ssh配置文件，此参数直接传递给ssh。-i identity_file 从指定文件中读取传输时使用的密钥文件，此参数直接传递给ssh。-l limit 限定用户所能使用的带宽，以Kbit/s为单位。-o ssh_option 如果习惯于使用ssh_config(5)中的参数传递方式，-P port 注意是大写的P, port是指定数据传输用到的端口号-S program 指定加密传输时所使用的程序。此程序必须能够理解ssh(1)的选项。 使用实例 复制文件 scp local_file remote_username@remote_ip:remote_folder 或者 scp local_file remote_username@remote_ip:remote_file 或者 scp local_file remote_ip:remote_folder 或者 scp local_file remote_ip:remote_file 复制目录 scp -r local_folder remote_username@remote_ip:remote_folder 或者 scp -r local_folder remote_ip:remote_folder 从远程拷贝到本地同理 jobs（查看后台进程）命令格式jobs(选项)(参数) 命令功能jobs命令用于显示Linux中的任务列表及任务状态，包括后台运行的任务。该命令可以显示任务号及其对应的进程号。其中，任务号是以普通用户的角度进行的，而进程号则是从系统管理员的角度来看的。一个任务可以对应于一个或者多个进程号。 命令参数 -l：显示进程号；-p：仅任务对应的显示进程号；-n：显示任务状态的变化；-r：仅输出运行状态（running）的任务；-s：仅输出停止状态（stoped）的任务。 使用实例&amp;这个用在一个命令的最后，可以把这个命令放到后台执行 Ctrl+z将当前任务加入后台任务 [root@hadoopmaster ~]# ping www.baidu.com PING www.a.shifen.com (180.97.33.108) 56(84) bytes of data. 64 bytes from 180.97.33.108 (180.97.33.108): icmp_seq=1 ttl=128 time=45.4 ms 64 bytes from 180.97.33.108 (180.97.33.108): icmp_seq=2 ttl=128 time=45.3 ms ^Z [1]+ 已停止 ping www.baidu.com jobs显示当前后台任务列表 [root@hadoopmaster ~]# jobs [1]+ 已停止 ping www.baidu.com bg 将一个在后台暂停的命令，变成继续执行 如果后台中有多个命令，可以用bg %jobnumber将选中的命令调出，%jobnumber是通过jobs命令查到的后台正在执行的命令的序号(不是pid) fg 将后台中的命令调至前台继续运行 如果后台中有多个命令，可以用 fg %jobnumber将选中的命令调出，%jobnumber是通过jobs命令查到的后台正在执行的命令的序号(不是pid) kill杀死一个进程，用法同fg和bg alias（别名）命令格式alias ［别名=’命令’］ ，在定义别名时，等号两边不能有空格。 unalias [别名] 删除别名。 命令功能linux系统下给命令指定别名。 在linux系统中如果命令太长又不符合用户的习惯，那么我们可以为它指定一个别名。虽然可以为命令建立“链接”解决长文件名的问题，但对于带命 令行参数的命令，链接就无能为力了。而指定别名则可以解决此类所有问题。 使用实例[root@hadoopmaster ~]# java -version java version \"1.8.0_101\" Java(TM) SE Runtime Environment (build 1.8.0_101-b13) Java HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode) [root@hadoopmaster ~]# alias jv='java -version' [root@hadoopmaster ~]# jv java version \"1.8.0_101\" Java(TM) SE Runtime Environment (build 1.8.0_101-b13) Java HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode) 使用不带参数的alias时，显示当前所有已定义别名 [root@hadoopmaster ~]# alias alias cp='cp -i' alias egrep='egrep --color=auto' alias fgrep='fgrep --color=auto' alias grep='grep --color=auto' alias jv='java -version' alias l.='ls -d .* --color=auto' alias ll='ls -l --color=auto' alias ls='ls --color=auto' alias mv='mv -i' alias rm='rm -i' alias which='alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde' alias x='xcall.sh' \\+回车（换行继续输入）命令格式[未输完的命令] \\+回车 [继续未输完的命令] 命令功能当输入指令过长时，使用\\+回车可以跳到下一行继续输入指令 使用实例[root@hadoopCDH mnt]# ls -al 总用量 0 drwxr-xr-x. 3 root root 19 8月 30 16:22 . dr-xr-xr-x. 18 root root 235 8月 31 09:07 .. drwxr-xr-x. 3 root root 53 8月 30 16:23 nginx [root@hadoopCDH mnt]# ls \\ #输入\\后再回车直接进入换行输入模式 > -al 总用量 0 drwxr-xr-x. 3 root root 19 8月 30 16:22 . dr-xr-xr-x. 18 root root 235 8月 31 09:07 .. drwxr-xr-x. 3 root root 53 8月 30 16:23 nginx [root@hadoopCDH mnt]# echo（定义变量）命令格式echo ${变量名} 命令功能查看当前变量的值 设置变量需遵从的规则 变量与变量内容之间只能用=来连接，不能有任何空格 myname=liming 如果要在变量内容里面输入空格，则用双引号 myname=\"li ming\" 变数名称只能是英文字母与数字，但是开头字符不能是数字，如下为错误示范： 2myname=VBird 变量内容若有空白字符可使用双引号\"或单引号'将变量内容结合起来，但 双引号内的特殊字符如$等，可以保有原本的特性，如下所示：var=\"lang is $LANG\"则echo $var可得lang is zh_TW.UTF-8 单引号内的特殊字符则仅为一般字符(纯文字)，如下所示：var='lang is $LANG'则echo $var可得lang is $LANG 可用字符\\将特殊符号(如[Enter], $, ,空白字符, ‘等)变成一般字符，如： myname=VBird\\ Tsai 一串指令的执行中，还需要藉由其他额外的指令所提供的资讯时，可以使用反单引号『`指令`』或『$(指令)』。特别注意，那个`是键盘上方的数字键1左边那个按键，而不是单引号！例如想要取得核心版本的设定： version=$(uname -r)再echo $version可得3.10.0-229.el7.x86_64 若该变量为扩增变量内容时，则可用\"$变量名称\"或${变量}累加内容，如下所示： PATH=\"$PATH\":/home/bin或PATH=${PATH} :/home/bin 若该变量需要在其他子程序执行，则需要以export来使变量变成环境变量： export PATH 通常大写字符为系统预设变量，自行设定变量可以使用小写字符，方便判断(纯粹依照使用者兴趣与爱好) ； 取消变量的方法为使用unset 变量名称例如取消myname的设定： unset myname 使用实例[root@hadoopCDH mnt]# echo $NGINX_HOME /usr/local/nginx [root@hadoopCDH mnt]# myname=liming [root@hadoopCDH mnt]# echo $myname liming [root@hadoopCDH mnt]# echo ${myname} liming [root@hadoopCDH mnt]# ntpdate（服务器时间同步）命令格式ntpdate time1.aliyun.com 命令功能同步时间，与阿里云服务器时间同步。 使用实例[root@hadoopmaster bin]# xcall.sh ntpdate time1.aliyun.com ========== hadoopmaster ========== 11 Sep 09:45:55 ntpdate[6548]: adjust time server 203.107.6.88 offset 0.007047 sec ========== hadoop001 ========== 11 Sep 09:46:02 ntpdate[6278]: adjust time server 203.107.6.88 offset 0.002663 sec ========== hadoop002 ========== 11 Sep 09:46:08 ntpdate[4192]: adjust time server 203.107.6.88 offset 0.005169 sec [root@hadoopmaster bin]# history（历史命令查看）命令格式及功能 命令格式 命令 history 显示命令历史列表 ↑(Ctrl+p) 显示上一条命令 ↓(Ctrl+n) 显示下一条命令 !num 执行命令历史列表的第num条命令 !! 执行上一条命令 !?string? 执行含有string字符串的最新命令 使用实例 设置显示命令时间 [root@hadoopmaster ~]# echo 'export HISTTIMEFORMAT='%F %T ' \"' &gt;&gt; /etc/profile # 将`export HISTTIMEFORMAT='%F %T '`添加进配置文件`/etc/profile` [root@hadoopmaster ~]# source /etc/profile # 刷新配置文件使其生效 [root@hadoopmaster ~]# history 5 # 查看最近5条记录，发现显示了时间 1063 2018-09-15 11:00:39 history --help 1064 2018-09-15 11:04:14 cd ~ 1065 2018-09-15 11:04:50 echo 'HISTTIMEFORMAT=\"%F %T \"' &gt;&gt; /etc/profile 1066 2018-09-15 11:05:01 vim /etc/profile 1067 2018-09-15 11:07:07 history 5 执行历史某条命令 [root@hadoopmaster ~]# history 4 # 显示最近4条记录 1066 2018-09-15 11:05:01 vim /etc/profile 1067 2018-09-15 11:07:07 history 5 1068 2018-09-15 11:08:30 ls 1069 2018-09-15 11:08:37 history 5 [root@hadoopmaster ~]# !1068 # 执行1068条，也就是ls命令 ls anaconda-ks.cfg zookeeper.out [root@hadoopmaster ~]# passwd（修改密码）命令格式passwd [用户名] 命令功能修改账户密码 使用实例[root@slave001 /]# passwd root # 修改root密码 Changing password for user root. New password: # 设置新密码 BAD PASSWORD: The password is shorter than 8 characters Retype new password: # 确认新密码 passwd: all authentication tokens updated successfully. 修改root密码也可以使用下面一句命令搞定 [root@a3c8baf6961e /]# echo \"1234\" | passwd --stdin root # 将root密码设置为1234 ss（查看端口占用）命令格式ss [参数] ss [参数] [过滤] 命令功能ss(Socket Statistics的缩写)命令可以用来获取 socket统计信息（查询端口占用），比 netstat 更快速高效 命令参数 -h, –help 帮助信息 -V, –version 程序版本信息 -n, –numeric 不解析服务名称 -r, –resolve 解析主机名 -a, –all 显示所有套接字（sockets） -l, –listening 显示监听状态的套接字（sockets） -o, –options 显示计时器信息 -e, –extended 显示详细的套接字（sockets）信息 -m, –memory 显示套接字（socket）的内存使用情况 -p, –processes 显示使用套接字（socket）的进程 -i, –info 显示 TCP内部信息 -s, –summary 显示套接字（socket）使用概况 -4, –ipv4 仅显示IPv4的套接字（sockets） -6, –ipv6 仅显示IPv6的套接字（sockets） -0, –packet 显示 PACKET 套接字（socket） -t, –tcp 仅显示 TCP套接字（sockets） -u, –udp 仅显示 UCP套接字（sockets） -d, –dccp 仅显示 DCCP套接字（sockets） -w, –raw 仅显示 RAW套接字（sockets） -x, –unix 仅显示 Unix套接字（sockets） 使用实例显示Sockets摘要ss -s [root@localhost ~]# ss -s Total: 7089 (kernel 10238) TCP: 600 (estab 267, closed 279, orphaned 0, synrecv 0, timewait 195/0), ports 0 Transport Total IP IPv6 * 10238 - - RAW 0 0 0 UDP 3 2 1 TCP 321 203 118 INET 324 205 119 FRAG 0 0 0 显示TCP连接ss -t -a [root@localhost ~]# ss -t -a State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 0 127.0.0.1:smux *:* LISTEN 0 0 *:3690 *:* LISTEN 0 0 *:ssh *:* ESTAB 0 0 192.168.120.204:ssh 10.2.0.68:49368 找出占用套接字/端口的应用程序ss -anlp | grep 8080 [root@localhost ~]# ss -anlp | grep 8088 tcp LISTEN 0 128 ::ffff:10.75.4.31:8088 :::* users:((\"java\",pid=11935,fd=225)) watch（检测命令运行结果）命令格式watch [参数] [命令] 命令功能监测一个命令的运行结果，周期性刷新结果，省得一遍遍的手动运行 命令参数 -n或–interval watch缺省每2秒运行一下程序，可以用-n或-interval来指定间隔的时间。 -d或–differences 用-d或–differences 选项watch 会高亮显示变化的区域。 而-d=cumulative选项会把变动过的地方(不管最近的那次有没有变动)都高亮显示出来。 -t或-no-title 会关闭watch命令在顶部的时间间隔,命令，当前时间的输出。 命令实例watch -n 1 -d netstat -ant 每隔一秒高亮显示网络链接数的变化情况watch -n 10 'cat /proc/loadavg' 10秒一次输出系统的平均负载 其他操作Ctrl+c退出观察模式 rz与sz（上传、下载文件）当我们使用虚拟终端软件，如Xshell、SecureCRT或PuTTY来连接远程服务器后，需要上传、下载文件到本地，可以使用该命令。使用前可能需要安装lrzsz软件：yum -y install lrzsz rz（Receive ZMODEM）命令格式rz [选项] 命令功能使用ZMODEM协议，将本地文件批量上传到远程Linux/Unix服务器，注意不能上传文件夹。 命令参数 -+, –append:将文件内容追加到已存在的同名文件-a,–ascii:以文本方式传输-b, –binary:以二进制方式传输，推荐使用--delay-startup N:等待N秒-e, –escape:对所有控制字符转义，建议使用-E, –rename:已存在同名文件则重命名新上传的文件，以点和数字作为后缀-p, –protect:对ZMODEM协议有效，如果目标文件已存在则跳过-q, –quiet:安静执行，不输出提示信息-v, –verbose:输出传输过程中的提示信息-y, –overwrite:存在同名文件则替换-X, –xmodem:使用XMODEM协议--ymodem:使用YMODEM协议-Z, –zmodem:使用ZMODEM协议--version：显示版本信息--h, –help：显示帮助信息 命令实例 输入rz，然后回车，选择本地文件上传 以二进制，并对控制字符进行转义，替换已存在的同名文件。[root@hadoopmaster opt]# rz -bye sz（Send ZMODEM）命令格式sz [选项] [filelist] 命令功能通过ZMODEM协议，可将多个文件从远程服务器下载到本地。注意不能下载文件夹，如果下载文件夹，请先打包再下载 命令参数选项参数与rz相同，请参考上文中rz命令参数，或者运行命令sz -h查看 命令实例下载多个文件 [root@hadoopmaster opt]# sz file1 file2 file3 wc（Word Count单词统计）命令格式wc [选项] [文件] 命令功能统计指定文件中的字节数、字数、行数，并将统计结果显示输出。 命令参数 -c 统计字节数。-l 统计行数。-m 统计字符数。这个标志不能与 -c 标志一起使用。-w 统计字数。一个字被定义为由空白、跳格或换行字符分隔的字符串。-L 打印最长行的长度。 使用实例[hdfs@centos3 log]$ wc -l mysqld.log 7756 mysqld.log [hdfs@centos3 log]$ jps 10842 Jps 19566 DataNode [hdfs@centos3 log]$ jps | wc -l 2 w（显示目前登入系统的用户信息）命令格式w [选项] 命令功能目前登入系统的用户有哪些人，以及他们正在执行的程序。 命令参数 -f 开启或关闭显示用户从何处登入系统。-h 不显示各栏位的标题信息列。-l 使用详细格式列表，此为预设值。-s 使用简洁格式列表，不显示用户登入时间，终端机阶段作业和程序所耗费的CPU时间。-u 忽略执行程序的名称，以及该程序耗费CPU时间的信息。 使用实例[root@centos3 ~]# w 16:23:23 up 29 days, 21:28, 5 users, load average: 0.41, 0.42, 0.40 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root pts/0 10.75.4.14 16:11 27.00s 9.31s 9.28s /home/jdk/bin/java -Dproc_jar -Dhdp.version=3.1.0.0-78 -Djava.net.preferIPv4Stack=true -Dhdp.version=3.1.0.0-78 -Xmx1024m -Xmx256m -Dlog4j.configurationFile=hive-log4j2.pr root pts/1 10.75.4.12 15:43 19.00s 43.79s 43.79s -bash root pts/2 10.76.34.243 09:22 7:00m 1.69s 1.62s vim messages root pts/3 10.75.4.12 16:23 3.00s 0.00s 0.00s -bash root pts/5 10.75.4.11 Mon15 3.00s 0.06s 0.06s -bash 查看相应ssh连接进程号，可以通过kill -9 命令杀掉进程 [root@centos3 ~]# w 16:36:49 up 29 days, 21:41, 4 users, load average: 2.03, 0.96, 0.66 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root pts/0 10.75.4.14 16:26 9:05 0.00s 0.00s -bash root pts/1 10.75.4.12 15:43 2:49 2:15 2:15 -bash root pts/2 10.75.4.11 16:35 1.00s 20.22s 0.00s w root pts/3 10.75.4.12 16:23 2:49 1:27 1:27 -bash [root@centos3 ~]# ps aux | grep sshd root 1105 0.0 0.0 112796 1280 ? Ss Feb18 0:00 /usr/sbin/sshd -D root 4368 1.2 0.0 161400 6192 ? Ss 15:43 0:40 sshd: root@pts/1 root 19926 11.3 0.0 161400 6200 ? Ss 16:23 1:39 sshd: root@pts/3 root 21314 0.8 0.0 161400 6044 ? Ss 16:26 0:05 sshd: root@pts/0 root 24001 0.0 0.0 161400 6044 ? Ss 16:35 0:00 sshd: root@pts/2 root 24932 0.0 0.0 112728 996 pts/2 S+ 16:37 0:00 grep --color=auto sshd [root@centos3 ~]# kill -9 4368 [root@centos3 ~]# w 16:38:35 up 29 days, 21:43, 4 users, load average: 1.55, 1.18, 0.78 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root pts/0 10.75.4.14 16:26 10:51 0.00s 0.00s -bash root pts/2 10.75.4.11 16:35 3.00s 20.23s 0.00s w root pts/3 10.75.4.12 16:23 4:35 2:33 2:33 -bash hostnamectl（查看修改主机名）命令格式hostnamectl [选项] 命令功能查看和修改主机名。 在CentOS中，有三种定义的主机名:静态的（static），瞬态的（transient），和灵活的（pretty）。静态主机名也称为内核主机名，是系统在启动时从/etc/hostname自动初始化的主机名。瞬态主机名是在系统运行时临时分配的主机名，例如，通过DHCP或mDNS服务器分配。静态主机名和瞬态主机名都遵从作为互联网域名同样的字符限制规则。而另一方面，灵活主机名则允许使用自由形式（包括特殊/空白字符）的主机名，以展示给终端用户（如hdp001）。 命令参数[root@hdp001 ~]# hostnamectl --help hostnamectl [OPTIONS...] COMMAND ... Query or change system hostname. -h --help 查看帮助 --version 显示包版本 --no-ask-password 不要提示输入密码 -H --host=[USER@]HOST 在远程主机上运行 -M --machine=CONTAINER 在本地容器上操作 --transient 仅设置瞬态主机名 --static 仅设置静态主机名 --pretty 只设置灵活的主机名 Commands: status 显示当前主机名设置 set-hostname NAME 设置系统主机名 set-icon-name NAME 设置主机的图标名称 set-chassis NAME 设置主机的机箱类型 set-deployment NAME 为主机设置部署环境 set-location NAME 设置主机的位置 使用实例查看当前主机名 [root@hdp002 ~]# hostnamectl Static hostname: hdp002 Icon name: computer-vm Chassis: vm Machine ID: e47dbc1c37d64b7ebcb988e0ecf1836a Boot ID: 93fa221f8aae49a183970941c4ad5d48 Virtualization: vmware Operating System: CentOS Linux 7 (Core) CPE OS Name: cpe:/o:centos:centos:7 Kernel: Linux 3.10.0-862.el7.x86_64 Architecture: x86-64 仅查看静态主机名 [root@hdp002 ~]# hostnamectl --static hdp002 修改主机名 [root@hdp002 ~]# hostnamectl set-hostname hdp002.segma.tech [root@hdp002 ~]# hostnamectl --static hdp002.segma.tech firewall-cmd（防火墙相关命令）命令格式firewall-cmd [选项] 命令功能操作防火墙相关命令。 使用实例查看防火墙所有信息 [root@1 ~]# firewall-cmd --list-all public (active) target: default icmp-block-inversion: no interfaces: eth0 sources: services: dhcpv6-client ssh ports: 1996/tcp 1996/udp 80/tcp protocols: masquerade: no forward-ports: source-ports: icmp-blocks: rich rules: 查看防火墙开放端口信息 [root@1 ~]# firewall-cmd --list-ports 1996/tcp 1996/udp 80/tcp 新增开放端口 [root@1 ~]# firewall-cmd --zone=public --add-port=80/tcp --permanent success –-zone 作用域 –-add-port=80/tcp 添加端口，格式为：端口/通讯协议 –-permanent 永久生效，没有此参数重启后失效 新增多个端口 [root@1 ~]# firewall-cmd --zone=public --add-port=80-90/tcp --permanent success 重新加载防火墙规则 [root@1 ~]# firewall-cmd --reload success 删除端口 [root@1 ~]# firewall-cmd --zone=public --remove-port=80/tcp --permanent document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.hming.org/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://blog.hming.org/tags/Linux/"},{"name":"命令","slug":"命令","permalink":"http://blog.hming.org/tags/%E5%91%BD%E4%BB%A4/"}]},{"title":"VMware虚拟机静态IP配置","slug":"VMware虚拟机静态IP配置","date":"2018-08-09T08:21:22.000Z","updated":"2018-08-09T08:21:22.000Z","comments":true,"path":"2018/08/09/vmware-xu-ni-ji-jing-tai-ip-pei-zhi/","link":"","permalink":"http://blog.hming.org/2018/08/09/vmware-xu-ni-ji-jing-tai-ip-pei-zhi/","excerpt":"","text":"VMware虚拟机网卡的两种模式：Bridged（桥接）和NAT（转发）。 Bridged（桥接模式）桥接模式可以让虚拟机的网络和物理机的网络处于平行的网络中，和物理机处于同一个网段的其他物理机就能ping通该虚拟机。 NAT模式该模式虚拟机自己创建一套网络，只有物理机和虚拟机处于同一局域网内，与物理机处于同一网段的无法连接虚拟机。虚拟机通过物理机的网卡进行外网访问。 根据自己需求选择模式，如果是想搭建一套不受外界干扰的局域网络，则用NAT模式。如果想与外界其他处于同一网段的物理机通信，则选择桥接模式 NAT模式1.查看网关和网段虚拟机点击【编辑】→【虚拟网络编辑器】 使用NAT模式，选择VMnet8。取消勾选【使用本地DHCP…】，勾选会设置动态ip。 点击NAT设置，记住子网IP范围，如图表示我们只能设置虚拟机在192.168.40.0~192.168.40.255范围内。 注意： 192.168.40.2为网关地址，192.168.40.255为广播地址，192.168.40.0一般为网段IP，所以0,2,255这三个地址不能设置 2.设置虚拟机IP地址涉及文件列表： /etc/sysconfig/network-scripts/ifcfg-*（网卡）（*根据实际情况不同，本文为ens33） /etc/sysconfig/network（主机名） /etc/resolv.conf（DNS） 网卡信息修改 vi /etc/sysconfig/network-scripts/ifcfg-ens33 TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=static DEFROUTE=yes NAME=ens33 UUID=d7a7196e-5033-4849-bcc5-f8c52acd245c DEVICE=ens33 ONBOOT=yes IPADDR=192.168.40.3 NETMASK=255.255.255.0 GATEWAY=192.168.40.2ONBOOT：开机启动。 NM_CONTROLLED：网络管理组件是否启用，精简版的是没有这个组件的。所以就不需要开启。 BOOTPROTO：网络分配方式，静态。 IPPADDR：手动指定ip地址。 NETMASK：子网掩码。 GATEWAY：网关ip。编辑好以后保存退出。 DNS配置 vi /etc/resolv.conf nameserver 8.8.8.8 nameserver 8.8.4.4nameserver：这里填对应的dns域名解析服务器的ip。 可以指定多个，其他的默认为备用DNS 主机名修改 vi /etc/sysconfig/network # Created by anaconda NETWORKING=yes HOSTNAME=hadoop001有需要就可以修改主机名。配置完三个文件重启一下机器（或者/etc/rc.d/init.d/network restart重启网络）。 3.确保Linux虚拟机网络适配器选项 选择虚拟机，点击右键→【设置】 【硬件】→【网络适配器】→选择【NAT模式】 4.Windows IP设置设置VMWare给我们配置的网络适配器，就是那个NAT8。右键属性 点击IPv4设置 设置Windows的ip地址，该地址也在范围内。 配置完之后就可以使用xshell等工具连接了。 Bridged（桥接模式）1.VM设置 查看物理机网卡名称 根据网卡，查看物理机ip网段信息进入cmd命令行，执行ipconfig /all 虚拟机点击【编辑】→【虚拟网络编辑器】选择正确的网卡 设置将要使用的虚拟机网络适配器，将其改为桥接模式。 2.设置虚拟机IP地址涉及文件列表： /etc/sysconfig/network-scripts/ifcfg-*（网卡）（*根据实际情况不同，本文为ens33） /etc/sysconfig/network（主机名） /etc/resolv.conf（DNS） 网卡信息修改 vi /etc/sysconfig/network-scripts/ifcfg-ens33 TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=static DEFROUTE=yes NAME=ens33 UUID=d7a7196e-5033-4849-bcc5-f8c52acd245c DEVICE=ens33 ONBOOT=yes IPADDR=192.168.88.3 # 这里网段要和物理机网段一致 NETMASK=255.255.255.0 GATEWAY=192.168.88.1 # 网关也要和物理机一样ONBOOT：开机启动。 NM_CONTROLLED：网络管理组件是否启用，精简版的是没有这个组件的。所以就不需要开启。 BOOTPROTO：网络分配方式，静态。 IPPADDR：手动指定ip地址。 NETMASK：子网掩码。 GATEWAY：网关ip。编辑好以后保存退出。 DNS配置 vi /etc/resolv.conf nameserver 8.8.8.8 nameserver 8.8.4.4nameserver：这里填对应的dns域名解析服务器的ip。 可以指定多个，其他的默认为备用DNS 主机名修改 vi /etc/sysconfig/network # Created by anaconda NETWORKING=yes HOSTNAME=hadoop001有需要就可以修改主机名。配置完三个文件重启一下机器（或者/etc/rc.d/init.d/network restart重启网络）。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.hming.org/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://blog.hming.org/tags/Linux/"},{"name":"IP","slug":"IP","permalink":"http://blog.hming.org/tags/IP/"},{"name":"虚拟机","slug":"虚拟机","permalink":"http://blog.hming.org/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"VMware","slug":"VMware","permalink":"http://blog.hming.org/tags/VMware/"}]},{"title":"遇到多个构造器参数时的最优解决方案","slug":"遇到多个构造器参数时的最优解决方案","date":"2017-08-17T15:54:11.000Z","updated":"2017-08-17T15:54:11.000Z","comments":true,"path":"2017/08/17/yu-dao-duo-ge-gou-zao-qi-can-shu-shi-de-zui-you-jie-jue-fang-an/","link":"","permalink":"http://blog.hming.org/2017/08/17/yu-dao-duo-ge-gou-zao-qi-can-shu-shi-de-zui-you-jie-jue-fang-an/","excerpt":"今天在写代码的时候，忽然发现为bean设置属性代码特别的多，冗余，例如： MyData myData = new MyData(); myData.setA1(1.0); myData.setA2(1.0); myData.setA3(1.0); myData.setA4(1.0); myData.setA5(1.0); myData.setQuality(\"ok\"); 经学长指点，发现可以用Builder模式解决这个问题，在此总结一下Builder模式。","text":"今天在写代码的时候，忽然发现为bean设置属性代码特别的多，冗余，例如： MyData myData = new MyData(); myData.setA1(1.0); myData.setA2(1.0); myData.setA3(1.0); myData.setA4(1.0); myData.setA5(1.0); myData.setQuality(\"ok\"); 经学长指点，发现可以用Builder模式解决这个问题，在此总结一下Builder模式。 遇到多个构造器参数时的最优解决方案一、传统的做法当遇到构造器里面有很多的参数需要传递时，最原始的做法可能就是直接传参数。 public class MyData{ private double A1; private double A2; private double A3; private double A4; private double A5; public MyData() { } public MyData(double a1, double a2, double a3, double a4, double a5) { A1 = a1; A2 = a2; A3 = a3; A4 = a4; A5 = a5; } } MyData myData = new MyData(1.0,0,2.0,3.3,4.2,5.9); 缺点：这个构造器调用通常需要设置你原本不想设置的参数，（比如上例中的A2）。而且这种方式可读性不高，就这样看，谁知道你的哪个参数对应着哪个属性呢？ 二、一种替代方式JavaBeans模式，这种模式调用一个无参构造器来创建对象，然后调用setter方法来设置你想要设置的参数。 public class MyData{ private double A1; private double A2; private double A3; private double A4; private double A5; public MyData() { } public MyData(double a1, double a2, double a3, double a4, double a5) { A1 = a1; A2 = a2; A3 = a3; A4 = a4; A5 = a5; } public double getA1() { return A1; } public void setA1(double a1) { A1 = a1; } public double getA2() { return A2; } public void setA2(double a2) { A2 = a2; } public double getA3() { return A3; } public void setA3(double a3) { A3 = a3; } public double getA4() { return A4; } public void setA4(double a4) { A4 = a4; } public double getA5() { return A5; } public void setA5(double a5) { A5 = a5; } } MyData myData = new MyData(); myData.setA1(1.0); myData.setA2(1.0); myData.setA3(1.0); myData.setA4(1.0); myData.setA5(1.0); 这种方式貌似完全解决了构造器参数可读性不高的问题，但是这种方式有着严重的缺点：这个对象的构造过程被分到了几个调用当中，在构建过程中JavaBean可能处于不一致的状态，也就是说需要程序员付出额外的努力来确保它的线程安全。 三、Builder模式这种方式不直接生成对象，而是根据你需要设置的属性参数调用构造器，得到一个builder对象。然后在builder对象上调用类似setter的方法，来设置每个相关的可选参数。最后利用builder的无参build方法（create方法）来生成不可变的对象。 public class MyDataBuilder { private double a1; private double a2; private double a3; private double a4; private double a5; public MyDataBuilder setA1(double a1) { this.a1 = a1; return this; } public MyDataBuilder setA2(double a2) { this.a2 = a2; return this; } public MyDataBuilder setA3(double a3) { this.a3 = a3; return this; } public MyDataBuilder setA4(double a4) { this.a4 = a4; return this; } public MyDataBuilder setA5(double a5) { this.a5 = a5; return this; } public MyData createMyData() { return new MyData(a1, a2, a3, a4, a5); } } 这时，创建对象就可以这么写： MyData myData = new MyDataBuilder() .setA1(2.0) .setA3(3.0) .setA4(4.0) .setA5(5.0) .createMyData(); 可以看到，这种builder方式既能清晰的看到每个参数的对应属性，又能保证类在创建时的一致性（因为生成对象的操作在一句语句中），另外还便于阅读，较JavaBeans的方法也减少了一些无用的代码编写量，更简洁，便于编写。 在idea中如何快速生成Builder类不得不说idea是个很强大的编译器，它提供了类的构建器的自动创建，但前提是该类必须有包含所有必须属性参数的构造器。 为类生成带有全部必须属性的构造器在类中右键选择Generate（也可以使用快捷键：Alt+Insert）得到以下面板后点击Constructor选择需要生成构造器的属性点击ok生成 注意：在自定义有参构造器时，需要重写一个无参的构造器 在需要生成的类里面右键，选择Refactor生成后： 总结Builder模式也有它自身的不足之处。为了创建对象，必须先创建它的构建器。虽然创建构建器的开销在实践中可能不是那么明显，但是在十分注重性能的情况下，可能就成问题了。最后，如果类的构造器或者静态工厂中具有多个参数，设计这种类时，Builder模式就是中不错的选择。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Java","slug":"Java","permalink":"http://blog.hming.org/categories/Java/"}],"tags":[{"name":"构造器","slug":"构造器","permalink":"http://blog.hming.org/tags/%E6%9E%84%E9%80%A0%E5%99%A8/"},{"name":"创建对象","slug":"创建对象","permalink":"http://blog.hming.org/tags/%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1/"}]},{"title":"程序员必知的8大排序算法","slug":"程序员必知的8大排序算法","date":"2017-08-09T14:34:25.000Z","updated":"2017-08-20T14:34:25.000Z","comments":true,"path":"2017/08/09/cheng-xu-yuan-bi-zhi-de-8-da-pai-xu-suan-fa/","link":"","permalink":"http://blog.hming.org/2017/08/09/cheng-xu-yuan-bi-zhi-de-8-da-pai-xu-suan-fa/","excerpt":"","text":"8种排序之间的关系 一、插入排序直接插入排序 思想：在要排序的一堆数组中，假设前面的（n-1）[n&gt;=2]个数已经是排好序的，现在要把第n个数插入到之前的有序数中，使得这n个数也是排好序的。如此反复直到所有的数都排好顺序。 实例： 用java实现： public int[] insertSort() { int a[] = {4, 2, 3, 1}; int temp = 0; for (int i = 1; i &lt; a.length; i++) { //第一次i是第二个元素，第一次是第二个元素和前面比较 int j = i - 1; //temp为当前需要插入的元素 temp = a[i]; //j为temp之前的一个元素 for (; j >= 0 &amp;&amp; temp &lt; a[j]; j--) {//如果j还指向数组中的元素（大于等于0），且大于temp a[j + 1] = a[j]; //将大于temp的值整体后移一个单位 } a[j + 1] = temp; //最后将temp放到自己应该存在的位置 } return a; } 希尔排序（最小增量排序）为直接插入排序的改进版，先进行分组的直接插入排序，直到整个数组呈基本有序的情况，再对整个数组进行一次直接插入排序。 思想： 划分组：把原始组分成多少分（按照每组d个元素分）。排序组：每个划分组中的第i个数所组成的组（用于排序）。 先将要排序的一组数按某个增量d（n/2，n为要排序数的个数，除不尽向上取整）分成若干组（这里暂且称它为划分组），每个划分组有d个数据（最后一组可能小于d），再取每划分组中对应的元素组成新的组（每一组的第i个为新的一组，如：每一组的第一个组成一组，这里暂且称它为排序组），对形成的排序组每组作直接插入排序。然后再用较小的增量d/2对它进行分划分组、排序组，每个排序组中再进行直接插入排序，直到增量减小到1，再最后进行一次直接插入排序。 实例： 用java实现： public int[] shellSort() { int a[] = {4, 2, 3, 1}; double d1 = a.length; int temp = 0; while (true) { //算出每一轮的增量 d1 = Math.ceil(d1/2); int d = (int) d1; //该循环取得每个需要进行直接插入排序的数组，x为原始数组中的脚标， //代表每个组中提取的第几个元素来组成新的分组进行排序 for (int x = 0; x &lt; d; x++) { //该循环为直接插入排序（只是排序的目标数组变成了角标相差为d的数所组成的数组） for (int i = x + d; i &lt; a.length; i += d) { int j = i - d; temp = a[i]; //直接插入排序的算法，只是将直接插入排序的1抽象为了d for (; j >= 0 &amp;&amp; temp &lt; a[j]; j -= d) { a[j + d] = a[j]; //将需要排序的组中大于temp的向后移（移动单位为d） } a[j + d] = temp; //将temp放到它应该在的位置 } } if (d == 1) { break; } } return a; } 二、选择排序简单选择排序堆排序三、交换排序冒泡排序 基本思路：对需要排序的数组自上而下对相邻的两个数进行比较，让较大的数往下沉，较小的数往上冒。即：每当相邻的两个数不满足要求的排序时，将它们交换 实例： 用java实现： public int[] bubbleSort(){ int a[] = {4, 2, 3, 1}; for(int i = a.length-1 ; i>0 ; i--){ //比较前面多少位 for(int j = 0 ; j&lt;i ; j++){ //从第一位开始，把大的数往后冒 if(a[j] > a[j+1]){ int temp = a[j]; a[j] = a[j+1]; a[j+1] = temp; } } } return a; } 快速排序四、归并排序五、基数排序 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"算法","slug":"算法","permalink":"http://blog.hming.org/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://blog.hming.org/tags/%E7%AE%97%E6%B3%95/"},{"name":"排序","slug":"排序","permalink":"http://blog.hming.org/tags/%E6%8E%92%E5%BA%8F/"}]},{"title":"HTTP协议","slug":"HTTP协议","date":"2017-08-09T14:27:24.000Z","updated":"2017-08-09T14:27:24.000Z","comments":true,"path":"2017/08/09/http-xie-yi/","link":"","permalink":"http://blog.hming.org/2017/08/09/http-xie-yi/","excerpt":"","text":"HTTP（HyperText Transfer Protocol，超文本传输协议）TCP/IP的分层管理应用层、传输层、网络层、数据链路层TCP/IP协议族各层的作用： 名称 作用 协议 应用层 决定了向用户提供应用服务时通信的活动。 FTP（文件传输协议）、DNS（域名系统）、HTTP协议也处于该层 传输层 对上层应用层提供处于网络连接中的两台计算机之间的数据传输。 TCP（传输控制协议）、UDP（用户数据报协议） 网络层（网络互连层） 用来处理在网络上流动的数据包。数据包是网络传输的最小数据单位。规定了通过怎样的路径（所谓的传输路线）到达对方计算机，并把数据包传送给对方 链路层（数据链路层） 用来处理连接网络的硬件部分。包括控制操作系统、硬件的设备驱动、NIC（Network Interface Card，网络适配器，即网卡），及光纤等物理可见部分（还包括连接器等一切传输媒介） 与HTTP关系密切的协议：IP、TCP和DNS负责传输的IP协议IP（Internet Protocol，网际协议）几乎所有使用网络的系统都会用到IP协议。不要把IP和IP地址混淆，IP其实是一种协议的名称，而IP地址是网络中计算机通讯时的地址。IP协议的作用是把各种数据包传送给对方。而要保证确实传送到对方那里，则需要满足各类条件。其中两个重要的条件是IP地址和MAC地址（Media Access Control Address）。IP地址可以和MAC地址进行配对。 IP地址 MAC地址 指明了节点被分配到的地址 网卡所属的固定地址 可变换 基本上不会更改 确保可靠性的TCP协议提供可靠的字节流服务。将大块数据分割成以报文段为单位的数据包进行管理。为了准确无误的将数据送达目标处，TCP协议采用了三次握手策略，握手过程中使用到了TCP的标志（flag）：SYN（synchronize）和ACK（acknowledgement）。发送端首先发送一个SYN的数据包给对方。接收端收到后，回传一个带有SYN/ACK标志的数据包以示传达确认信息。最后，发送端再回传一个带ACK标志的数据包，代表“握手”结束。 标有SYN的数据包发给你—–&gt; 发送端 &lt;—–收到你的数据包（发送带有SYN/ACK的数据包） 接收端 明白！（发送带有ACK的数据包）—–&gt; 负责域名解析的DNS服务DNS（Domain Name System）服务提供域名到IP地址之间的解析服务。 URI和URLURI统一资源标识符，用字符串标识某一互联网资源。URL统一资源定位符，表示资源的地点。是URI的子集。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"网络协议","slug":"网络协议","permalink":"http://blog.hming.org/categories/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"}],"tags":[{"name":"网络","slug":"网络","permalink":"http://blog.hming.org/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Http","slug":"Http","permalink":"http://blog.hming.org/tags/Http/"}]},{"title":"MongoDB的安装以及MongoDB Replicat Set复制集的搭建","slug":"MongoDB的安装以及MongoDB-Replicat-Set复制集的搭建","date":"2017-07-29T03:32:03.000Z","updated":"2017-07-29T03:32:03.000Z","comments":true,"path":"2017/07/29/mongodb-de-an-zhuang-yi-ji-mongodb-replicat-set-fu-zhi-ji-de-da-jian/","link":"","permalink":"http://blog.hming.org/2017/07/29/mongodb-de-an-zhuang-yi-ji-mongodb-replicat-set-fu-zhi-ji-de-da-jian/","excerpt":"","text":"一、搭建MongoDB单机环境MongoDB 是一个基于分布式文件存储的数据库。由 C++ 语言编写。旨在为 WEB 应用提供可扩展的高性能数据存储解决方案。 A、使用APT安装参考官方安装文档 1. 导入public keysudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 0C49F3730359A14518585931BC711F9BA15703C6 2. 导入源（不同Ubuntu版本的源不一样，此处采用Ubuntu 16.04）echo \"deb [ arch=amd64,arm64 ] http://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.4 multiverse\" | sudo tee /etc/apt/sources.list.d/mongodb-org-3.4.list 3. 重新加载本地源sudo apt-get update 4. 安装mongodbsudo apt-get install -y mongodb-org 5. 修改配置文件 配置文件默认文件目录/etc/mongod.conf默认存储其数据文件/var/lib/mongodb默认日志文件/var/log/mongodb/mongod.log 6. 启动mongodbmongod -f /etc/mongod.conf 7. 卸载mongodb1)停止mongodb服务 sudo service mongod stop 2)删除软件包删除您以前安装的任何MongoDB包。 sudo apt-get purge mongodb-org * 3)删除数据目录删除数据库和日志文件 sudo rm -r / var / log / mongodb sudo rm -r / var / lib / mongodb B、使用安装包安装到清华开源镜像下载相应的包 1. 解压到需要安装的目录tar zxvf mongodb-linux-x86_64-ubuntu1604-3.4.4.tgz tar命令参数详解：-c ：建立打包档案，可搭配-v 来察看过程中被打包的档名(filename)-t ：察看打包档案的内容含有哪些档名，重点在察看『档名』就是了；-x ：解打包或解压缩的功能，可以搭配-C (大写) 在特定目录解开特别留意的是， -c, -t, -x 不可同时出现在一串指令列中。-z ：透过gzip 的支援进行压缩/解压缩：此时档名最好为*.tar.gz-j ：透过bzip2 的支援进行压缩/解压缩：此时档名最好为*.tar.bz2-J ：透过xz 的支援进行压缩/解压缩：此时档名最好为*.tar.xz特别留意， -z, -j, -J 不可以同时出现在一串指令列中。-v ：在压缩/解压缩的过程中，将正在处理的档名显示出来！-f filename：-f 后面要立刻接要被处理的档名！建议-f 单独写一个选项啰！(比较不会忘记)-C 目录：这个选项用在解压缩，若要在特定目录解压缩，可以使用这个选项。更多的压缩命令参考鸟哥的Linux私房菜之档案的压缩、解压 2. 创建存放数据文件目录以及日志文件目录（可以自己指定）可以创建多个数据库存放路径，每个数据库对应一个conf配置文件，mongodb只需要安装一次 mkdir -p /mongodb/db # 创建数据文件夹 mkdir -p /mongodb/log touch /mongodb/log/mongodb.log #创建文件 3. 在适当的路径编辑配置文件（后缀可选conf和yaml）vi mongodb.conf 配置文件模板： # mongodb.conf # Where and how to store data. storage: dbPath: /mongodb/data journal: enabled: true # engine: # mmapv1: # wiredTiger: # where to write logging data. systemLog: destination: file logAppend: true path: /mongodb/log/mongodb.log # network interfaces net: port: 28001 # bindIp: 127.0.0.1 processManagement: fork: true #security: #operationProfiling: 文件路径修改为设置的存储路径，端口可自定义（一般推荐27或者28开头的5位数） 4. 配置环境变量PATH路径# 这里也可以修改~/.bashrc文件（区别见下表） sudo vi /etc/profile # 追加(路径是放置Mongodb安装包的bin路径) export PATH=/home/dusk/mongodb/bin:$PATH Linux中profile、bashrc、bash_profile之间的区别和联系 文件名 作用区间 执行时间 修改后是否需要重启 /etc/profile 该系统下每个用户 用户第一次登陆 是（source /etc/profile） /etc/bashrc 该系统下每个用户 用户新打开shell 否 ~/.bash_profile 当前用户 用户第一次登陆 是（source ~/.bash_profile） ~/.bashrc 当前用户 用户新打开shell 否 ~/.bash_logout 当前用户 退出shell 否 /etc/profile：该文件为系统的每个用户的环境信息文件，对每个用户生效。当用户第一次登陆的时候会执行这个文件加载里面的shell配置，所以修改这个文件之后要重启设置才能生效–&gt;source /etc/profile /etc/bashrc：为每一个执行bash shell的用户执行此文件，当bash shell被打开时，该文件被读取。修改后只需要重新打开一个bash即可生效 ~/.bash_profile：每个用户目录下都有这个文件，用户可以通过修改这个文件来设置自己专用的shell信息，该文件中设置了一些环境变量，执行用户的.bashrc文件。该文件类似于/etc/profile，需要重新启动才会生效，只对当前用户生效。 ~/.bashrc：该文件包含专用于你自己的bash shell信息，每次打开新的shell时被读取，只对当前用户新打开的bash生效。 ~/.bash_logout：当该用户退出bash shell时执行 5. 如果修改的是/etc/profile，则需要重新启动配置文件source /etc/profile 6. 在配置文件路径启动mongodbmongod -f mongodb.conf 关闭MongoDB 使用mongod命令mongod --shutdown --dbpath /数据库储存路径 连接进mongodb数据库关闭# 进入mongoshell mongo --port=28001 # 使用admin数据库（只有在admin下才能执行shutdown方法） use admin # 关闭mongodb服务 db.shutdownServer() 查看mongodb的进程，用kill杀掉进程不推荐这种方式，会有丢失数据的风险 二、搭建MongoDB Replicat Set复制集MongoDB Replica Set是MongoDB官方推荐的主从复制和高可用方案，用于替代原有的Master-Slave主从复制方案。不懂原理的可以点击这里查看复制集原理（推荐了解原理后再搭建） 1.搭建环境（电脑配置）在需要布置为节点的机器上安装好MongoDB环境，参照上面的教程 节点 主机名(IP地址):端口号 Primary Node(主节点) node1:28001 Secondary Node(次节点) node2:28001 Arbiter Node(投票节点) node3:28001 当然，你也可以在一台电脑上搭建复制集，但是端口一定不要冲突 2.确保每个节点数据、日志文件都建立完毕# 数据目录 mkdir -p /mongodb/data/ # 日志目录 mkdir -p /mongodb/log/ # 创建日志文件 touch /mongodb/log/mongodb.log # 配置文件目录 mkdir -p /mongodb/conf 参考上面的mongodb环境搭建 3.修改每个节点的配置文件（重点）# 例： vi /mongodb/conf/mongodb.yaml 在文件后面追加： # 副本 replication: #设置复制集名称，可自定义 replSetName: DBTEST #设置操作日志的大小(important) oplogSizeMB: 10240 #sharding: ## Enterprise-Only Options: #auditLog: #snmp: 复制集名称每个节点一定要一样 4.启动每个节点mongod -f /mongodb/conf/mongodb.conf 5.进入一个节点配置复制集（重点）#任意一个节点上(最好选在主节点node1) mongo --port 28001 在mongo shell中配置副本输入rs.help()可以查看rs的各种方法 # 初始化复制集 rs.initiate() # 显示复制集配置对象 rs.conf() # 将其余成员添加到副本集 # 返回{ \"ok\" : 1 }说明添加成功 rs.add(\"node2:28001\") rs.addArb(\"node3:28001\") 查看副本集状态，可以看到复制集的全部信息都被显示出来 DBTEST:PRIMARY> rs.status() { \"set\" : \"DBTEST\", \"date\" : ISODate(\"2017-06-30T07:10:33.247Z\"), \"myState\" : 1, \"term\" : NumberLong(1), \"heartbeatIntervalMillis\" : NumberLong(2000), \"members\" : [ { \"_id\" : 0, \"name\" : \"node1:28001\", \"health\" : 1, \"state\" : 1, \"stateStr\" : \"PRIMARY\", \"uptime\" : 316, \"optime\" : { \"ts\" : Timestamp(1498806589, 1), \"t\" : NumberLong(1) }, \"optimeDate\" : ISODate(\"2017-06-30T07:09:49Z\"), \"infoMessage\" : \"could not find member to sync from\", \"electionTime\" : Timestamp(1498806520, 2), \"electionDate\" : ISODate(\"2017-06-30T07:08:40Z\"), \"configVersion\" : 4, \"self\" : true }, { \"_id\" : 1, \"name\" : \"node2:28001\", \"health\" : 1, \"state\" : 2, \"stateStr\" : \"SECONDARY\", \"uptime\" : 58, \"optime\" : { \"ts\" : Timestamp(1498806589, 1), \"t\" : NumberLong(1) }, \"optimeDate\" : ISODate(\"2017-06-30T07:09:49Z\"), \"lastHeartbeat\" : ISODate(\"2017-06-30T07:10:31.761Z\"), \"lastHeartbeatRecv\" : ISODate(\"2017-06-30T07:10:32.765Z\"), \"pingMs\" : NumberLong(0), \"syncingTo\" : \"node2:28001\", \"configVersion\" : 4 }, { \"_id\" : 2, \"name\" : \"node3:28001\", \"health\" : 1, \"state\" : 7, \"stateStr\" : \"ARBITER\", \"uptime\" : 43, \"lastHeartbeat\" : ISODate(\"2017-06-30T07:10:31.761Z\"), \"lastHeartbeatRecv\" : ISODate(\"2017-06-30T07:10:29.970Z\"), \"pingMs\" : NumberLong(0), \"configVersion\" : 4 } ], \"ok\" : 1 } 6.删除子节点rs.remove(\"node3:28001\") # 返回{\"ok\" : 1} 7.可能遇到的问题在节点中执行show方法可能出现 DBTEST:SECONDARY> show databases 2017-07-28T11:15:06.856+0800 E QUERY [thread1] Error: listDatabases failed:{ \"ok\" : 0, \"errmsg\" : \"not master and slaveOk=false\", \"code\" : 13435, \"codeName\" : \"NotMasterNoSlaveOk\" } : _getErrorWithCode@src/mongo/shell/utils.js:25:13 Mongo.prototype.getDBs@src/mongo/shell/mongo.js:62:1 shellHelper.show@src/mongo/shell/utils.js:755:19 shellHelper@src/mongo/shell/utils.js:645:15 #解决方法是在报错的节点上执行rs.slaveOk()方法即可 DBTEST:STARTUP2> rs.slaveOk() DBTEST:STARTUP2> show databases admin 0.000GB local 0.000GB mydatabase 0.000GB 8.关闭、重启复制集参考上边的关闭mongodb的方法，依次在每个节点上执行关闭操作注意关闭顺序，在重启节点的过程中，建议不要直接shutdown Primary，这样可能导致已经写入primary但未同步到secondary的数据丢失 1.shutdown Primary （shutdown会等待Secondary oplog追到10s以内）2.Primary退出后，剩余的节点选举出一个新的Primary（复制集只包含1或2节点例外）3.Primary重新启动，因为当前复制集已经有了新的Primary，这个Primary将以Secondary的角色运行。4.从新的Primary同步的过程中，发现自己有无效的oplog，会先进行rollback。（rollback的数据只要不超过300M是可以找回的） 上面这种操作可能会导致数据丢失 1.逐个重启复制集里所有的Secondary节点2.对Primary发送stepDown命令，等待primary降级为Secondary3.重启降级后的Primary document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"数据库","slug":"数据库","permalink":"http://blog.hming.org/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://blog.hming.org/tags/Linux/"},{"name":"Mongodb","slug":"Mongodb","permalink":"http://blog.hming.org/tags/Mongodb/"}]},{"title":"MongoDB笔记","slug":"MongoDB笔记","date":"2017-07-26T11:03:26.000Z","updated":"2017-07-29T11:03:26.000Z","comments":true,"path":"2017/07/26/mongodb-bi-ji/","link":"","permalink":"http://blog.hming.org/2017/07/26/mongodb-bi-ji/","excerpt":"","text":"一、Mongo数据库为NoSQL数据库 关系型数据库 NoSQL数据库 数据库 数据库类似于MySQL 表 集合 行 文档 列 成员 主键 Object ID（自动维护） 与Node.js捆绑。 启动MongoDB服务 默认端口启动mongod --dbpath E:\\MongoDB\\db 设置端口启动mongod --dbpath E:\\MongoDB\\db --port=27001 连接MongoDB数据库mongo或者mongo --port=27001 切换到admin数据库 use admin 关闭数据库服务 db.shutdownServer() (必须在admin下才能执行成功) 重启服务 mongod -f E:\\MongoDB\\mongodb.conf 二、基本语法查看所有数据库db.showDatabases; 使用某个数据库use admin 这时并不会创建数据库，只有在数据库里面保存集合数据后，才真正创建数据库 创建一个集合db.createCollection(\"emp\"); 插入一条数据db.emp.insert({\"name\": 10, \"ange\": 10}); 一般在执行这一步的时候会直接创建集合emp，所以上面那句语句一般不会用，都是直接使用这句来插入数据的同时创建集合 查看所有集合show collections; 查看emp表的数据语法：db.集合名称.find({若干条件}，[ { 设置显示的字段 } ])db.emp.find(); 增加不规则的数据var deptData = { \"name\" : \"123\", \"sex\" : \"man\" } db.emp.insert(deptData); 关于ID问题在MongoDB集合中的每一行记录都会自动的生成一个“ *” _id” :ObjectId(“55949a13eecd74894d19d8dc”)*”数据，这个数据组成是：“时间戳 + 机器码 + PID + 计数器”，这个ID的信息是MongonDB数据自己为用户生成的。 单独的一个文档信息查看db.dept.findOne(); 删除一个数据db.dept.remove( { \"_id\" :ObjectId(\"55949a13eecd74894d19d8dc\")} ); 更新数据var deptData = { \"name\" : \"123\", \"sex\" : \"man\" } db.dept.updata({ \"_id\" :ObjectId(\"55949a13eecd74894d19d8dc\")},deptData); 删除集合语法：db.集合名称.drop()db.dept.drop(); 删除当前数据库db.dropDatabase(); 三、数据操作（重点）增加数据增加一个简单数据db.dept.insert({\"url\":\"hm-dusk.github.io\"});保存一个数组 db.dept.insert([ {\"url\":\"hm-dusk.github.io\"}, {\"url\":\"https://hm-dusk.github.io\"} ]);可以使用JavaScript的循环添加 for(var x = 0; x &lt; 1000; x ++){ db.dept.insert({\"url\":\"hm-dusk.github.io\"}); }数据查询任何的数据库之中，数据的查询操作都是最为麻烦的，而在MongoDB数据库里面，对于查询的支持非常到位，包含有关系运算、逻辑运算、数组运算、正则运算等等。 首先对于数据的查询操作核心的语法：“db.集合名称.find({查询条件} [,{设置显示的字段}])”。 db.dept.find();条件查询 db.dept.find( { \"url\":\"hm-dusk.github.io\" } );对于设置的显示字段严格来讲就称为数据的投影操作，如果不需要显示的字段设置“0”，而需要显示的字段设置“1”。 //不想显示_id db.dept.find( {\"url\":\"hm-dusk.github.io\"},{\"_id\":0} ); db.dept.find( {\"url\":\"hm-dusk.github.io\"},{\"_id\":0,\"url\":1} );大部分的情况下，这种投影操作的意义不大。同时对于数据的查询也可以使用“pretty()”函数进行漂亮显示。 db.dept.find( {\"url\":\"hm-dusk.github.io\"},{\"_id\":0} ).pretty();范例：查询单个数据 db.dept.findOne( {\"url\":\"hm-dusk.github.io\"},{\"_id\":0} );关系运算在MongoDB里面支持的关系查询操作：大于（$gt）、小于（$lt）、大于等于（$gte）、小于等于（$lte）、不等于（$ne）、等于（key:value、$eq）。但是要想让这些操作可以正常使用，那么需要准备出一个数据集合。 范例：查询姓名是张三的信息 db.students.find({\"name\":\"张三\"}).pretty();范例：查询性别是男的信息 db.students.find({\"sex\":\"男\"}).pretty();范例：查询年龄大于19岁的学生 db.students.find({\"age\": {\"$gt\":19} }).pretty();范例：查询成绩大于等于60分的学生 db.students.find({\"score\": {\"$gte\":60} }).pretty();范例：查询姓名不是王五的信息 db.students.find({\"name\": {\"$ne\":\"王五\"} }).pretty(); 此时与之前最大的区别就在于，在一个JSON结构里面需要定义其它的JSON结构，并且这种风格在日后通过程序进行操作的时候依然如此。 逻辑运算逻辑运算主要就是三种类型：与（$and）、或（$or）、非（$not、$nor）。 范例：查询年龄在19 ~ 20岁的学生信息 db.students.find({ \"age\":{\"$gte\":19,\"$lte\":20} }).pretty();在进行逻辑运算的时候“and”的连接是最容易的，因为只需要利用“,”分割若干个条件就可以了。 范例：查询年龄不是19岁的学生 db.students.find({ \"age\":{\"$ne\":19} }).pretty();范例：查询年龄大于19岁，或者成绩大于90分的学生信息 db.students.find({ \"$or\":[ {\"age\":{\"$gt\":19}}, {\"score\":{\"$gt\":90}} ] }).pretty(); 范例：也可以进行或的求反操作(针对于或的操作可以实现一个求反的功能。) db.students.find({ \"$nor\":[ {\"age\":{\"$gt\":19}}, {\"score\":{\"$gt\":90}} ] }).pretty();求模模的运算使用“$mod”来完成，语法“{$mod : [数字,余数]}”。 范例：求模 db.students.find({\"age\": {\"$mod\":[20,1]} }).pretty();利用求模计算可以编写一些数学的计算公式。 范围查询只要是数据库，必须存在有“$in”（在范围之中）、“$nin”（不在范围之中）。 范例：查询姓名是“张三”、“李四”、“王五”的信息 db.students.find({\"name\": {\"$in\":[\"张三\",\"李四\",\"王五\"]} }).pretty();范例：不在范围 db.students.find({\"name\": {\"$nin\":[\"张三\",\"李四\",\"王五\"]} }).pretty();在实际的工作之中，范围的操作很重要。 数组查询首先在mongoDB里面是支持数组保存的，一旦支持了数组保存，就需要针对于数组的数据进行匹配。 范例：保存一部分数组内容此时的数据包含有数组内容，而后需要针对于数组数据进行判断，可以使用几个运算符：$all、$size、$slice、$elemMatch。 范例：查询同时参加语文和数学课程的学生现在两个数组内容都需要保存，所以使用“{\"$all\",[内容1,内容2,..]}” db.students.find({\"course\": {\"$all\": [\"语文\",\"数学\"]} }).pretty();现在所有显示的学生信息里面包含语文和数学的内容，而如果差一个内容的不会显示。 虽然“$all”计算可以用于数组上，但是也可以用于一个数据的匹配上。 范例：查询学生地址是“海淀区”的信息 db.students.find({\"address\": {\"$all\":[\"海淀区\"]} }).pretty(); 既然在集合里面现在保存的是数组信息，那么数组就可以利用索引操作，使用“key.index”的方式来定义索引。 范例：查询数组中第二个内容（index= 1，索引下标从0开始）为数学的信息 db.students.find({\"course.1\":\"数学\"}).pretty();范例：要求查询出只参加两门课程的学生使用“$size”来进行数量的控制。 db.students.find({\"course\": {\"$size\":2} }).pretty();发现在进行数据查询的时候只要是内容复合条件，数组的内容就全部显示出来了，但是现在希望可以控制数组的返回的数量，那么可以使用“$slice”进行控制。 范例：返回年龄为19岁所有学生的信息，但是要求只显示两门参加课程 db.students.find({\"age\":19},{\"course\":{\"$slice\":2}}).pretty();现在只取得了前两门的信息，那么也可以设置负数表示取出后两门的信息。 db.students.find({\"age\":19},{\"course\":{\"$slice\":-2}}).pretty();或者只是取出中间部分的信息。 db.students.find({\"age\":19},{\"course\":{\"$slice\":[1,2]}}).pretty(); 在此时设置的两个数据里面第一个数据表示跳过的数据量，而第二个数据表示返回的数量。 嵌套集合运算在MongoDB数据里面每一个集合数据可以继续保存其它的集合数据，例如：有些学生需要保存家长信息。 范例：增加数据此时给出的内容是嵌套的集合，而这种集合的数据的判断只能够通过“$elemMatch”完成。 范例：查询出年龄大于等于19岁且父母有人是局长的信息 db.students.find( {\"$and\":[ {\"age\":{\"$gte\":19}}, {\"parents\":{\"$elemMatch\":{\"job\":\"局长\"}}} ]}).pretty(); 由于这种查询的时候条件比较麻烦，所以如果可以，尽量别搞这么复杂的数据结构组成。 判断某个字段是否存在使用“$exists”可以判断某个字段是否存在，如果设置为true表示存在，如果设置为false就表示不存在。 范例：查询具有parents成员的数据 db.students.find({\"parents\":{\"$exists\":true}}).pretty();范例：查询不具有course成员的数据 db.students.find({\"course\":{\"$exists\":false}}).pretty(); 可以利用此类查询来进行一些不需要的数据的过滤。 条件过滤实际上习惯于传统关系型数据库开发的我们对于数据的筛选，可能首先想到的一定是where子句，所以在MongoDB里面也提供有“$where”。 范例：使用where进行数据查询 db.students.find({\"$where\":\"this.age&gt;20\"}).pretty(); db.students.find(\"this.age&gt;20\").pretty();对于“$where”是可以简化的，但是这类的操作是属于进行每一行的信息判断，实际上对于数据量较大的情况并不方便使用。实际上以上的代码严格来讲是属于编写一个操作的函数。 db.students.find(function(){ return this.age &gt; 20; }).pretty(); db.students.find({\"$where\":function(){ return this.age &gt; 20; }}).pretty();以上只是查询了一个判断，如果要想实现多个条件的判断，那么就需要使用and连接。 db.students.find({\"$and\":[ {\"$where\":\"this.age&gt;19\"}, {\"$where\":\"this.age&lt;21\"} ] }); 虽然这种形式的操作可以实现数据查询，但是最大的缺点是将在MongoDB里面保存的BSON数据变为了JavaScript的语法结构，这样的方式不方便使用数据库索引机制。 正则运算如果要想实现模糊查询，那么必须使用正则表达式，而且正则表达式使用的是语言Perl兼容的正则表达式的形式。如果要想实现正则使用，则按照如下的定义格式： 基础语法：{key : 正则标记} 完整语法：{key : {\"$regex\" : 正则标记 , \"$options\" : 选项}} |- 对于options主要是设置正则的信息查询的标记：|- “i”：忽略字母大小写；|- “m”：多行查找；|- “x”：空白字符串除了被转义的或在字符类中意外的完全被忽略；|- “s”：匹配所有的字符（圆点、“.”），包括换行内容。|- 需要注意的是，如果是直接使用（javascript）那么只能够使用i和m，而“x”和“s”必须使用“$regex”。 范例：查询以“谷”开头的姓名 db.students.find({\"name\": /谷/ }).pretty();范例：查询姓名有字母A db.students.find({\"name\": /a/i }).pretty(); db.students.find({\"name\": {\"$regex\": /a/i }}).pretty();如果要执行模糊查询的操作，严格来讲只需要编写一个关键字就够了。正则操作之中除了可以查询出单个字段的内容之外，也可以进行数组数据的查询。 范例：查询数组数据 db.students.find({\"course\": /语?/ }).pretty(); db.students.find({\"course\": /语/ }).pretty(); MongoDB中的正则符号和之前Java正则是有一些小小差别，不建议使用以前的一些标记，正则就将其应用在模糊数据查询上。 数据排序在MongoDB里面数据的排序操作使用“sort()”函数，在进行排序的时候可以有两个顺序：升序（1）、降序（-1）。 范例：数据排序 db.students.find().sort({\"score\": -1}).pretty();但是在进行排序的过程里面有一种方式称为自然排序，按照数据保存的先后顺序排序，使用“$natural”表示。 范例：自然排序 db.students.find().sort({\"$natural\": -1}).pretty(); 在MongoDB数据库里面排序的操作相比较传统关系型数据库的设置要简单。 数据分页显示在MongoDB里面的数据分页显示也是符合于大数据要求的操作函数： skip(n)：表示跨过多少数据行； limit(n)：取出的数据行的个数限制。 范例：分页显示（第一页，skip(0)、limit(5)） db.students.find().skip(0).limit(5).sort({\"age\":-1}).pretty();范例：分页显示（第二页，skip(5),limit(5）) db.students.find().skip(5).limit(5).sort({\"age\":-1}).pretty(); 这两个分页的控制操作，就是在以后只要是存在有大数据的信息情况下都会使用它。 四、数据更新操作对于MongoDB而言，数据的更新基本上是一件很麻烦的事情，如果在实际的工作之中，真的具有此类的操作支持，那么最好的做法，在MongoDB里面对于数据的更新操作提供了两类函数：save()、update()。 函数的基本使用如果要修改数据最直接的使用函数就是update()函数，但是这个函数的语法要求很麻烦： 语法：db.集合.update(更新条件 , 新的对象数据（更新操作符） , upsert , multi)； |- upsert：如果要更新的数据不存在，则增加一条新的内容（true为增加、false为不增加）；|-multi：表示是否只更新满足条件的第一行记录，如果设置为false，只更新第一条，如果是true全更新。 范例：更新存在的数据——将年龄是19岁的人的成绩都更新为100分（此时会返回多条数据） 只更新第一条数据：db.students.update({\"age\":19}, {\"$set\": {\"score\":100}}, false,false); 所有满足条件的数据都更新db.students.update({\"age\":19}, {\"$set\":{\"score\":100}}, false,true); 范例：更新不存在的数据 db.students.update({\"age\":30}, {\"$set\":{\"name\":\"不存在\"}}, true,false); //由于没有年龄是30岁的学生信息，所以此时相当于进行了数据的创建。那么除了update()函数之外，还提供有一个save()函数，这个函数的功能与更新不存在的内容相似。 范例：使用save()操作 db.students.save({\"_id\": ObjectID(\"55949a13eecd74894d19d8dc\"), \"age\":50}); //由于此时对应的id数据存在了，所以就变为了更新操作。但是如果要保存的数据不存在（不能保存有“_id”），那么就变为了增加操作。修改器对MongoDB数据库而言，数据的修改会牵扯到内容的变更、结构的变更（包含有数组），所以在进行MongoDB设计的时候就提供有一系列的修改器的应用，那么像之前使用的“$set”就是一个修改器。 $inc：主要针对于一个数字字段，增加某个数字字段的数据内容；语法：{\"$inc\" : {\"成员\" : 内容}} 范例：将所有年龄为19岁的学生成绩一律减少30分,年龄加1 db.students.update({\"age\":19}, {\"$inc\": {\"score\":-30,\"age\":1} });$set：进行内容的重新设置；语法：{\"$set\" : {\"成员\" : \"新内容\"}} 范例：将年龄是20岁的人的成绩修改为89 db.students.update({\"age\":20}, {\"$set\": {\"score\":89} });$unset：删除某个成员的内容；语法：{\"$unset\" : {\"成员\" : 1}} 范例：删除“张三”的年龄与成绩信息 db.students.update({\"name\":\"张三\"}, {\"$unset\": {\"age\":1,\"score\":1} }); //执行之后指定的成员内容就消失了。$push：相当于将内容追加到指定的成员之中（基本上是数组）；语法：${\"$push\" : {成员 : value}} 范例：向“李四”添加课程信息（此时张三信息下没有course信息） db.students.update({\"name\":\"李四\"}, {\"$push\": {\"course\":\"语文\"} });范例：向“谷大神 - E”里面的课程追加一个“美术” db.students.update({\"name\":\"谷大神 - E\"}, {\"$push\": {\"course\":\"美术\"} }); 就是进行数组数据的添加操作使用的，如果没有数组则进行一个新的数组的创建，如果有则进行内容的追加。 $pushAll：与“$push”是类似的，可以一次追加多个内容到数组里面；语法：${\"$pushAll\" : {成员 : 数组内容}} 范例：向“王五”的信息里面添加多个课程内容 db.students.update({\"name\":\"王五\"}, {\"$pushAll\": {\"cource\":[\"美术\",\"音乐\",\"田径\"]} });$addToSet：向数组里面增加一个新的内容，只有这个内容不存在的时候才会增加；语法：{\"$addToSet\" : {成员 : 内容}} 范例：向王五的信息增加新的内容 db.students.update({\"name\": \"王五\"}, {\"$addToSet\": {\"course\":\"舞蹈\"} }); //此时会判断要增加的内容在数组里面是否已经存在了，如果不存在则向数组之中追加内容，如果存在了则不做任何的修改操作。$pop：删除数组内的数据；语法：{\"$pop\" : {成员 : 内容}}内容如果设置为-1表示删除第一个，如果是1表示删除最后一个； 范例：删除王五的第一个课程 db.students.update({\"name\":\"王五\"}, {\"$pop\": {\"course\":1}});$pull：从数组内删除一个指定内容的数据语法：{\"$pull\" : {成员 : 数据}}进行数据比对的，如果是此数据则删除； 范例：删除王五学生的音乐课程信息 db.students.update({\"name\":\"王五\"}, {\"$pull\":\"音乐\"});$pullAll：一次性删除多个内容；语法：{\"$pull\" : {成员 : [数据, 数据,...]}} 范例：删除“谷大神 - A”中的三门课程 db.students.update({\"name\":\"谷大神 - A\"}, {\"$pullAll\":{\"course\":[\"语文\",\"数学\",\"英语\"]}});$rename：为成员名称重命名；语法：{\"$rename\" : {旧的成员名称 : 新的成员名称}} 范例：将“张三”name成员名称修改为“姓名” db.students.update({\"name\":\"张三\"}, {\"$rename\":{\"name\":\"姓名\"}});在整个MongoDB数据库里面，提供的修改器的支持很到位。 删除数据 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"数据库","slug":"数据库","permalink":"http://blog.hming.org/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"Mongodb","slug":"Mongodb","permalink":"http://blog.hming.org/tags/Mongodb/"}]},{"title":"Vim程式编辑器","slug":"Vim程式编辑器","date":"2017-07-26T01:47:27.000Z","updated":"2019-01-02T03:44:58.000Z","comments":true,"path":"2017/07/26/vim-cheng-shi-bian-ji-qi/","link":"","permalink":"http://blog.hming.org/2017/07/26/vim-cheng-shi-bian-ji-qi/","excerpt":"","text":"vim编辑器常用指令一般指令模式（command mode）：移动游标方法 指令 代表含义 [Ctrl]+[f] 向下移动一页，相当于[Page Down] [Ctrl]+[b] 向上移动一页，相当于[Page Up] 0或者功能键[Home] 移动到行最左侧 $或者功能键[End] 移动到行最右侧 G 移动到文档最后一列 nG n代表数字，移动到第n行(可配合:set nu) gg 移动到第一行，相当于1G n[Enter] n为数字。游标向下移动n行 保存离开 指 令 代表含义 :w 将编辑的资料写入磁盘中 :w! 当档案属性为只读时，强制写入该档案。具体能不能写入，跟用户对该档案的权限有关 :q 离开vi :q! 强制离开，不存储档案 :wq 储存后离开 删除、复制和粘贴 指令 代表含义 x,X x为向后删除一个字符（相当于[del]），X为向前删除一个字符（相当于[backspace]） dd 删除游标所在的一整行（可以理解为剪切，p对dd同样有效） ndd n表示数字，删除游标所在的向下n行 yy 复制游标所在行 nyy n表示数字，复制游标所在的向下n行 p,P p为粘贴插入到游标下一行，原始的文档向后推，P为上一行 u 复原上一个动作（撤销） Ctrl+r 重复上一个动作 . 小数点，重复上一个动作 搜索与替换 指令 代表含义 /word 从光标处开始向下查找名为word的字符串 ?word 从光标处开始向上查找名为word的字符串 n 重复上一个搜索动作 N 与n功能相反（反向搜索） :n1,n2s/word1/word2/g n1与n2为数字。在第n1与n2列之间寻找word1这个字串，并将该字串取代为word2 ！举例来说，在100到200列之间搜寻vim并取代为VIM则:100,200s/vim/VIM/g :1,$s/word1/word2/g 从第一列到最后一列寻找word1字串，并将该字串取代为word2 :1,$s/word1/word2/gc 从第一列到最后一列寻找word1字串，并将该字串取代为word2 ，且在取代前显示提示字元给使用者确认(confirm)是否需要取代 区块选择操作 指令 代表含义 v 字元选择，会将游标经过的地方反白选择！ V 列选择，会将游标经过的列反白选择！ Ctrl+v 区块选择，可以用长方形的方式选择资料 y 将反白的地方复制起来 d 将反白的地方删除掉 p 将刚刚复制的区块，在游标所在处贴上！ 一般指令模式切换到编辑模式： 指令 代表含义 i或I 进入插入模式(Insert mode)：i为『从目前游标所在处插入』， I为『在目前所在列的第一个非空白字元处开始插入』。 a或A 进入插入模式(Insert mode)：a为『从目前游标所在的下一个字元处开始插入』， A为『从游标所在列的最后一个字元处开始插入』。 o或O 进入插入模式(Insert mode)：这是英文字母o的大小写。o为『在目前游标所在的下一列处插入新的一列』； O为在目前游标所在处的上一列插入新的一列！ r或R 进入取代模式(Replace mode)：r只会取代游标所在的那一个字元一次；R会一直取代游标所在的文字，直到按下ESC为止； vim编辑器页面设置 指令 代表含义 :set nu 设置vim编辑器显示行号 :set nonu 取消行号 设置vim编辑器打开默认显示行号：新建或修改$HOME/.vimrc文件，在文件中添加 set number 参考文档：鸟哥的Linux私房菜之vim程式编辑器 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Linux","slug":"Linux","permalink":"http://blog.hming.org/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://blog.hming.org/tags/Linux/"},{"name":"编辑器","slug":"编辑器","permalink":"http://blog.hming.org/tags/%E7%BC%96%E8%BE%91%E5%99%A8/"}]},{"title":"Java去掉字符串特殊字符的方法","slug":"Java去掉字符串特殊字符的方法","date":"2017-07-25T02:55:07.000Z","updated":"2017-07-25T02:55:07.000Z","comments":true,"path":"2017/07/25/java-qu-diao-zi-fu-chuan-te-shu-zi-fu-de-fang-fa/","link":"","permalink":"http://blog.hming.org/2017/07/25/java-qu-diao-zi-fu-chuan-te-shu-zi-fu-de-fang-fa/","excerpt":"","text":"语法：str = str.replaceAll(\"[\\pP]\", \"\");\\pP 中小写 p 是property的意思，表示 Unicode 属性，用于 Unicode 正表达式的前缀。大写 P 表示 Unicode 字符集七个字符属性之一：标点字符。 符号 表示的意思 P 标点字符 L 字母 M 标记符号（一般不会单独出现） Z 分隔符（比如空格、换行等） S 符号（比如数学符号、货币符号等） N 数字（比如阿拉伯数字、罗马数字等） C 其他字符 例： String result = \",.!，，D_NAME。！；‘’”“《》**dfs #$%^&amp;()-+1431221厉害123漢字どうかのjavaを決繁体\"; result = result.replaceAll(\"[\\\\pP\\\\pZ\\\\pS\\\\pC\\\\pM]\", \"\"); //去掉标点符号、空格，换行、等所有特殊字符 /* 输出： DNAMEdfs1431221厉害123漢字どうかのjavaを決繁体 */ 以后字符串的对应字符处理就可以用这个简单可靠的方法了 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Java","slug":"Java","permalink":"http://blog.hming.org/categories/Java/"}],"tags":[{"name":"字符串","slug":"字符串","permalink":"http://blog.hming.org/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"}]},{"title":"那些年经历过的异常信息","slug":"那些年经历的异常信息","date":"2017-07-24T01:40:54.000Z","updated":"2017-07-29T01:40:54.000Z","comments":true,"path":"2017/07/24/na-xie-nian-jing-li-de-yi-chang-xin-xi/","link":"","permalink":"http://blog.hming.org/2017/07/24/na-xie-nian-jing-li-de-yi-chang-xin-xi/","excerpt":"","text":"java.lang.UnsupportedOperationException不支持功能异常，常常发生在Arrays.asList()后再对List进行add、remove这些操作时 File file = new File(\"e:/123/\"); List&lt;File> files = Arrays.asList(file.listFiles()); ListIterator&lt;File> lit = files.listIterator(); while(lit.hasNext()){//遍历该分类下的文件 File file = lit.next(); if(file.getName().contains(\"123\")){//包含123 lit.remove(); //将该文件从list中移除 } } Arrays.asList() 返回java.util.Arrays$ArrayList， 而不是ArrayList。Arrays$ArrayList和ArrayList都是继承AbstractList。remove，add等 方法在AbstractList中是默认抛出 UnsupportedOperationException异常而且不作任何操作。ArrayList 重写了这些方法来对list进行操作，但是Arrays$ArrayList没有重写 remove(int)，add(int)等方法，所以会抛出UnsupportedOperationException异常。 解决方法:在遍历List（由数组转换而来）需要add和remove时，转换成List时不要用Arrays.asList()方法 第一种：Collections的addAll静态方法 File file = new File(\"e:/123/\"); List&lt;File> files = Lists.newArrayList(); Collections.addAll(files,file.listFiles()); ListIterator&lt;File> lit = files.listIterator(); while(lit.hasNext()){//遍历该分类下的文件 ... } 第二种：遍历数组，一个元素一个元素的add进List File file = new File(\"e:/123/\"); List&lt;File> files = Lists.newArrayList(); for(File file : file.listFiles()){ files.add(file); } document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Java","slug":"Java","permalink":"http://blog.hming.org/categories/Java/"}],"tags":[{"name":"异常","slug":"异常","permalink":"http://blog.hming.org/tags/%E5%BC%82%E5%B8%B8/"}]},{"title":"浮点型计算中丢失精度问题","slug":"计算中丢失精度问题","date":"2017-07-23T14:51:58.000Z","updated":"2017-07-23T14:51:58.000Z","comments":true,"path":"2017/07/23/ji-suan-zhong-diu-shi-jing-du-wen-ti/","link":"","permalink":"http://blog.hming.org/2017/07/23/ji-suan-zhong-diu-shi-jing-du-wen-ti/","excerpt":"","text":"在进行浮点数计算时，用BigDecimalpublic class test{ @Test public void fun(){ double a = 0.3; double b = 0.6; double c = a+b; System.out.println(c); //输出0.8999999999999999 } } 上面语句按道理说输出应该是0.9，但是实际输出为0.8999999999999999。在计算机内部，首先将double转换成二进制，再进行二进制的计算，最后把计算好的二进制结果转换成double。在两次转换的过程中由于计算机表示的位数有限，而0.3和0.6表示成二进制都是无限的（尴尬），所以在转换成二进制的时候就已经改变了0.3和0.6的值，计算出来的结果当然是错的。实际上，0.0到0.9的10个数中，只有0.0和0.5能精确表示。 同理，下面的代码输出结果也丢失精度。 public class test{ public static void main(String[] args){ double a = 0.2 + 0.4; double b = 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1; System.out.println(a);//输出0.6000000000000001 System.out.println(b);//输出0.8999999999999999 } } 那么在java中如何避免这个问题呢？当然最好的方式是不用这种计算方式，但是如果必须用到的话，就只能用BigDecimal这个类。 参考资料：代码之谜（四）- 浮点数（从惊讶到思考）代码之谜（五）- 浮点数（谁偷了你的精度？） document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Java","slug":"Java","permalink":"http://blog.hming.org/categories/Java/"}],"tags":[{"name":"精度问题","slug":"精度问题","permalink":"http://blog.hming.org/tags/%E7%B2%BE%E5%BA%A6%E9%97%AE%E9%A2%98/"}]},{"title":"Java遍历Map的几种方式","slug":"Java遍历Map的几种方式","date":"2017-07-19T11:26:48.000Z","updated":"2017-07-19T11:26:48.000Z","comments":true,"path":"2017/07/19/java-bian-li-map-de-ji-chong-fang-shi/","link":"","permalink":"http://blog.hming.org/2017/07/19/java-bian-li-map-de-ji-chong-fang-shi/","excerpt":"","text":"第一种 在for-each循环中使用entries来遍历 最常见的且大多数情况下使用的方式，在键和值都需要的时候使用 但是，如果要在遍历中删除某个键值对，则不能使用该方法 Map&lt;Integer, Integer> map = Maps.newHashMap(); for(Map.Entry&lt;Integer,Integer> entry:map.entrySet()){ System.out.println(\"键：\" + entry.getKey() + \"，值：\" + entry.getValue()); } 注意：for-each循环在Java 5中被引入所以该方法只能应用于java 5或更高的版本中。如果你遍历的是一个空的map对象，for-each循环将抛出NullPointerException，因此在遍历前你总是应该检查空引用。 第二种 在for-each循环中遍历keys或values 如果只需要map中的键或者值，你可以通过keySet或values来实现遍历，而不是用entrySet Map&lt;Integer, Integer> map = Maps.newHashMap(); //遍历map中的键 for (Integer key : map.keySet()) { System.out.println(\"Key = \" + key); } //遍历map中的值 for (Integer value : map.values()) { System.out.println(\"Value = \" + value); } 该方法比entrySet遍历在性能上稍好（快了10%），而且代码更加干净。 第三种 使用Iterator遍历Map&lt;Integer, Integer> map = Maps.newHashMap(); Iterator&lt;Map.Entry&lt;Integer, Integer>> entries = map.entrySet().iterator(); while (entries.hasNext()) { Map.Entry&lt;Integer, Integer> entry = entries.next(); System.out.println(\"Key = \" + entry.getKey() + \", Value = \" + entry.getValue()); //在这里面可以删除键值对 if(entries.next().getValue()>0){ entries.remove(); } } 该种方式看起来冗余却有其优点所在。首先，在老版本java中这是惟一遍历map的方式。另一个好处是，你可以在遍历时调用iterator.remove()来删除entries，另两个方法则不能。根据javadoc的说明，如果在for-each遍历中尝试使用此方法，结果是不可预测的。 从性能方面看，该方法类同于for-each遍历（即方法二）的性能。 第四种 通过键找值遍历（效率低）Map&lt;Integer, Integer> map = new HashMap&lt;Integer, Integer>(); for (Integer key : map.keySet()) { Integer value = map.get(key); System.out.println(\"Key = \" + key + \", Value = \" + value); } 作为方法一的替代，这个代码看上去更加干净；但实际上它相当慢且无效率。因为从键取值是耗时的操作（与方法一相比，在不同的Map实现中该方法慢了20%~200%）。如果你安装了FindBugs，它会做出检查并警告你关于哪些是低效率的遍历。所以尽量避免使用。 总结如果仅需要键(keys)或值(values)使用方法二。如果你使用的语言版本低于java 5，或是打算在遍历时删除entries，必须使用方法三。否则使用方法一(键值都要)。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Java","slug":"Java","permalink":"http://blog.hming.org/categories/Java/"}],"tags":[{"name":"集合","slug":"集合","permalink":"http://blog.hming.org/tags/%E9%9B%86%E5%90%88/"},{"name":"遍历","slug":"遍历","permalink":"http://blog.hming.org/tags/%E9%81%8D%E5%8E%86/"}]},{"title":"MySQL笔记","slug":"MySQL笔记","date":"2017-07-18T12:42:01.000Z","updated":"2017-07-29T11:03:26.000Z","comments":true,"path":"2017/07/18/mysql-bi-ji/","link":"","permalink":"http://blog.hming.org/2017/07/18/mysql-bi-ji/","excerpt":"","text":"一、常见数据库Oracle：甲骨文（占有率最高）DB2：IBMSQL Server：微软Sybase：赛尔斯MySQL：甲骨文 二、RDBMS（关系型数据库管理系统）表结构： 三、SQL（结构化查询语句）SQL语句分类： DDL：数据库或表的结构操作 （重点） DML：对表的记录进行更新（增、删、改）（重点） DQL：对表的记录的查询（重点、难点） DCL：对用户的创建，及授权 四、DDL（数据库或表的结构操作）操作库： 查看所有数据库：SHOW DATABASES 切换（选择要操作的）数据库：USE 数据库名 创建数据库：CREATE DATABASE [IF NOT EXISTS] 数据库名 删除数据库：DROP DATABASE [IF EXISTS] 数据库名 修改数据库编码：ALTER DATABASE 数据库名 CHARACTER SET utf8 操作表： 创建表： CREATE TABLE [IF NOT EXISTS] 表名（ 列名 列类型， 列名 列类型， 。。。 ）； 查看当前数据库中所有表：SHOW TABLES 查询某一张表结构：DESC 表名 删除表：DROP TABLE 表名 修改表：前缀：ALTER TABLE 表名称 添加列：add（ 列名 列类型， 列名 列类型， 。。。 ）； 修改列类型：modify 列名 列新的类型； 修改列名：change 原列名 新列名 列类型； 删除列：drop 列名； 修改表名称：rename to 新表名； 五、数据类型（列类型）在数据库中所有的字符串类型，必须使用单引，不能使用双引！日期类型也要使用单引！ int：整型double：浮点型，double（5，2）：表示最多5位，必须有两位小数decimal：浮点型char：固定长度字符串类型：char（255）最大255，数据长度不足指定长度，会补足到指定长度varchar：可变长度字符串类型text（clob）：字符串类型（mysql特有，sql server里面也有）blod：字节类型，二进制date：日期类型，格式为：yyyy-MM-ddtime：时间类型，格式为：hh：mm：sstimestamp：时间戳类型 六、DML（对表的记录更新（增、删、改））插入数据INSERT INTO 表名（列名1，列名2，。。。）VALUES（列值1，列值2，。。。）； 在表名后给出要插入的列名，其他没有指定的列等同与插入null值。所以插入记录总是插入一行，不可能是半行。在VALUES后给出列值，值的顺序和个数必须与前面指定的列对应如果表中有自增的主键，那么可以用这种方法不指定主键列，也可以用null和0代替，MySQL会自己处理 INTERT INTO 表名 VALUES(列值1, 列值2) 没有给出要插入的列，那么表示插入所有列。值的个数必须是该表列的个数。值的顺序，必须与表创建时给出的列的顺序相同。 修改数据UPDATE 表名 SET 列名1=列值1, 列名2=列值2, ... [WHERE 条件] 条件(条件可选的)： 条件必须是一个boolean类型的值或表达式：UPDATE t_person SET gender=’男’, age=age+1 WHERE sid=’1’; 运算符：=、!=、&lt;&gt;、&gt;、&lt;、&gt;=、&lt;=、BETWEEN…AND、IN(…)、IS NULL、NOT、OR、AND WHERE age >= 18 AND age &lt;= 80 等价于WHERE age BETWEEN 18 AND 80 WHERE name='zhangSan' OR name='liSi' 等价于WHERE name IN ('zhangSan', 'liSi') WHERE age IS NULL, 不能使用等号 WHERE age IS NOT NULL 删除数据DELETE FROM 表名 [WHERE 条件]; TRUNCATE TABLE 表名：TRUNCATE是DDL语句，它是先删除drop该表，再create该表。而且无法回滚！！！ 七、DCL（对用户的创建，及授权） 一个项目创建一个用户！一个项目对应的数据库只有一个！ 这个用户只能对这个数据库有权限，其他数据库你就操作不了了！ 创建用户CREATE USER 用户名@IP地址 IDENTIFIED BY '密码'; > 用户只能在指定的IP地址上登录 CREATE USER 用户名@'%' IDENTIFIED BY '密码'; > 用户可以在任意IP地址上登录 给用户授权GRANT 权限1, … , 权限n ON 数据库.* TO 用户名@IP地址 > 权限、用户、数据库 > 给用户分派在指定的数据库上的指定的权限 > > 例如；GRANT,CREATE,ALTER,DROP,INSERT,UPDATE,DELETE,SELECT ON mydb1.* TO user1@localhost; > 给user1用户分派在mydb1数据库上的create、alter、drop、insert、update、delete、select权限 * GRANT ALL ON 数据库.* TO 用户名@IP地址; > 给用户分派指定数据库上的所有权限 撤销授权 * REVOKE 权限1, … , 权限n ON 数据库.* FROM 用户名@IP地址; > 撤消指定用户在指定数据库上的指定权限 > > 例如；REVOKE CREATE,ALTER,DROP ON mydb1.* FROM user1@localhost; > 撤消user1用户在mydb1数据库上的create、alter、drop权限 查看权限SHOW GRANTS FOR 用户名@IP地址 > 查看指定用户的权限 删除用户DROP USER 用户名@IP地址 八、DQL数据库查询语言一、 基本查询1. 字段(列)控制1) 查询所有列 SELECT * FROM 表名; SELECT * FROM emp; –&gt;其中“ * ”表示查询所有列 2) 查询指定列 SELECT 列1 [, 列2, ... 列N] FROM 表名; SELECT empno, ename, sal, comm FROM 表名; 3) 完全重复的记录只一次 当查询结果中的多行记录一模一样时，只显示一行。一般查询所有列时很少会有这种情况，但只查询一列（或几列）时，这种可能就大了！ SELECT DISTINCT * | 列1 [, 列2, ... 列N] FROM 表名; SELECT DISTINCT sal FROM emp; –&gt;保查询员工表的工资，如果存在相同的工资只显示一次！ 4) 列运算 数量类型的列可以做加、减、乘、除运算SELECT sal*1.5 FROM emp;SELECT sal+comm FROM emp; 字符串类型可以做连续运算SELECT CONCAT('$', sal) FROM emp; 转换NULL值有时需要把NULL转换成其它值，例如comm+1000时，如果comm列存在NULL值，那么NULL+1000还是NULL，而我们这时希望把NULL当前0来运算。SELECT IFNULL(comm, 0)+1000 FROM emp;–&gt;IFNULL(comm, 0)：如果comm中存在NULL值，那么当成0来运算。 给列起别名你也许已经注意到了，当使用列运算后，查询出的结果集中的列名称很不好看，这时我们需要给列名起个别名，这样在结果集中列名就显示别名了SELECT IFNULL(comm, 0)+1000 AS '奖金' FROM emp;–&gt; 其中AS可以省略 2. 条件控制1.条件查询 与前面介绍的UPDATE和DELETE语句一样，SELECT语句也可以使用WHERE子句来控制记录。SELECT empno,ename,sal,comm FROM emp WHERE sal &gt; 10000 AND comm IS NOT NULL;SELECT empno,ename,sal FROM emp WHERE sal BETWEEN 20000 AND 30000;SELECT empno,ename,job FROM emp WHERE job IN ('经理', '董事长'); 2.模糊查询 当你想查询姓张，并且姓名一共两个字的员工时，这时就可以使用模糊查询SELECT * FROM emp WHERE ename LIKE '张_'; –&gt; 模糊查询需要使用运算符：LIKE，其中_匹配一个任意字符，注意，只匹配一个字符而不是多个。 –&gt; 上面语句查询的是姓张，名字由两个字组成的员工。SELECT * FROM emp WHERE ename LIKE '___'; –&gt;姓名由3个字组成的员工 如果我们想查询姓张，名字几个字可以的员工时就要使用“%”了。SELECT * FROM emp WHERE ename LIKE '张%';–&gt; 其中%匹配0~N*个任意字符，所以上面语句查询的是姓张的所有员工。SELECT * FROM emp WHERE ename LIKE '%阿%';–&gt; 千万不要认为上面语句是在查询姓名中间带有阿字的员工，因为%匹配0~N个字符，所以姓名以阿开头和结尾的员工也都会查询到。SELECT * FROM emp WHERE ename LIKE '%';–&gt; 这个条件等同与不存在，但如果姓名为NULL*的查询不出来！ 二、排序 升序SELECT * FROM WHERE emp ORDER BY sal ASC; –&gt; 按sal排序，升序！–&gt; 其中ASC是可以省略的 降序SELECT * FROM WHERE emp ORDER BY comm DESC; –&gt; 按comm排序，降序！–&gt; 其中DESC不能省略 使用多列作为排序条件SELECT * FROM WHERE emp ORDER BY sal ASC, comm DESC; –&gt; 使用sal升序排，如果sal相同时，使用comm的降序排 三、聚合函数 聚合函数用来做某列的纵向运算。 COUNTSELECT COUNT(*) FROM emp;–&gt; 计算emp表中所有列都不为NULL的记录的行数SELECT COUNT(comm) FROM emp;–&gt; 云计算emp表中comm列不为NULL的记录的行数 MAXSELECT MAX(sal) FROM emp;–&gt; 查询最高工资 MINSELECT MIN(sal) FROM emp;–&gt; 查询最低工资 SUMSELECT SUM(sal) FROM emp;–&gt; 查询工资合 AVGSELECT AVG(sal) FROM emp;–&gt; 查询平均工资 四、分组查询 分组查询是把记录使用某一列进行分组，然后查询组信息。 例如：查看所有部门的记录数。 SELECT deptno, COUNT(*) FROM emp GROUP BY deptno; –&gt; 使用deptno分组，查询部门编号和每个部门的记录数 SELECT job, MAX(SAL) FROM emp GROUP BY job; –&gt; 使用job分组，查询每种工作的最高工资 组条件 以部门分组，查询每组记录数。条件为记录数大于3 SELECT deptno, COUNT(*) FROM emp GROUP BY deptno HAVING COUNT(*) &gt; 3; 五、limit子句(方言) LIMIT用来限定查询结果的起始行，以及总行数。 例如：查询起始行为第5行，一共查询3行记录 SELECT * FROM emp LIMIT 4, 3; –&gt; 其中4表示从第5行开始，其中3表示一共查询3行。即第5、6、7行记录。 select * from emp limit 0, 5; 1. 一页的记录数：10行 2. 查询第3页 select * from emp limit 20, 10; (当前页-1) * 每页记录数 (3-1) * 10 (17-1) * 8, 8 九、备份恢复数据库 –&gt; sql语句sql语句 –&gt; 数据库 数据库导出SQL脚本(备份数据库内容，并不是备份数据库！) mysqldump –u用户名 –p密码 数据库名&gt;生成的脚本文件路径例如：mysqldump -uroot -p123 mydb1&gt;C:\\mydb1.sql(与mysql.exe和mysqld.exe一样, 都在bin目录下)注意：不要打分号，不要登录mysql，直接在cmd下运行注意：生成的脚本文件中不包含create database语句 执行SQL脚本第一种方式 mysql -u用户名 -p密码 数据库&lt;脚本文件路径例如：先删除mydb1库，再重新创建mydb1库mysql -uroot -p123 mydb1&lt;C:\\mydb1.sql注意：不要打分号，不要登录mysql，直接在cmd下运行 第二种方式 登录mysqlsource SQL脚本路径例如：先删除mydb1库，再重新创建mydb1库切换到mydb1库source c:\\mydb1.sql 十、主键约束（唯一标识） 非空 唯一 被引用（学习外键时） 当表的某一列被指定为主键后，该列就不能为空，不能有重复值出现。创建表时指定主键的两种方式：1. CREATE TABLE stu( sid CHAR(6) PRIMARY KEY, sname VARCHAR(20), age INT, gender VARCHAR(10) ); 指定sid列为主键列，即为sid列添加主键约束 2. CREATE TABLE stu( sid CHAR(6), sname VARCHAR(20), age INT, gender VARCHAR(10), PRIMARY KEY(sid) ); 指定sid列为主键列，即为sid列添加主键约束 修改表时指定主键： ALTER TABLE stu ADD PRIMARY KEY(sid); 删除主键： ALTER TABLE stu DROP PRIMARY KEY; 十一、主键自增长 因为主键列的特性是：必须唯一、不能为空，所以我们通常会指定主键类为整型，然后设置其自动增长，这样可以保证在插入数据时主键列的唯一和非空特性。 创建表时指定主键自增长 CREATE TABLE stu( sid INT PRIMARY KEY AUTO_INCREMENT, sname VARCHAR(20), age INT, gender VARCHAR(10) ); 修改表时设置主键自增长：ALTER TABLE stu CHANGE sid sid INT AUTO_INCREMENT; 修改表时删除主键自增长：ALTER TABLE stu CHANGE sid sid INT; 测试主键自增长： INSERT INTO stu VALUES(NULL, ‘zhangSan’,23,’male’);INSERT INTO stu(sname,age,gender) VALUES(‘zhangSan’,23,’male’); 十二、非空约束与唯一约束 非空约束 因为某些列不能设置为NULL值，所以可以对列添加非空约束。 例如： CREATE TABLE stu( sid INT PRIMARY KEY AUTO_INCREMENT, sname VARCHAR(20) NOT NULL, age INT, gender VARCHAR(10) ); 对sname列设置了非空约束 唯一约束 车库某些列不能设置重复的值，所以可以对列添加唯一约束。 例如： CREATE TABLE stu( sid INT PRIMARY KEY AUTO_INCREMENT, sname VARCHAR(20) NOT NULL UNIQUE, age INT, gender VARCHAR(10) ); 对sname列设置了唯一约束 十三、概述模型、对象模型、关系模型对象模型：可以双向关联，而且引用的是对象，而不是一个主键！关系模型：只能多方引用一方，而且引用的只是主键，而不是一整行记录。 对象模型：**在java中是domain！！！例如：User、Student is ahas a(关联)1对11对多多对多use a 关系模型：在数据库中表！！！ 当我们要完成一个软件系统时，需要把系统中的实体抽取出来，形成概念模型。 例如部门、员工都是系统中的实体。概念模型中的实体最终会成为Java中的类、数据库中表。 实体之间还存在着关系，关系有三种： 1对多：例如每个员工都从属一个部门，而一个部门可以有多个员工，其中员工是多方，而部门是一方。 1对1：例如老公和老婆就是一对一的关系，一个老公只能有一个老婆，而一个老婆只能有一个老公。 多对多：老师与学生的关系就是多对多，一个老师可以有多个学生，一个学生可以有多个老师。 概念模型：在Java中成为实体类（javaBean） 类就使用成员变量来完成关系，一般都是双向关联！ 多对一双向中关联，即员工关联部门，部门也关联员工 class Employee {//多方关联一方 ... private Department department; } class Department {//一方关联多方 ... private List&lt;Employee> employees; }``` ```sql class Husband { ... private Wife wife; } class Wife { ... private Husband } class Student { ... private List&lt;Teacher> teachers } class Teacher { ... private List&lt;Student> students; } 十四、外键约束 外键必须是另一表的主键的值(外键要引用主键！) 外键可以重复 外键可以为空 一张表中可以有多个外键！ 概念模型在数据库中成为表 数据库表中的多对一关系，只需要在多方使用一个独立的列来引用1方的主键即可 /*员工表*/ create talbe emp ( empno int primary key,/*员工编号*/ ... deptno int/*所属部门的编号*/ ); /*部门表*/ create table dept ( deptno int primary key,/*部门编号*/ ... ); emp表中的deptno列的值表示当前员工所从属的部门编号。也就是说emp.deptno必须在dept表中是真实存在！ 但是我们必须要去对它进行约束，不然可能会出现员工所属的部门编号是不存在的。这种约束就是外键约束。 我们需要给emp.deptno添加外键约束，约束它的值必须在dept.deptno中存在。外键必须是另一个表的主键！语法：CONSTRAINT 约束名称 FOREIGN KEY(外键列名) REFERENCES 关联表(关联表的主键) 创建表时指定外键约束 create talbe emp ( empno int primary key, ... deptno int, CONSTRAINT fk_emp FOREIGN KEY(mgr) REFERENCES emp(empno) ); 修改表时添加外键约束 ALERT TABLE emp ADD CONSTRAINT fk_emp_deptno FOREIGN KEY(deptno) REFERENCES dept(deptno); 修改表时删除外键约束 ALTER TABLE emp DROP FOREIGN KEY fk_emp_deptno;/*约束名称*/ 十五、数据库关系1.一对一关系在表中建立一对一关系比较特殊，需要让其中一张表的主键，即是主键又是外键。 create table husband( hid int PRIMARY KEY, ... ); create table wife( wid int PRIMARY KEY, ... ADD CONSTRAINT fk_wife_wid FOREIGN KEY(wid) REFERENCES husband(hid) ); 其中wife表的wid即是主键，又是相对husband表的外键！ husband.hid是主键，不能重复！ wife.wid是主键，不能重复，又是外键，必须来自husband.hid。 所以如果在wife表中有一条记录的wid为1，那么wife表中的其他记录的wid就不能再是1了，因为它是主键。 同时在husband.hid中必须存在1这个值，因为wid是外键。这就完成了一对一关系。 *从表的主键即是外键！ 2.多对多关系在表中建立多对多关系需要使用中间表，即需要三张表，在中间表中使用两个外键，分别引用其他两个表的主键。 create table student( sid int PRIMARY KEY, ... ); create table teacher( tid int PRIMARY KEY, ... ); create table stu_tea( sid int, tid int, ADD CONSTRAINT fk_stu_tea_sid FOREIGN KEY(sid) REFERENCES student(sid), ADD CONSTRAINT fk_stu_tea_tid FOREIGN KEY(tid) REFERENCES teacher(tid) ); 这时在stu_tea这个中间表中的每条记录都是来说明student和teacher表的关系例如在stu_tea表中的记录：sid为1001，tid为2001，这说明编号为1001的学生有一个编号为2001的老师 sid tid 101 201 /*编号为101的学生有一个编号为201的老师*/ 101 202 /*编号为101的学生有一个编号为202的老师*/ 101 203 /*编号为101的学生有一个编号为203的老师*/ 102 201 /*编号为102的学生有一个编号为201的老师*/ 102 204 /*编号为102的学生有一个编号为204的老师*/ 十六、多表查询分类： 合并结果集(了解) 连接查询 子查询 1. 合并结果集 要求被合并的表中，列的类型和列数相同 UNION：去除重复行 UNION ALL：不去除重复行SELECT * FROM cd UNION ALL SELECT * FROM ab; 2. 连接查询 分类 内连接 外连接 左外连接 右外连接 全外连接(MySQL不支持) 自然连接（属于一种简化方式） 内连接 方言：SELECT * FROM 表1 别名1, 表2 别名2 WHERE 别名1.xx=别名2.xx 标准：SELECT * FROM 表1 别名1 INNER JOIN 表2 别名2 ON 别名1.xx=别名2.xx 自然：SELECT * FROM 表1 别名1 NATURAL JOIN 表2 别名2 内连接查询出的所有记录都满足条件。 外连接 左外：SELECT * FROM 表1 别名1 LEFT OUTER JOIN 表2 别名2 ON 别名1.xx=别名2.xx 左表记录无论是否满足条件都会查询出来，而右表只有满足条件才能出来。左表中不满足条件的记录，右表部分都为NULL 左外自然：SELECT * FROM 表1 别名1 NATURAL LEFT OUTER JOIN 表2 别名2 ON 别名1.xx=别名2.xx 右外：SELECT * FROM 表1 别名1 RIGHT OUTER JOIN 表2 别名2 ON 别名1.xx=别名2.xx 右表记录无论是否满足条件都会查询出来，而左表只有满足条件才能出来。右表不满足条件的记录，其左表部分都为NULL 右外自然：SELECT * FROM 表1 别名1 NATURAL RIGHT OUTER JOIN 表2 别名2 ON 别名1.xx=别名2.xx 全链接：把left或者right改为full，但是mysql不支持，可以使用UNION来完成全链接 3. 子查询 ：查询中有查询（查看select关键字的个数！） 出现的位置： where后作为条件存在 from后作为表存在(多行多列) 条件 (***)单行单列：SELECT * FROM 表1 别名1 WHERE 列1 [=、&gt;、&lt;、&gt;=、&lt;=、!=] (SELECT 列 FROM 表2 别名2 WHERE 条件) (**)多行单列：SELECT * FROM 表1 别名1 WHERE 列1 [IN, ALL, ANY] (SELECT 列 FROM 表2 别名2 WHERE 条件) (*)单行多列：SELECT * FROM 表1 别名1 WHERE (列1,列2) IN (SELECT 列1, 列2 FROM 表2 别名2 WHERE 条件) (***)多行多列：SELECT * FROM 表1 别名1 , (SELECT ....) 别名2 WHERE 条件 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"数据库","slug":"数据库","permalink":"http://blog.hming.org/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://blog.hming.org/tags/MySQL/"}]},{"title":"那些年经历过的编码警告","slug":"代码警告","date":"2017-07-17T08:23:26.000Z","updated":"2017-07-17T08:23:26.000Z","comments":true,"path":"2017/07/17/dai-ma-jing-gao/","link":"","permalink":"http://blog.hming.org/2017/07/17/dai-ma-jing-gao/","excerpt":"","text":"try catch中catch块臃肿catch块臃肿 虽然不会报错，但是会有警告。 正确的书写方式如下： try{ //... } catch (IOException | ClassNotFoundException e){ e.printStackTrace(); } 可以看到，通过 | 运算符号折叠成一个判断语句，这个符号有”或”的意思，在这里理解非常合适。 应该是java意识到了catch语句的臃肿，所以在JDK中开始建议这种模式来捕获异常。 集合泛型检查警告 该警告就是集合在创建是没有用泛型指定存储的对象类型 解决方式： 为集合指定泛型 List&lt;String> list = new ArrayList&lt;String>(); 利用Commons工具包生成集合import com.google.common.collect.Lists; List&lt;String> list = Lists.newArrayList(); 其他集合类型如：Map、Set类似 一些清晰易懂的警告1、空指针警告 该警告意思是可能报空指针异常，也就是没有做安全处理。消除警告的做法就是在调用方法之前，对有可能出现空指针异常的对象做是否为空的判断，也就是安全处理。 2、忽略返回值警告 该警告消除方式为定义一个该方法的返回值类型去接收返回值。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Java","slug":"Java","permalink":"http://blog.hming.org/categories/Java/"}],"tags":[{"name":"代码规范","slug":"代码规范","permalink":"http://blog.hming.org/tags/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"}]},{"title":"Idea创建Maven项目注意事项","slug":"Idea创建Maven项目注意事项","date":"2016-07-23T09:15:19.000Z","updated":"2016-07-23T09:15:19.000Z","comments":true,"path":"2016/07/23/idea-chuang-jian-maven-xiang-mu-zhu-yi-shi-xiang/","link":"","permalink":"http://blog.hming.org/2016/07/23/idea-chuang-jian-maven-xiang-mu-zhu-yi-shi-xiang/","excerpt":"","text":"新建项目的时候选择maven项目。接着下一步，这里需要注在Properties中添加一个参数archetypeCatalog=internal，不加这个参数，在maven生成骨架的时候将会非常慢，有时候直接卡住。 来自网上的解释：archetypeCatalog表示插件使用的archetype元数据，不加这个参数时默认为remote，local，即中央仓库archetype元数据，由于中央仓库的archetype太多了所以导致很慢，指定internal来表示仅使用内部元数据。 这样，在初始化maven项目的时候就不会被卡住了。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Java","slug":"Java","permalink":"http://blog.hming.org/categories/Java/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"http://blog.hming.org/tags/Maven/"},{"name":"Idea","slug":"Idea","permalink":"http://blog.hming.org/tags/Idea/"},{"name":"编辑器","slug":"编辑器","permalink":"http://blog.hming.org/tags/%E7%BC%96%E8%BE%91%E5%99%A8/"}]}]}